<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Avro简介及Java运用</title>
    <url>/2019/02/15/Avro%E7%AE%80%E4%BB%8B%E5%8F%8AJava%E8%BF%90%E7%94%A8/</url>
    <content><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p><a href="https://zh.wikipedia.org/wiki/Apache_Avro">Avro</a>是一种远程过程调用和数据序列化框架，是在Apache的Hadoop项目之内开发的。它使用JSON来定义数据类型和通讯协议，使用压缩二进制格式来序列化数据。它主要用于Hadoop，它可以为持久化数据提供一种序列化格式，Avro是一个数据序列化的系统。可以将数据结构或对象转化成便于存储或传输的格式。Avro设计之初就用来支持数据密集型应用，适合于远程或本地大规模数据的存储和交换。</p>
<span id="more"></span>
<h3 id="序列化及反序列化概念"><a href="#序列化及反序列化概念" class="headerlink" title="序列化及反序列化概念"></a>序列化及反序列化概念</h3><ul>
<li>把对象转换为字节序列的过程称为对象的<strong>序列化</strong>。</li>
<li>把字节序列恢复为对象的过程称为对象的<strong>反序列化</strong>。</li>
</ul>
<p>对象的序列化主要有两种用途：</p>
<ol>
<li>把对象的字节序列永久地保存到硬盘上，通常存放在一个文件中</li>
<li>在网络上传送对象的字节序列。</li>
</ol>
<p>　　在很多应用中，需要对某些对象进行序列化，让它们离开内存空间，入住物理硬盘，以便长期保存。比如最常见的是Web服务器中的Session对象，当有 10万用户并发访问，就有可能出现10万个Session对象，内存可能吃不消，于是Web容器就会把一些seesion先序列化到硬盘中，等要用了，再把保存在硬盘中的对象还原到内存中。</p>
<p>　　当两个进程在进行远程通信时，彼此可以发送各种类型的数据。无论是何种类型的数据，都会以二进制序列的形式在网络上传送。发送方需要把这个Java对象转换为字节序列，才能在网络上传送；接收方则需要把字节序列再恢复为Java对象。</p>
<h3 id="Avro特点"><a href="#Avro特点" class="headerlink" title="Avro特点"></a>Avro特点</h3><ul>
<li><p>丰富的数据结构类型；</p>
</li>
<li><p>快速可压缩的二进制数据形式，对数据二进制序列化后可以节约数据存储空间和网络传输带宽；</p>
</li>
<li><p>存储持久数据的文件容器；</p>
</li>
<li><p>可以实现远程过程调用RPC；</p>
</li>
<li><p>简单的动态语言结合功能。</p>
</li>
</ul>
<h2 id="数据类型"><a href="#数据类型" class="headerlink" title="数据类型"></a>数据类型</h2><h3 id="基础数据类型"><a href="#基础数据类型" class="headerlink" title="基础数据类型"></a>基础数据类型</h3><table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
<th>Schema</th>
</tr>
</thead>
<tbody>
<tr>
<td>null</td>
<td>the absence of a value</td>
<td>“null”</td>
</tr>
<tr>
<td>boolean</td>
<td>a binary value</td>
<td>“boolean”</td>
</tr>
<tr>
<td>int</td>
<td>32-bit signed integer</td>
<td>“int”</td>
</tr>
<tr>
<td>long</td>
<td>64-bit signed integer</td>
<td>“long”</td>
</tr>
<tr>
<td>float</td>
<td>Single-precision (32-bit) IEEE 754 floating-point number</td>
<td>“float”</td>
</tr>
<tr>
<td>double</td>
<td>Double-precision (64-bit) IEEE 754 floating-point number</td>
<td>“double”</td>
</tr>
<tr>
<td>bytes</td>
<td>Sequence of 8-bit unsigned bytes</td>
<td>“bytes”</td>
</tr>
<tr>
<td>string</td>
<td>Sequence of Unicode characters</td>
<td>“string”</td>
</tr>
</tbody>
</table>
<h3 id="复杂数据类型"><a href="#复杂数据类型" class="headerlink" title="复杂数据类型"></a>复杂数据类型</h3><p>Avro提供了6种复杂类型。分别是Record，Enum，Array，Map，Union和Fixed。</p>
<h4 id="Record"><a href="#Record" class="headerlink" title="Record"></a>Record</h4><p>Record是一个任意类型的命名字段的集合</p>
<p>支持的属性设置：</p>
<ul>
<li>name：record类型的名字(必填)</li>
<li>namespace：命名空间(可选)</li>
<li>doc：这个类型的文档说明(可选)</li>
<li>aliases：record类型的别名，是个字符串数组(可选)</li>
<li><p>fields：record类型中的字段，是个对象数组(必填)。每个字段需要以下属性：</p>
<ol>
<li>name：字段名字(必填)</li>
<li>doc：字段说明文档(可选)</li>
<li>type：一个schema的json对象或者一个类型名字(必填)</li>
<li>default：默认值(可选)</li>
<li>order：排序(可选)，只有3个值ascending(默认)，descending或ignore</li>
<li>aliases：别名，字符串数组(可选)</li>
</ol>
</li>
</ul>
<p>一个Record类型例子，定义一个元素类型是Long的链表：<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="string">&quot;type&quot;</span>: <span class="string">&quot;record&quot;</span>, </span><br><span class="line">  <span class="string">&quot;name&quot;</span>: <span class="string">&quot;LongList&quot;</span>,</span><br><span class="line">  <span class="string">&quot;aliases&quot;</span>: [<span class="string">&quot;LinkedLongs&quot;</span>], <span class="comment">// old name for this</span></span><br><span class="line">  <span class="string">&quot;fields&quot;</span> : [</span><br><span class="line">    &#123;<span class="string">&quot;name&quot;</span>: <span class="string">&quot;value&quot;</span>, <span class="string">&quot;type&quot;</span>: <span class="string">&quot;long&quot;</span>&#125;, <span class="comment">// each element has a long</span></span><br><span class="line">    &#123;<span class="string">&quot;name&quot;</span>: <span class="string">&quot;next&quot;</span>, <span class="string">&quot;type&quot;</span>: [<span class="string">&quot;null&quot;</span>, <span class="string">&quot;LongList&quot;</span>]&#125; <span class="comment">// optional next element</span></span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h4 id="Enum"><a href="#Enum" class="headerlink" title="Enum"></a>Enum</h4><p>枚举类型的类型名字是”enum”，还支持其它属性的设置：</p>
<ul>
<li>name：枚举类型的名字(必填)</li>
<li>namespace：命名空间(可选)</li>
<li>aliases：字符串数组，别名(可选)</li>
<li>doc：说明文档(可选)</li>
<li>symbols：字符串数组，所有的枚举值(必填)，不允许重复数据。</li>
</ul>
<p>一个枚举类型的例子：<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">&#123; <span class="string">&quot;type&quot;</span>: <span class="string">&quot;enum&quot;</span>,</span><br><span class="line">  <span class="string">&quot;name&quot;</span>: <span class="string">&quot;Suit&quot;</span>,</span><br><span class="line">  <span class="string">&quot;symbols&quot;</span> : [<span class="string">&quot;SPADES&quot;</span>, <span class="string">&quot;HEARTS&quot;</span>, <span class="string">&quot;DIAMONDS&quot;</span>, <span class="string">&quot;CLUBS&quot;</span>]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h4 id="Array"><a href="#Array" class="headerlink" title="Array"></a>Array</h4><p>数组类型的类型名字是”array”并且只支持一个属性：</p>
<p>items：数组元素的schema</p>
<p>一个数组例子：<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="string">&quot;type&quot;</span>: <span class="string">&quot;array&quot;</span>, </span><br><span class="line">    <span class="string">&quot;items&quot;</span>: <span class="string">&quot;string&quot;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h4 id="Map"><a href="#Map" class="headerlink" title="Map"></a>Map</h4><p>Map类型的类型名字是”map”并且只支持一个属性：</p>
<p>values：map值的schema</p>
<p>Map的key必须是字符串。</p>
<p>一个Map例子：<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="string">&quot;type&quot;</span>: <span class="string">&quot;map&quot;</span>,</span><br><span class="line">    <span class="string">&quot;values&quot;</span>: <span class="string">&quot;long&quot;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h4 id="Union"><a href="#Union" class="headerlink" title="Union"></a>Union</h4><p>组合类型，表示各种类型的组合，使用数组进行组合。比如<code>[“null”, “string”]</code>表示类型可以为null或者string。</p>
<p>如以下例子<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">     <span class="string">&quot;type&quot;</span>: <span class="string">&quot;record&quot;</span>,</span><br><span class="line">     <span class="string">&quot;namespace&quot;</span>: <span class="string">&quot;com.example&quot;</span>,</span><br><span class="line">     <span class="string">&quot;name&quot;</span>: <span class="string">&quot;FullName&quot;</span>,</span><br><span class="line">     <span class="string">&quot;fields&quot;</span>: </span><br><span class="line">     [</span><br><span class="line">       &#123; <span class="string">&quot;name&quot;</span>: <span class="string">&quot;first&quot;</span>, <span class="string">&quot;type&quot;</span>: [<span class="string">&quot;null&quot;</span>, <span class="string">&quot;string&quot;</span>] &#125;,</span><br><span class="line">       &#123; <span class="string">&quot;name&quot;</span>: <span class="string">&quot;last&quot;</span>, <span class="string">&quot;type&quot;</span>: <span class="string">&quot;string&quot;</span>, <span class="string">&quot;default&quot;</span> : <span class="string">&quot;Doe&quot;</span> &#125;</span><br><span class="line">     ]</span><br><span class="line">&#125; </span><br></pre></td></tr></table></figure><br>组合类型的默认值是看组合类型的第一个元素，因此如果一个组合类型包括null类型，那么null类型一般都会放在第一个位置，这样子的话这个组合类型的默认值就是null。</p>
<p>组合类型中不允许同一种类型的元素的个数不会超过1个，除了record，fixed和enum。比如组合类中有2个array类型或者2个map类型，这是不允许的。</p>
<p>组合类型不允许嵌套组合类型。</p>
<h4 id="Fixed"><a href="#Fixed" class="headerlink" title="Fixed"></a>Fixed</h4><p>混合类型的类型名字是fixed，支持以下属性：</p>
<ul>
<li>name：名字(必填)</li>
<li>namespace：命名空间(可选)</li>
<li>aliases：字符串数组，别名(可选)</li>
<li>size：一个整数，表示每个值的字节数(必填)</li>
</ul>
<p>比如16个字节数的fixed类型例子如下：<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="string">&quot;type&quot;</span>: <span class="string">&quot;fixed&quot;</span>, </span><br><span class="line">    <span class="string">&quot;size&quot;</span>: <span class="number">16</span>, </span><br><span class="line">    <span class="string">&quot;name&quot;</span>: <span class="string">&quot;md5&quot;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h2 id="java实践"><a href="#java实践" class="headerlink" title="java实践"></a>java实践</h2><h3 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h3><h4 id="引入pom-xml"><a href="#引入pom-xml" class="headerlink" title="引入pom.xml"></a>引入pom.xml</h4><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.avro<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>avro<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.8.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h4 id="下载avro-tool"><a href="#下载avro-tool" class="headerlink" title="下载avro-tool"></a>下载avro-tool</h4><p>avro-tools-1.8.2.jar 该jar包主要用户将定义好的schema文件生成对应的java文件<br><a href="http://central.maven.org/maven2/org/apache/avro/avro-tools/1.8.2/">下载地址</a></p>
<h3 id="schema"><a href="#schema" class="headerlink" title="schema"></a>schema</h3><p>Avro依赖模式(Schema)来实现数据结构定义。可以把模式理解为Java的类，它定义每个实例的结构，可以包含哪些属性。可以根据类来产生任意多个实例对象。对实例序列化操作时必须需要知道它的基本结构，也就需要参考类的信息。这里，根据模式产生的Avro对象类似于类的实例对象。每次序列化/反序列化时都需要知道模式的具体结构。所以，在Avro可用的一些场景下，如文件存储或是网络通信，都需要模式与数据同时存在。Avro数据以模式来读和写(文件或是网络)，并且写入的数据都不需要加入其它标识，这样序列化时速度快且结果内容少。由于程序可以直接根据模式来处理数据，所以Avro更适合于脚本语言的发挥。</p>
<h4 id="定义schema"><a href="#定义schema" class="headerlink" title="定义schema"></a>定义schema</h4><p>avro的schema是json格式，支持前文所描述的类型。<br>下面是一个schema例子 User.avsc<br><figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">   <span class="attr">&quot;type&quot;</span>: <span class="string">&quot;record&quot;</span>,</span><br><span class="line">   <span class="attr">&quot;name&quot;</span>: <span class="string">&quot;User&quot;</span>,</span><br><span class="line">   <span class="attr">&quot;fields&quot;</span>: [</span><br><span class="line">      &#123;</span><br><span class="line">         <span class="attr">&quot;name&quot;</span>: <span class="string">&quot;name&quot;</span>,</span><br><span class="line">         <span class="attr">&quot;type&quot;</span>: <span class="string">&quot;string&quot;</span>,</span><br><span class="line">         <span class="attr">&quot;doc&quot;</span>:<span class="string">&quot;姓名&quot;</span></span><br><span class="line">      &#125;,</span><br><span class="line">      &#123;</span><br><span class="line">         <span class="attr">&quot;name&quot;</span>: <span class="string">&quot;favorite_number&quot;</span>,</span><br><span class="line">         <span class="attr">&quot;type&quot;</span>: [</span><br><span class="line">            <span class="string">&quot;int&quot;</span>,</span><br><span class="line">            <span class="string">&quot;null&quot;</span></span><br><span class="line">         ]</span><br><span class="line">      &#125;,</span><br><span class="line">      &#123;</span><br><span class="line">         <span class="attr">&quot;name&quot;</span>: <span class="string">&quot;favorite_color&quot;</span>,</span><br><span class="line">         <span class="attr">&quot;type&quot;</span>: [</span><br><span class="line">            <span class="string">&quot;string&quot;</span>,</span><br><span class="line">            <span class="string">&quot;null&quot;</span></span><br><span class="line">         ]</span><br><span class="line">      &#125;</span><br><span class="line">   ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h4 id="编译schema"><a href="#编译schema" class="headerlink" title="编译schema"></a>编译schema</h4><p>使用avro-tools-1.8.2.jar 编译<br>编译命令格式如下：</p>
<p><code>java -jar avro-tools-1.8.2.jar compile schema &lt;filename.avsc&gt; &lt;outputpath&gt;</code></p>
<h3 id="序列化与反序列化"><a href="#序列化与反序列化" class="headerlink" title="序列化与反序列化"></a>序列化与反序列化</h3><p>avro的序列化和反序列化，有两种方法。第一种是需要利用schema生成实体类，另外一种只需要指定schema并使用GenericRecord作为实体。</p>
<h4 id="生成实体类User"><a href="#生成实体类User" class="headerlink" title="生成实体类User"></a>生成实体类User</h4><p>编译schema至java项目src目录</p>
<h5 id="序列化"><a href="#序列化" class="headerlink" title="序列化"></a>序列化</h5><p>AvroSerialize.java<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.*;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.avro.file.*;</span><br><span class="line"><span class="keyword">import</span> org.apache.avro.io.*;</span><br><span class="line"><span class="keyword">import</span> org.apache.avro.specific.*;</span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">AvroSerialize</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String args[])</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    	</span><br><span class="line">    	<span class="comment">// 新建3个实体类</span></span><br><span class="line">        User user1 = <span class="keyword">new</span> User();</span><br><span class="line">        user1.setName(<span class="string">&quot;Alyssa&quot;</span>);</span><br><span class="line">        user1.setFavoriteNumber(<span class="number">256</span>);</span><br><span class="line"></span><br><span class="line">        User user2 = <span class="keyword">new</span> User(<span class="string">&quot;Ben&quot;</span>, <span class="number">7</span>, <span class="string">&quot;red&quot;</span>);</span><br><span class="line"></span><br><span class="line">        User user3 = User.newBuilder()</span><br><span class="line">                .setName(<span class="string">&quot;Charlie&quot;</span>)</span><br><span class="line">                .setFavoriteColor(<span class="string">&quot;blue&quot;</span>)</span><br><span class="line">                .setFavoriteNumber(<span class="keyword">null</span>)</span><br><span class="line">                .build();</span><br><span class="line"></span><br><span class="line">        DatumWriter&lt;User&gt; userDatumWriter = <span class="keyword">new</span> SpecificDatumWriter&lt;User&gt;(User.class);</span><br><span class="line">        DataFileWriter&lt;User&gt; dataFileWriter = <span class="keyword">new</span> DataFileWriter&lt;User&gt;(userDatumWriter);</span><br><span class="line">        dataFileWriter.create(user1.getSchema(), <span class="keyword">new</span> File(<span class="string">&quot;./src/main/avro/user.avro&quot;</span>));</span><br><span class="line">        dataFileWriter.append(user1);</span><br><span class="line">        dataFileWriter.append(user2);</span><br><span class="line">        dataFileWriter.append(user3);</span><br><span class="line">        dataFileWriter.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h5 id="反序列化"><a href="#反序列化" class="headerlink" title="反序列化"></a>反序列化</h5><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.*;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.avro.file.*;</span><br><span class="line"><span class="keyword">import</span> org.apache.avro.io.*;</span><br><span class="line"><span class="keyword">import</span> org.apache.avro.specific.*;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">AvroDeserialize</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String args[])</span> </span>&#123;</span><br><span class="line">        DatumReader&lt;User&gt; reader = <span class="keyword">new</span> SpecificDatumReader&lt;&gt;(User.class);</span><br><span class="line">        DataFileReader&lt;User&gt; fileReader = <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            fileReader = <span class="keyword">new</span> DataFileReader&lt;User&gt;(<span class="keyword">new</span> File(<span class="string">&quot;./src/main/avro/user.avro&quot;</span>), reader);</span><br><span class="line">            User user = <span class="keyword">null</span>;</span><br><span class="line">            <span class="keyword">while</span> (fileReader.hasNext()) &#123;</span><br><span class="line">                user = fileReader.next(user);</span><br><span class="line">                System.out.println(user);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>输出</strong></p>
<blockquote>
<p>{“name”: “Alyssa”, “favorite_number”: 256, “favorite_color”: null}<br>{“name”: “Ben”, “favorite_number”: 7, “favorite_color”: “red”}<br>{“name”: “Charlie”, “favorite_number”: null, “favorite_color”: “blue”}</p>
</blockquote>
<h4 id="使用GenericRecord"><a href="#使用GenericRecord" class="headerlink" title="使用GenericRecord"></a>使用GenericRecord</h4><h5 id="序列化-1"><a href="#序列化-1" class="headerlink" title="序列化"></a>序列化</h5><p>AvroGenericDeserializa.java<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> avro;</span><br><span class="line"><span class="keyword">import</span> java.io.*;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.avro.Schema;</span><br><span class="line"><span class="keyword">import</span> org.apache.avro.file.*;</span><br><span class="line"><span class="keyword">import</span> org.apache.avro.generic.*;</span><br><span class="line"><span class="keyword">import</span> org.apache.avro.io.*;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">AvroGenericDeserializa</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String args[])</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        Schema schema = <span class="keyword">new</span> Schema.Parser().parse(<span class="keyword">new</span> File(<span class="string">&quot;./src/main/avro/User.avsc&quot;</span>));</span><br><span class="line">        GenericRecord user1 = <span class="keyword">new</span> GenericData.Record(schema);</span><br><span class="line">        user1.put(<span class="string">&quot;name&quot;</span>, <span class="string">&quot;Alyssa&quot;</span>);</span><br><span class="line">        user1.put(<span class="string">&quot;favorite_number&quot;</span>, <span class="number">256</span>);</span><br><span class="line"></span><br><span class="line">        GenericRecord user2 = <span class="keyword">new</span> GenericData.Record(schema);</span><br><span class="line">        user2.put(<span class="string">&quot;name&quot;</span>, <span class="string">&quot;Ben&quot;</span>);</span><br><span class="line">        user2.put(<span class="string">&quot;favorite_number&quot;</span>, <span class="number">7</span>);</span><br><span class="line">        user2.put(<span class="string">&quot;favorite_color&quot;</span>, <span class="string">&quot;red&quot;</span>);</span><br><span class="line"></span><br><span class="line">        File file = <span class="keyword">new</span> File(<span class="string">&quot;./src/main/avro/user_generic.avro&quot;</span>);</span><br><span class="line">        DatumWriter&lt;GenericRecord&gt; datumWriter = <span class="keyword">new</span> GenericDatumWriter&lt;GenericRecord&gt;(schema);</span><br><span class="line">        DataFileWriter&lt;GenericRecord&gt; dataFileWriter = <span class="keyword">new</span> DataFileWriter&lt;GenericRecord&gt;(datumWriter);</span><br><span class="line">        dataFileWriter.create(schema, file);</span><br><span class="line">        dataFileWriter.append(user1);</span><br><span class="line">        dataFileWriter.append(user2);</span><br><span class="line">        dataFileWriter.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure></p>
<h5 id="反序列化-1"><a href="#反序列化-1" class="headerlink" title="反序列化"></a>反序列化</h5><p>AvroGenericSerialize.java<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.*;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.avro.Schema;</span><br><span class="line"><span class="keyword">import</span> org.apache.avro.file.*;</span><br><span class="line"><span class="keyword">import</span> org.apache.avro.generic.*;</span><br><span class="line"><span class="keyword">import</span> org.apache.avro.io.*;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">AvroGenericSerialize</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String args[])</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        Schema schema = <span class="keyword">new</span> Schema.Parser().parse(<span class="keyword">new</span> File(<span class="string">&quot;./src/main/avro/User.avsc&quot;</span>));</span><br><span class="line">        File file = <span class="keyword">new</span> File(<span class="string">&quot;./src/main/avro/user_generic.avro&quot;</span>);</span><br><span class="line">        DatumReader&lt;GenericRecord&gt; datumReader = <span class="keyword">new</span> GenericDatumReader&lt;GenericRecord&gt;(schema);</span><br><span class="line">        DataFileReader&lt;GenericRecord&gt; dataFileReader = <span class="keyword">new</span> DataFileReader&lt;GenericRecord&gt;(file, datumReader);</span><br><span class="line">        GenericRecord user = <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">while</span> (dataFileReader.hasNext()) &#123;</span><br><span class="line">            user = dataFileReader.next(user);</span><br><span class="line">            System.out.println(user);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br><strong>输出</strong></p>
<blockquote>
<p>{“name”: “Alyssa”, “favorite_number”: 256, “favorite_color”: null}<br>{“name”: “Ben”, “favorite_number”: 7, “favorite_color”: “red”}</p>
</blockquote>
]]></content>
      <tags>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title>Eclipse+Maven构建Hadoop项目</title>
    <url>/2019/02/01/Eclipse+Maven%E6%9E%84%E5%BB%BAHadoop%E9%A1%B9%E7%9B%AE/</url>
    <content><![CDATA[<p><a href="https://zh.wikipedia.org/zh-cn/Apache_Maven">Maven</a>翻译为”专家”、”内行”，是 Apache 下的一个纯 Java 开发的开源项目。基于项目对象模型(Project Object Model 缩写：POM)概念，Maven利用一个中央信息片断能管理一个项目的构建、报告和文档等步骤。Maven 是一个项目管理工具，可以对 Java 项目进行构建、依赖管理。</p>
<p>在开发一些大型项目的时候，需要用到各种各样的开源包jar，为了方便管理及加载jar，使用maven开发项目可以节省大量时间且方便项目移动至新的开发环境。<br><span id="more"></span></p>
<h2 id="开发环境"><a href="#开发环境" class="headerlink" title="开发环境"></a>开发环境</h2><ul>
<li>系统：MacOS 10.14.1</li>
<li>Hadoop：2.7.0</li>
<li>Java：1.8.0</li>
<li>Eclipse：4.6.2</li>
<li>Maven: 3.3.9</li>
</ul>
<h2 id="Maven安装"><a href="#Maven安装" class="headerlink" title="Maven安装"></a>Maven安装</h2><p>我使用的这个版本的Eclipse已经自带了Maven插件，不需要在自行安装，因此我也没有实际操作，本文就不介绍如何配置。</p>
<p>至于怎么知道自己使用的Eclipse是否自带有Maven，可以在Eclipse-&gt;Preference-&gt;Maven-&gt;Installations查看是否有Maven及版本号。或者直接新建项目查看是否有Maven选项。<br> <img src="/img/tuchuang/master/resource/2019-02/maven_installation.png" alt="Maven installations"></p>
<h2 id="构建Hadoop环境"><a href="#构建Hadoop环境" class="headerlink" title="构建Hadoop环境"></a>构建Hadoop环境</h2><h3 id="创建Maven项目"><a href="#创建Maven项目" class="headerlink" title="创建Maven项目"></a>创建Maven项目</h3><p>打开Eclipse，File-&gt;new-&gt;project，选择Maven，然后下一步next<br> <img src="/img/tuchuang/master/resource/2019-02/new_maven_project.png" alt="new maven project"><br>选择Creat a simple project，然后下一步next<br> <img src="/img/tuchuang/master/resource/2019-02/new_maven_project_2.png" alt="new maven project"></p>
<p>输入Group id和artifact id。然后finish。</p>
<p>groupid和artifactId被统称为“坐标”是为了保证项目唯一性而提出的，如果你要把你项目弄到maven本地仓库去，你想要找到你的项目就必须根据这两个id去查找。</p>
<p>groupId一般分为多个段，这里我只说两段，第一段为域，第二段为公司名称。域又分为org、com、cn等等许多，其中org为非营利组织，com为商业组织。举个apache公司的tomcat项目例子：这个项目的groupId是org.apache，它的域是org（因为tomcat是非营利项目），公司名称是apache，artigactId是tomcat。</p>
<p>比如我创建一个项目，我一般会将groupId设置为cn.snowin，cn表示域为中国，snowin是我个人姓名缩写，artifactId设置为testProj，表示你这个项目的名称是testProj，依照这个设置，你的包结构最后是cn.snowin.testProj打头。(引自<a href="https://blog.csdn.net/snowin1994/article/details/53024871">链接</a>)<br> <img src="/img/tuchuang/master/resource/2019-02/new_maven_project_3.png" alt="new maven project"></p>
<p>完成上述步骤后，就可以在Project Explorer中看到刚刚创建的Maven项目。<br> <img src="/img/tuchuang/master/resource/2019-02/project_explorer_maven.png" alt="project explorer"></p>
<h3 id="增加Hadoop依赖"><a href="#增加Hadoop依赖" class="headerlink" title="增加Hadoop依赖"></a>增加Hadoop依赖</h3><p>我使用的Hadoop 2.7版本，以下是我的POM配置文件<br><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">project</span> <span class="attr">xmlns</span>=<span class="string">&quot;http://maven.apache.org/POM/4.0.0&quot;</span> <span class="attr">xmlns:xsi</span>=<span class="string">&quot;http://www.w3.org/2001/XMLSchema-instance&quot;</span></span></span><br><span class="line"><span class="tag">	<span class="attr">xsi:schemaLocation</span>=<span class="string">&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">modelVersion</span>&gt;</span>4.0.0<span class="tag">&lt;/<span class="name">modelVersion</span>&gt;</span></span><br><span class="line"> </span><br><span class="line">	<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>practice.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>simple-examples<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">version</span>&gt;</span>0.0.1-SNAPSHOT<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">packaging</span>&gt;</span>jar<span class="tag">&lt;/<span class="name">packaging</span>&gt;</span></span><br><span class="line"> </span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>simple-examples<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">url</span>&gt;</span>http://maven.apache.org<span class="tag">&lt;/<span class="name">url</span>&gt;</span></span><br><span class="line"> </span><br><span class="line">	<span class="tag">&lt;<span class="name">properties</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">project.build.sourceEncoding</span>&gt;</span>UTF-8<span class="tag">&lt;/<span class="name">project.build.sourceEncoding</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">properties</span>&gt;</span></span><br><span class="line"> </span><br><span class="line">	<span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>junit<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>junit<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">version</span>&gt;</span>4.12<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">scope</span>&gt;</span>test<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">		<span class="comment">&lt;!-- https://mvnrepository.com/artifact/org.apache.hadoop/hadoop-common --&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-common<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">version</span>&gt;</span>2.7.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"> </span><br><span class="line">		<span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-hdfs<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">version</span>&gt;</span>2.7.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">		<span class="comment">&lt;!-- https://mvnrepository.com/artifact/org.apache.hadoop/hadoop-client --&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">version</span>&gt;</span>2.7.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"> 		</span><br><span class="line"> 		<span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.mrunit<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>mrunit<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">version</span>&gt;</span>1.1.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">classifier</span>&gt;</span>hadoop2<span class="tag">&lt;/<span class="name">classifier</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">scope</span>&gt;</span>test<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">		<span class="comment">&lt;!-- https://mvnrepository.com/artifact/org.apache.hadoop/hadoop-mapreduce-client-core --&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-mapreduce-client-core<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">version</span>&gt;</span>2.7.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">		<span class="comment">&lt;!-- https://mvnrepository.com/artifact/org.apache.hadoop/hadoop-yarn-api --&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-yarn-api<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">version</span>&gt;</span>2.7.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">		<span class="comment">&lt;!-- https://mvnrepository.com/artifact/org.apache.hadoop/hadoop-auth --&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-auth<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">version</span>&gt;</span>2.7.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">		<span class="comment">&lt;!-- https://mvnrepository.com/artifact/org.apache.hadoop/hadoop-minicluster --&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-minicluster<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">version</span>&gt;</span>2.7.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">scope</span>&gt;</span>test<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">		<span class="comment">&lt;!-- https://mvnrepository.com/artifact/org.apache.hadoop/hadoop-mapreduce-client-jobclient --&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-mapreduce-client-jobclient<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">version</span>&gt;</span>2.7.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">scope</span>&gt;</span>provided<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"> </span><br><span class="line">	<span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">project</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<p>在Project Explorer中右键该项目，选择build project，Maven就会根据POM.xml配置文件下载所需要的jar包。<br> <img src="/img/tuchuang/master/resource/2019-02/build_project.png" alt="build project"></p>
<p>稍等一段时间后，就可以看到Maven Dependencies中已经下载好的jar包。<br> <img src="/img/tuchuang/master/resource/2019-02/hadoop_jar.png" alt="jar"></p>
<h3 id="hadoop配置文件"><a href="#hadoop配置文件" class="headerlink" title="hadoop配置文件"></a>hadoop配置文件</h3><p>运行 MapReduce 程序前，务必将 <code>/usr/local/Cellar/hadoop/2.7.0/libexec/etc/hadoop</code> 中将有修改过的配置文件（如伪分布式需要core-site.xml 和 hdfs-site.xml），以及log4j.properties复制到<code>src/main/resources/</code><br> <img src="/img/tuchuang/master/resource/2019-02/peizhixmlresource.png" alt="配置目录"></p>
<h2 id="MapReduce实例—WordCount"><a href="#MapReduce实例—WordCount" class="headerlink" title="MapReduce实例—WordCount"></a>MapReduce实例—WordCount</h2><p>在<code>src/main/java/</code>路径下，创建java文件，代码如下</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.util.StringTokenizer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IntWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.util.GenericOptionsParser;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">WordCount</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">TokenizerMapper</span> <span class="keyword">extends</span> <span class="title">Mapper</span>&lt;<span class="title">Object</span>, <span class="title">Text</span>, <span class="title">Text</span>, <span class="title">IntWritable</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">		<span class="comment">/**</span></span><br><span class="line"><span class="comment">		 * LongWritable, IntWritable, Text 均是 Hadoop 中实现的用于封装 Java</span></span><br><span class="line"><span class="comment">		 * 数据类型的类，这些类实现了WritableComparable接口，</span></span><br><span class="line"><span class="comment">		 * 都能够被串行化从而便于在分布式环境中进行数据交换，你可以将它们分别视为long,int,String 的替代品。</span></span><br><span class="line"><span class="comment">		 */</span></span><br><span class="line">		<span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">static</span> IntWritable one = <span class="keyword">new</span> IntWritable(<span class="number">1</span>);  <span class="comment">// 值为1</span></span><br><span class="line">		<span class="keyword">private</span> Text word = <span class="keyword">new</span> Text();</span><br><span class="line"></span><br><span class="line">		<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(Object key, Text value, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">			StringTokenizer itr = <span class="keyword">new</span> StringTokenizer(value.toString());  <span class="comment">// 对字符串进行切分</span></span><br><span class="line">			<span class="keyword">while</span> (itr.hasMoreTokens()) &#123;</span><br><span class="line">				word.set(itr.nextToken());</span><br><span class="line">				context.write(word, one);  </span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">IntSumReducer</span> <span class="keyword">extends</span> <span class="title">Reducer</span>&lt;<span class="title">Text</span>, <span class="title">IntWritable</span>, <span class="title">Text</span>, <span class="title">IntWritable</span>&gt; </span>&#123;</span><br><span class="line">		<span class="keyword">private</span> IntWritable result = <span class="keyword">new</span> IntWritable();</span><br><span class="line"></span><br><span class="line">		<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">reduce</span><span class="params">(Text key, Iterable&lt;IntWritable&gt; values, Context context)</span></span></span><br><span class="line"><span class="function">				<span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">			<span class="keyword">int</span> sum = <span class="number">0</span>;</span><br><span class="line">			<span class="keyword">for</span> (IntWritable val : values) &#123;</span><br><span class="line">				sum += val.get();</span><br><span class="line">			&#125;</span><br><span class="line">			result.set(sum);</span><br><span class="line">			context.write(key, result);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">		Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">        conf.addResource(<span class="string">&quot;classpath:/hadoop/core-site.xml&quot;</span>);</span><br><span class="line">        conf.addResource(<span class="string">&quot;classpath:/hadoop/hdfs-site.xml&quot;</span>);</span><br><span class="line">        conf.addResource(<span class="string">&quot;classpath:/hadoop/mapred-site.xml&quot;</span>);</span><br><span class="line"><span class="comment">//		String[] otherArgs = new GenericOptionsParser(conf, args).getRemainingArgs();</span></span><br><span class="line">		String[] otherArgs = &#123;<span class="string">&quot;/input&quot;</span>, <span class="string">&quot;/output&quot;</span>&#125;;</span><br><span class="line">		<span class="keyword">if</span> (otherArgs.length != <span class="number">2</span>) &#123;</span><br><span class="line">			System.err.println(<span class="string">&quot;Usage: wordcount &lt;in&gt; &lt;out&gt;&quot;</span>);</span><br><span class="line">			System.exit(<span class="number">2</span>);</span><br><span class="line">		&#125;</span><br><span class="line">		Job job = <span class="keyword">new</span> Job(conf, <span class="string">&quot;word count&quot;</span>);</span><br><span class="line">		job.setJarByClass(WordCount.class);</span><br><span class="line">		job.setMapperClass(TokenizerMapper.class);</span><br><span class="line">		job.setCombinerClass(IntSumReducer.class);</span><br><span class="line">		job.setReducerClass(IntSumReducer.class);</span><br><span class="line">		job.setOutputKeyClass(Text.class);</span><br><span class="line">		job.setOutputValueClass(IntWritable.class);</span><br><span class="line">		FileInputFormat.setInputDirRecursive(job, <span class="keyword">true</span>);</span><br><span class="line">		FileInputFormat.addInputPath(job, <span class="keyword">new</span> Path(otherArgs[<span class="number">0</span>]));</span><br><span class="line">		FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> Path(otherArgs[<span class="number">1</span>]));</span><br><span class="line">		System.exit(job.waitForCompletion(<span class="keyword">true</span>) ? <span class="number">0</span> : <span class="number">1</span>);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
]]></content>
      <tags>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title>FTP带用户名密码的访问路径</title>
    <url>/2016/09/25/FTP%E5%B8%A6%E7%94%A8%E6%88%B7%E5%90%8D%E5%AF%86%E7%A0%81%E7%9A%84%E8%AE%BF%E9%97%AE%E8%B7%AF%E5%BE%84/</url>
    <content><![CDATA[<p>不带密码的ftp路径格式：<br><code>ftp://url/目录/文件</code><br>带密码的ftp路径格式：<br><code>ftp://username:password@ip/目录/文件</code></p>
]]></content>
      <tags>
        <tag>其他</tag>
      </tags>
  </entry>
  <entry>
    <title>Hadoop开发实例 使用Eclipse实现WordCount</title>
    <url>/2019/01/28/Hadoop%E5%BC%80%E5%8F%91%E5%AE%9E%E4%BE%8B%20%E4%BD%BF%E7%94%A8Eclipse%E5%AE%9E%E7%8E%B0WordCount/</url>
    <content><![CDATA[<p>在学习Hadoop中，WordCount是许多人接触的第一个MapReduce程序，我也不例外。通过在网络上学习找到了不少帖子，但大多数是使用终端运行<code>hadoop jar WordCount.jar</code>实现的。本文将介绍如何使用Eclipse开发并运行WordCount。<br><span id="more"></span></p>
<h2 id="开发环境"><a href="#开发环境" class="headerlink" title="开发环境"></a>开发环境</h2><ul>
<li>系统：MacOS 10.14.1</li>
<li>Hadoop：2.7.0</li>
<li>Java：1.8.0</li>
<li>Eclipse：4.6.2</li>
</ul>
<h2 id="配置Eclipse"><a href="#配置Eclipse" class="headerlink" title="配置Eclipse"></a>配置Eclipse</h2><h3 id="添加hadoop-eclipse-plugin插件"><a href="#添加hadoop-eclipse-plugin插件" class="headerlink" title="添加hadoop-eclipse-plugin插件"></a>添加hadoop-eclipse-plugin插件</h3><p>新安装的Eclipse通常是无法直接新建MapReduce程序，需要添加<code>hadoop-eclipse-plugin</code>插件，<a href="https://github.com/winghc/hadoop2x-eclipse-plugin/tree/master/release">下载地址</a>。<br>此处以macOS为例。</p>
<ol>
<li>先下载hadoop_eclipse_plugin插件</li>
<li>进入到eclipse的dropins目录<br>在Finder中找到应用程序，然后找到eclipse.这时eclipse显示的是一个app，而不是一个目录。右键点击后，打开选择显示包内容，就可以找到eclipse的应用程序目录了</li>
<li>把hadoop_eclipse_plugin.jar放进dropins文件夹内。</li>
<li>重启eclipse，打开window-&gt; show view-&gt; other-&gt; MapReduce Tools,选择Map/Reduce Locations</li>
</ol>
<h3 id="与Hadoop集群建立连接"><a href="#与Hadoop集群建立连接" class="headerlink" title="与Hadoop集群建立连接"></a>与Hadoop集群建立连接</h3><p>点击Eclipse的Map/Reduce Locations面板在面板中单击右键，选择New Hadoop Location。<br><img src="/img/tuchuang/master/resource/2019-01/MapReduceLocation_1.png" alt="MapReduce location"><br>在弹出来的General选项面板中，General 的设置要与 Hadoop 的配置一致。一般两个 Host值是一样的。如果是在本机搭建hadoop伪分布式，填写 localhost 即可，这里使用的是Hadoop伪分布，DFS Master 的 Port 改为 9000。Map/Reduce(V2) Master 的 Port 用默认的即可，Location Name 随意填写。<br><img src="/img/tuchuang/master/resource/2019-01/MapReduceLocation_0.png" alt="MapReduce location"></p>
<h3 id="操作HDFS文件"><a href="#操作HDFS文件" class="headerlink" title="操作HDFS文件"></a>操作HDFS文件</h3><p>配置好后，点击Project Explorer 中的DFS Location就能直接查看 HDFS 中的文件列表，双击可以查看内容，右键点击可以上传、下载、删除 HDFS 中的文件。<br><img src="/img/tuchuang/master/resource/2019-01/ProjectExplorerHDFS.png" alt="HDFS"><br><img src="/img/tuchuang/master/resource/2019-01/HDFS_upload_download.png" alt="HDFS_upload_download"><br>当程序运行完成后，会生成一个output文件夹，通常运行完成后不能马上看到，此时可以尝试，右键点击DFS Locations后Reconnect或重启Eclipse。</p>
<h2 id="使用Eclipse实现WordCount"><a href="#使用Eclipse实现WordCount" class="headerlink" title="使用Eclipse实现WordCount"></a>使用Eclipse实现WordCount</h2><h3 id="Create-Project"><a href="#Create-Project" class="headerlink" title="Create Project"></a>Create Project</h3><p>点击File菜单,选择New-&gt;Project<br><img src="/img/tuchuang/master/resource/2019-01/newproject_wordCount.png" alt="new_project_wordcount"><br>选择MapReduce wizard，后点击next。<br><img src="/img/tuchuang/master/resource/2019-01/MapReduce_wizard.png" alt="mapreduce wizard"><br>Project Name随意填写，然后点finish。<br><img src="/img/tuchuang/master/resource/2019-01/new_mapreduce_project.png" alt="new mapreduce project"></p>
<h3 id="Create-WordCount-java"><a href="#Create-WordCount-java" class="headerlink" title="Create WordCount.java"></a>Create WordCount.java</h3><p>如普通Project一样，创建一个java程序后，复制如下代码。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.util.StringTokenizer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IntWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.util.GenericOptionsParser;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">WordCount</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">TokenizerMapper</span> <span class="keyword">extends</span> <span class="title">Mapper</span>&lt;<span class="title">Object</span>, <span class="title">Text</span>, <span class="title">Text</span>, <span class="title">IntWritable</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">		<span class="comment">/**</span></span><br><span class="line"><span class="comment">		 * LongWritable, IntWritable, Text 均是 Hadoop 中实现的用于封装 Java</span></span><br><span class="line"><span class="comment">		 * 数据类型的类，这些类实现了WritableComparable接口，</span></span><br><span class="line"><span class="comment">		 * 都能够被串行化从而便于在分布式环境中进行数据交换，你可以将它们分别视为long,int,String 的替代品。</span></span><br><span class="line"><span class="comment">		 */</span></span><br><span class="line">		<span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">static</span> IntWritable one = <span class="keyword">new</span> IntWritable(<span class="number">1</span>);  <span class="comment">// 值为1</span></span><br><span class="line">		<span class="keyword">private</span> Text word = <span class="keyword">new</span> Text();</span><br><span class="line"></span><br><span class="line">		<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(Object key, Text value, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">			StringTokenizer itr = <span class="keyword">new</span> StringTokenizer(value.toString());  <span class="comment">// 对字符串进行切分</span></span><br><span class="line">			<span class="keyword">while</span> (itr.hasMoreTokens()) &#123;</span><br><span class="line">				word.set(itr.nextToken());</span><br><span class="line">				context.write(word, one);  </span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">IntSumReducer</span> <span class="keyword">extends</span> <span class="title">Reducer</span>&lt;<span class="title">Text</span>, <span class="title">IntWritable</span>, <span class="title">Text</span>, <span class="title">IntWritable</span>&gt; </span>&#123;</span><br><span class="line">		<span class="keyword">private</span> IntWritable result = <span class="keyword">new</span> IntWritable();</span><br><span class="line"></span><br><span class="line">		<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">reduce</span><span class="params">(Text key, Iterable&lt;IntWritable&gt; values, Context context)</span></span></span><br><span class="line"><span class="function">				<span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">			<span class="keyword">int</span> sum = <span class="number">0</span>;</span><br><span class="line">			<span class="keyword">for</span> (IntWritable val : values) &#123;</span><br><span class="line">				sum += val.get();</span><br><span class="line">			&#125;</span><br><span class="line">			result.set(sum);</span><br><span class="line">			context.write(key, result);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">		Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line"><span class="comment">//		String[] otherArgs = new GenericOptionsParser(conf, args).getRemainingArgs();</span></span><br><span class="line">		String[] otherArgs = &#123;<span class="string">&quot;/input&quot;</span>, <span class="string">&quot;/output&quot;</span>&#125;;</span><br><span class="line">		<span class="keyword">if</span> (otherArgs.length != <span class="number">2</span>) &#123;</span><br><span class="line">			System.err.println(<span class="string">&quot;Usage: wordcount &lt;in&gt; &lt;out&gt;&quot;</span>);</span><br><span class="line">			System.exit(<span class="number">2</span>);</span><br><span class="line">		&#125;</span><br><span class="line">		Job job = <span class="keyword">new</span> Job(conf, <span class="string">&quot;word count&quot;</span>);</span><br><span class="line">		job.setJarByClass(WordCount.class);</span><br><span class="line">		job.setMapperClass(TokenizerMapper.class);</span><br><span class="line">		job.setCombinerClass(IntSumReducer.class);</span><br><span class="line">		job.setReducerClass(IntSumReducer.class);</span><br><span class="line">		job.setOutputKeyClass(Text.class);</span><br><span class="line">		job.setOutputValueClass(IntWritable.class);</span><br><span class="line">		FileInputFormat.setInputDirRecursive(job, <span class="keyword">true</span>);</span><br><span class="line">		FileInputFormat.addInputPath(job, <span class="keyword">new</span> Path(otherArgs[<span class="number">0</span>]));</span><br><span class="line">		FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> Path(otherArgs[<span class="number">1</span>]));</span><br><span class="line">		System.exit(job.waitForCompletion(<span class="keyword">true</span>) ? <span class="number">0</span> : <span class="number">1</span>);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="在Eclipse运行WordCount-java"><a href="#在Eclipse运行WordCount-java" class="headerlink" title="在Eclipse运行WordCount.java"></a>在Eclipse运行WordCount.java</h3><p>如前文所说，若要在hadoop上运行此project需要封装成jar包。若需要直接在Eclipse右键运行的话还需要做一下配置。<br>运行 MapReduce 程序前，务必将 <code>/usr/local/Cellar/hadoop/2.7.0/libexec/etc/hadoop</code> 中将有修改过的配置文件（如伪分布式需要core-site.xml 和 hdfs-site.xml），以及log4j.properties复制到WordCount 项目下的src文件夹（~/workspace/WordCount/src）中。如下图<br><img src="/img/tuchuang/master/resource/2019-01/wordcount_peizhiwenjian.png" alt="mapreduce 配置"></p>
<p>这是因为在使用 Eclipse 运行 MapReduce 程序时，会读取 Hadoop-Eclipse-Plugin 的Advanced parameters作为 Hadoop 运行参数，如果未进行修改，则默认的参数其实就是单机（非分布式）参数，因此程序运行时是读取本地目录而不是HDFS目录，就会提示Input路径不存在。报如下图错误<br><img src="/img/tuchuang/master/resource/2019-01/MapReduce_error.png" alt="word count error"><br>配置好以上文件后，就可以运行普通java程序一样右键run了，不同的是所输出的结果会出现的HDFS上，而输出路径及输入数据集的路径在在源代码中<code>String[] otherArgs</code>指定。<br><img src="/img/tuchuang/master/resource/2019-01/wordcount_output.png" alt="word count output"></p>
]]></content>
      <tags>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title>Hadoop排序</title>
    <url>/2019/02/18/Hadoop%E6%8E%92%E5%BA%8F/</url>
    <content><![CDATA[<h1 id="Hadoop排序"><a href="#Hadoop排序" class="headerlink" title="Hadoop排序"></a>Hadoop排序</h1><p><a href="https://zhuanlan.zhihu.com/p/43851100">转载来源</a></p>
<p>Hadoop排序，从大的范围来说有两种排序，一种是按照key排序，一种是按照value排序。如果按照value排序，只需在map函数中将key和value对调，然后在reduce函数中在对调回去。从小范围来说排序又分成部分排序，全局排序，辅助排序，二次排序等。本文介绍如何在Hadoop中实现全局排序。<br><span id="more"></span></p>
<p>全局排序，就是说在一个MapReduce程序产生的输出文件中，所有的结果都是按照某个策略进行排序的，例如降序还是升序。MapReduce只能保证一个分区内的数据是key有序的，一个分区对应一个reduce，因此只有一个reduce就保证了数据全局有序，但是这样又不能用到Hadoop集群的优势。</p>
<p>对于多个reduce如何保证数据的全局排序呢？通常的做法是按照key值分区，通过MapReduce的默认分区函数HashPartition将不同范围的key发送到不同的reduce处理，例如一个文件中有key值从1到10000的数据，我们使用两个分区，将1到5000的key发送到partition1，然后由reduce1处理，5001到10000的key发动到partition2然后由reduce2处理，reduce1中的key是按照1到5000的升序排序，reduce2中的key是按照5001到10000的升序排序，这样就保证了整个MapReduce程序的全局排序。但是这样做有两个缺点：</p>
<p>1、当数据量大时会出现OOM。</p>
<p>2、会出现数据倾斜。</p>
<p>Hadoop提供TotalOrderPartitioner类用于实现全局排序的功能，并且解决了OOM和数据倾斜的问题。</p>
<p>TotalOrderPartitioner类提供了数据采样器，对key值进行部分采样，然后按照采样结果寻找key值的最佳分割点，将key值均匀的分配到不同的分区中。</p>
<p>TotalOrderPartitioner 类提供了三个采样器，分别是：</p>
<ul>
<li>SplitSampler 分片采样器，从数据分片中采样数据，该采样器不适合已经排好序的数据</li>
<li>RandomSampler随机采样器，按照设置好的采样率从一个数据集中采样</li>
<li>IntervalSampler间隔采样机，以固定的间隔从分片中采样数据，对于已经排好序的数据效果非常好。</li>
</ul>
<p>三个采样器都实现了K[] getSample(InputFormat&lt;K,V&gt; inf, Job job)方法，该方法返回的是K[]数组，数组中存放的是根据采样结果返回的key值，即分隔点，MapRdeuce就是根据K[]数组的长度N生成N-1个分区partition数量，然后按照分割点的范围将对应的数据发送到对应的分区中。</p>
]]></content>
      <tags>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title>Hive 2.3.4 安裝及配置</title>
    <url>/2019/03/04/Hive%202.3.4%E5%AE%89%E8%A3%9D%E5%8F%8A%E9%85%8D%E7%BD%AE/</url>
    <content><![CDATA[<p>Hive是一个数据仓库基础工具在Hadoop中用来处理结构化数据。它架构在Hadoop之上，总归为大数据，并使得查询和分析方便。并提供简单的sql查询功能，可以将sql语句转换为MapReduce任务进行运行。<br><img src="/img/tuchuang/master/resource/2019-03/hiveLogo.png" alt="HIVE"><br><span id="more"></span></p>
<h2 id="前期工作"><a href="#前期工作" class="headerlink" title="前期工作"></a>前期工作</h2><ul>
<li><p>安装JDK</p>
</li>
<li><p>安装Hadoop</p>
</li>
<li><p>安装MySQL</p>
</li>
</ul>
<h2 id="下载并安装Hive"><a href="#下载并安装Hive" class="headerlink" title="下载并安装Hive"></a>下载并安装Hive</h2><h3 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h3><p>Hive<a href="http://apache.website-solution.net/hive/">下载地址</a>及<a href="https://hive.apache.org/index.html">官网</a>。</p>
<p>选择<strong>apache-hive-2.3.4-bin.tar.gz</strong>进行下载。</p>
<h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><p>将压缩包复制至想要的安装位置，我的做法是复制到跟hadoop安装的同一个目录下。<br><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">sudo mv apache-hive-2.1.1-bin.tar.gz /usr/<span class="built_in">local</span>/Cellar/hadoop</span><br><span class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span>/Cellar/hadoop</span><br><span class="line">sudo tar -xzvf apache-hive-2.3.4-bin.tar.gz    <span class="comment">##解压</span></span><br></pre></td></tr></table></figure></p>
<h3 id="设置系统环境变量"><a href="#设置系统环境变量" class="headerlink" title="设置系统环境变量"></a>设置系统环境变量</h3><p>编辑bash_profile文件 <code>vi .bash_profile</code>。<br>添加以下内容。<br><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Hive</span></span><br><span class="line"><span class="built_in">export</span> HIVE_HOME=/usr/<span class="built_in">local</span>/Cellar/hadoop/apache-hive-2.3.4-bin</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$HIVE_HOME</span>/bin</span><br></pre></td></tr></table></figure><br>使环境变量生效: <code>source .bash_profile</code></p>
<h3 id="配置文件hive-site-xml"><a href="#配置文件hive-site-xml" class="headerlink" title="配置文件hive.site.xml"></a>配置文件hive.site.xml</h3><p>进入<code>Hive/conf</code>文件夹 复制示例配置文件并改名为<code>hive.site.xml</code><br><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">cp hive-default.xml.template hive-site.xml</span><br></pre></td></tr></table></figure><br>在开头添加如下配置。<br><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">name</span>&gt;</span>system:java.io.tmpdir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">value</span>&gt;</span>/tmp/hive/java<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">name</span>&gt;</span>system:user.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">value</span>&gt;</span>$&#123;user.name&#125;<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<h2 id="创建及配置HDFS文件夹"><a href="#创建及配置HDFS文件夹" class="headerlink" title="创建及配置HDFS文件夹"></a>创建及配置HDFS文件夹</h2><h3 id="创建"><a href="#创建" class="headerlink" title="创建"></a>创建</h3><p>在 Hive 中创建表之前需要创建以下 HDFS 目录并给它们赋相应的权限。</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">hdfs dfs -mkdir -p /user/hive/warehouse</span><br><span class="line">hdfs dfs -mkdir -p /user/hive/tmp</span><br><span class="line">hdfs dfs -mkdir -p /user/hive/<span class="built_in">log</span></span><br><span class="line">hdfs dfs -chmod 777 /user/hive/warehouse</span><br><span class="line">hdfs dfs -chmod 777 /usr/hive/tmp</span><br><span class="line">hdfs dfs -chmod 777 /usr/hive/<span class="built_in">log</span></span><br></pre></td></tr></table></figure>
<p>创建完成后可以使用<code>hdfs dfs -ls /hive</code>查看是否已经成功新建文件夹。</p>
<h3 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h3><p>打开刚刚准备好的<strong>hive-site.xml</strong>配置文件，把刚刚新建的HDFS文件夹的路径添加到配置文件中去。<br><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.exec.scratchdir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hive/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>HDFS root scratch dir for Hive jobs which gets created with write all (733) permission. For each connecting user, an HDFS scratch dir: $&#123;hive.exec.scratchdir&#125;/<span class="symbol">&amp;lt;</span>username<span class="symbol">&amp;gt;</span> is created, with $&#123;hive.scratch.dir.permission&#125;.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.warehouse.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/hive/warehouse<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>location of default database for the warehouse<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.querylog.location<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/hive/log<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>Location of Hive run time structured log file<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<h2 id="创建及配置Mysql"><a href="#创建及配置Mysql" class="headerlink" title="创建及配置Mysql"></a>创建及配置Mysql</h2><h3 id="创建Hive数据库"><a href="#创建Hive数据库" class="headerlink" title="创建Hive数据库"></a>创建Hive数据库</h3><p>假定你已经安装好MySQL。下面需要创建一个 hive 数据库用来存储 Hive 元数据</p>
<p>打开Mysql服务，并以root用户登入。<br><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">mysql.server start</span><br><span class="line">mysql -u root -p <span class="comment"># 回车后输入密码 若无密码则使用 mysql -u root</span></span><br></pre></td></tr></table></figure></p>
<h3 id="创建用户名"><a href="#创建用户名" class="headerlink" title="创建用户名"></a>创建用户名</h3><p>进入mysql后，创建一个 hive 数据库用来存储 Hive 元数据，且数据库访问的用户名和密码都为hadoop。<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">CREATE DATABASE hive; </span><br><span class="line">USE hive; </span><br><span class="line">CREATE USER &#x27;hadoop&#x27;@&#x27;localhost&#x27; IDENTIFIED BY &#x27;hadoop&#x27;;</span><br><span class="line">GRANT ALL ON hive.* TO &#x27;hive&#x27;@&#x27;localhost&#x27; IDENTIFIED BY &#x27;hadoop&#x27;; </span><br><span class="line">GRANT ALL ON hive.* TO &#x27;hive&#x27;@&#x27;%&#x27; IDENTIFIED BY &#x27;hadoop&#x27;; </span><br><span class="line">FLUSH PRIVILEGES; </span><br><span class="line">quit;</span><br></pre></td></tr></table></figure></p>
<h3 id="配置-1"><a href="#配置-1" class="headerlink" title="配置"></a>配置</h3><p>将刚刚创建的数据库及用户名和密码写入配置文件。<br><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionURL<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>jdbc:mysql://localhost:3306/hive?createDatabaseIfNotExist=true<span class="symbol">&amp;amp;</span>characterEncoding=UTF-8<span class="symbol">&amp;amp;</span>useSSL=false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionDriverName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>com.mysql.jdbc.Driver<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionUserName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionPassword<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<h3 id="配置JDBC"><a href="#配置JDBC" class="headerlink" title="配置JDBC"></a>配置JDBC</h3><p>由于需要使用Java连接Mysql数据库，所以需要配置MySQL Connector。我这里使用的是mysql-connector-java-5.1.39-bin版本<a href="/img/tuchuang/master/resource/2019-03/mysql-connector-java-5.1.39-bin.jar">下载地址</a>。并将它复制进 <code>$HIVE_HOME/lib</code>路径下</p>
<h2 id="启动及测试"><a href="#启动及测试" class="headerlink" title="启动及测试"></a>启动及测试</h2><h3 id="启动HDFS"><a href="#启动HDFS" class="headerlink" title="启动HDFS"></a>启动HDFS</h3><p>使用Hive之前，请先确保HDFS已经启动。可以使用<code>start-dfs.sh</code>脚本来启动 HDFS。</p>
<h3 id="Mysql初始化"><a href="#Mysql初始化" class="headerlink" title="Mysql初始化"></a>Mysql初始化</h3><p>从 Hive 2.1 版本开始, 我们需要先运行 schematool 命令来执行初始化操作。<br><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">schematool -dbType mysql -initSchema</span><br></pre></td></tr></table></figure><br>运行后终端将会显示如下信息<br><img src="/img/tuchuang/master/resource/2019-03/schematool_show.png" alt="schematool result show"></p>
<h3 id="使用Hive-CLI"><a href="#使用Hive-CLI" class="headerlink" title="使用Hive CLI"></a>使用Hive CLI</h3><p>要使用 Hive CLI（Hive command line interface）, 可以在终端输入<code>Hive</code>，便可以进入。<br>启动信息如下：<br><img src="/img/tuchuang/master/resource/2019-03/hive_cli.png" alt="hive cli start message"><br>创建一个table<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">CREATE TABLE pokes (foo INT, bar STRING);</span><br></pre></td></tr></table></figure><br>show tables和desc pokes 显示信息如下<br><img src="/img/tuchuang/master/resource/2019-03/showtabledescpokes.png" alt="show tables and desc pokes message"><br>在HDFS中显示如下<br><img src="/img/tuchuang/master/resource/2019-03/HIVE_show_in_hdfs.png" alt="show in hdfs"></p>
]]></content>
      <tags>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title>HMM+Vetebi算法实现词性标注 python实现</title>
    <url>/2016/10/30/HMM-Vetebi%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0%E8%AF%8D%E6%80%A7%E6%A0%87%E6%B3%A8-python%E5%AE%9E%E7%8E%B0/</url>
    <content><![CDATA[<p>　　隐马尔可夫模型（Hidden Markov Model，HMM）是统计模型，它用来描述一个含有隐含未知参数的马尔可夫过程。其难点是从可观察的参数中确定该过程的隐含参数。然后利用这些参数来作进一步的分析，例如模式识别。<br>　　在正常的马尔可夫模型中，状态对于观察者来说是直接可见的。这样状态的转换概率便是全部的参数。而在隐马尔可夫模型中,状态并不是直接可见的，但受状态影响的某些变量则是可见的。每一个状态在可能输出的符号上都有一概率分布。因此输出符号的序列能够透露出状态序列的一些信息。<br><span id="more"></span></p>
<h2 id="马尔科夫模型-（Markov-Model，HMM）"><a href="#马尔科夫模型-（Markov-Model，HMM）" class="headerlink" title="马尔科夫模型 （Markov Model，HMM）"></a>马尔科夫模型 （Markov Model，HMM）</h2><p>　　在考虑隐马尔科夫模型之前，我们首先要了解马尔可夫模型。马尔可夫模型描述了一类重要的随机过程，这个随机过程是随时间而随机变化的过程。我们常会考虑一个并不互相独立的随机变量组成的序列，序列中每个变量的值依赖于它前面的元素。简单来说：<br>　　<img src="/img/tuchuang/master/graph/%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E5%85%AC%E5%BC%8F.png" alt="马尔科夫公式"><br>　　<strong>即在特定条件下，系统在时间t的状态只与其在时间t-1的状态相关该随机过程称为一阶马尔可夫过程。</strong></p>
<h2 id="隐马尔科夫模型（Hidden-Markov-Model，HMM）"><a href="#隐马尔科夫模型（Hidden-Markov-Model，HMM）" class="headerlink" title="隐马尔科夫模型（Hidden Markov Model，HMM）"></a>隐马尔科夫模型（Hidden Markov Model，HMM）</h2><p>　　如果知道某个事件的观察序列，是可以使用一个马尔可夫模型来计算；但是，有时候有些事件是不可以直接观测到的。例如，本篇博文要讲的词性标注这个例子：<br>　　字串(可观察序列)：　结合　　/　　成　　/　　分子　　/　　时<br>　　字的词性(隐序列)：　vn,v　/ 　v,nr,q,a,an,j　/　 n　/ 　Ng,nr,Dg　/<br>　　<strong>HMM就是估算隐藏于表面事件背后的事件的概率。</strong><br>　　<img src="/img/tuchuang/master/graph/HMM%E5%85%AC%E5%BC%8F.png" alt="HMM公式"></p>
<h3 id="转移概率矩阵"><a href="#转移概率矩阵" class="headerlink" title="转移概率矩阵"></a>转移概率矩阵</h3><p>　　转移概率指的是估计的事件的序列之间的概率关系，上诉例子中，我们所需要的转移概率为P(v|vn)p(v|v)…P(v|n)表示前一个词的词性是名词，则这个词为动词的概率。通过训练集的统计我们可以统计得出转移概率矩阵。即词性转移矩阵：</p>
<table>
<thead>
<tr>
<th style="text-align:center"></th>
<th style="text-align:center">v</th>
<th style="text-align:center">n</th>
<th style="text-align:center">s</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">ｖ</td>
<td style="text-align:center">0.5</td>
<td style="text-align:center">0.375</td>
<td style="text-align:center">0.125</td>
</tr>
<tr>
<td style="text-align:center">ｎ</td>
<td style="text-align:center">0.25</td>
<td style="text-align:center">0.125</td>
<td style="text-align:center">0.625</td>
</tr>
<tr>
<td style="text-align:center">ｓ</td>
<td style="text-align:center">0.25</td>
<td style="text-align:center">0.375</td>
<td style="text-align:center">0.375</td>
</tr>
</tbody>
</table>
<p>　　</p>
<h3 id="发射概率矩阵"><a href="#发射概率矩阵" class="headerlink" title="发射概率矩阵"></a>发射概率矩阵</h3><p>　　发射概率指的是，隐藏序列和可观察序列之间的概率关系，上述例子中，我们需要的发射概率为P(结合｜v)…表示“结合”这个词为动词的概率。通过训练集的统计，我们同样也能够得出发射概率矩阵：</p>
<table>
<thead>
<tr>
<th style="text-align:center"></th>
<th style="text-align:center">v</th>
<th style="text-align:center">n</th>
<th style="text-align:center">s</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">结合</td>
<td style="text-align:center">0.5</td>
<td style="text-align:center">0.375</td>
<td style="text-align:center">0.125</td>
</tr>
<tr>
<td style="text-align:center">成</td>
<td style="text-align:center">0.25</td>
<td style="text-align:center">0.125</td>
<td style="text-align:center">0.625</td>
</tr>
<tr>
<td style="text-align:center">分子</td>
<td style="text-align:center">0.25</td>
<td style="text-align:center">0.375</td>
<td style="text-align:center">0.375</td>
</tr>
<tr>
<td style="text-align:center">时</td>
<td style="text-align:center">0.25</td>
<td style="text-align:center">0.375</td>
<td style="text-align:center">0.375</td>
</tr>
</tbody>
</table>
<p><em>ps 上面矩阵的数据都是乱写的</em></p>
<h3 id="计算观测序列的概率"><a href="#计算观测序列的概率" class="headerlink" title="计算观测序列的概率"></a>计算观测序列的概率</h3><p>　　有了转移矩阵和概率矩阵，我们终于可以来预测句子中每个词的词性。最直接易懂的方法便是穷举法，我们通过求每个词每个词性每种情况的概率，取最大的概率作为我们预测的词性标注。<br>　　例如上述例子：<br>　　<strong>字串</strong>：　结合　　/　　成　　/　　分子　　/　　时<br>　　<strong>字的词性</strong>：　vn,v　/ 　v,nr,q,a,an,j　/　 n　/ 　Ng,nr,Dg　/<br>　　第一种可能的词性序列是：vn,v,n,Ng<br>　　即:<br>　　P(结合,成,分子,时,vn,v,n,Ng)<br>　=p(结合|vn)×p(成|v)×p(分子|n)×p(时|Ng)×p(vn|start)×p(v|vn)×p(n|v)×p(Ng|n)
　</p>
<h2 id="Vetebi算法"><a href="#Vetebi算法" class="headerlink" title="Vetebi算法"></a>Vetebi算法</h2><p>　　如果直接使用上述的穷举法去寻找最优的概率，毋庸置疑该算法的复杂度是相当复杂的，例如上述例子仅有４个词却总共有36种情况需要考虑，也就是说我们需要分别计算36种情况的概率，然后取最大值作为我们的预测结果。那么我们有没有什么可以简化的方法吗？<br>　　因此在算法优化上，我们可以引用维特比算法(Vetebi)。维特比算法是现代数字通信中使用最频繁的算法，同时也是很多自然语言处理的解码算法。<br>　　算法描述：依据最后一个时刻中概率最高的状态，逆向通过找其路径中的上一个最大部分最优路径，从而找到整个最优路径。<br>　　<img src="/img/tuchuang/master/graph/%E9%83%A8%E5%88%86%E6%9C%80%E4%BC%98%E8%B7%AF%E5%BE%84.png" alt="部分最优路径"><br>　　vt(j)是所有序列中在t时刻以状态j终止的最大概率,所对应的路径为部分最优路径。</p>
<p><strong>实例</strong><br>　　还是以“结合　成　分子　时”为例子，在计算概率的途中，我们可以理解为不断寻找最优解的过程。<br>　　我们可以首先考虑“结合 成”这2个词的词性计算词性概率，对于“成”的6个词性分别都有一个最大的概率和对应的前置词性如图所示：<br>　　<img src="/img/tuchuang/master/graph/vetebi_1.png" alt="Vetebi_1"><br>　　接着考虑“分子”的词性为n，它的最优前置词性为an，如图所示：<br>　　<img src="/img/tuchuang/master/graph/Vetebi_2.jpg" alt="Vetebi_2"><br>　　最后考虑“时”的词性Ng,nr,Dg，分别计算得最后的概率为0.1，0.2，0.3；如图所示：<br>　　<img src="/img/tuchuang/master/graph/Vetebi_3.jpg" alt="Vetebi_3"><br>　　取最大概率Dg为0.3，从后往前将全局最优路径导出，如图所示：<br>　　<img src="/img/tuchuang/master/graph/Vetebi_4.jpg" alt="Vetebi_4"><br>　　最后我们可以得出最终结果: 结合/v; 成/an; 分子/n; 时/Dg
　　</p>
<h3 id="python代码实现"><a href="#python代码实现" class="headerlink" title="python代码实现"></a>python代码实现</h3><p>核心代码<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">hmm</span>(<span class="params">self, sentence_list</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    :param sentence_list: 已分好词的句子列表</span></span><br><span class="line"><span class="string">    :return: 对应每个词的词性列表</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    sentence_list = <span class="built_in">list</span>(sentence_list)</span><br><span class="line">    sentence_len = sentence_list.__len__()  <span class="comment"># 句子长度</span></span><br><span class="line">    cixin_len = self.cixin_list.__len__()  <span class="comment"># 词性个数</span></span><br><span class="line">    <span class="comment"># 概率分布表 .[i, j, 0]表示第i个词为第j个词性的最优概率;.[i, j, 1]表示该最优概率的前一个词的词性索引,若为-1表示该词为第一个词无前词</span></span><br><span class="line">    pro_table = np.zeros((sentence_len, cixin_len, <span class="number">2</span>))</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        pro_table[<span class="number">0</span>, :, <span class="number">0</span>] = self.emitter_pro_matrix[self.vocab_map[sentence_list[<span class="number">0</span>]]]</span><br><span class="line">        pro_table[<span class="number">0</span>, :, <span class="number">1</span>] = -<span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(sentence_len)[<span class="number">1</span>:]:</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(cixin_len):</span><br><span class="line">                <span class="keyword">if</span> self.emitter_pro_matrix[self.vocab_map[sentence_list[i]], j] == <span class="number">0</span>:</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">                pre_cixin_pro = pro_table[i-<span class="number">1</span>, :, <span class="number">0</span>]</span><br><span class="line">                pre_cixin_pro *= self.trans_pro_matrix[j]</span><br><span class="line">                pre_cixin_pro *= self.emitter_pro_matrix[self.vocab_map[sentence_list[i]], j]</span><br><span class="line">                pro_table[i, j, <span class="number">0</span>] = np.<span class="built_in">max</span>(pre_cixin_pro)</span><br><span class="line">                pro_table[i, j, <span class="number">1</span>] = np.where(pre_cixin_pro == np.<span class="built_in">max</span>(pre_cixin_pro))[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line">        result_cixin_map = []</span><br><span class="line">        sy = <span class="built_in">int</span>(np.where(pro_table[-<span class="number">1</span>, :, <span class="number">0</span>] == np.<span class="built_in">max</span>(pro_table[-<span class="number">1</span>, :, <span class="number">0</span>]))[<span class="number">0</span>][<span class="number">0</span>])</span><br><span class="line">        t = -<span class="number">1</span></span><br><span class="line">    <span class="keyword">except</span> KeyError:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;无法正常运行 有词语不存在词库之中&quot;</span></span><br><span class="line">    <span class="keyword">while</span> sy != -<span class="number">1</span>:</span><br><span class="line">        result_cixin_map.append(sy)</span><br><span class="line">        sy = <span class="built_in">int</span>(pro_table[t, sy, <span class="number">1</span>])</span><br><span class="line">        t -= <span class="number">1</span></span><br><span class="line">    result_cixin = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> s <span class="keyword">in</span> result_cixin_map[::-<span class="number">1</span>]:</span><br><span class="line">        result_cixin.append(self.cixin_list[s])</span><br><span class="line">    <span class="keyword">return</span> result_cixin</span><br></pre></td></tr></table></figure></p>
<p>完整代码及数据<a href="https://github.com/Hareric/Natural-Language-Processing/tree/master/HMM">下载</a></p>
<p>　　
　　
　　
　　</p>
]]></content>
      <tags>
        <tag>NLP</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>Java细节知识点整理</title>
    <url>/2016/06/27/Java%E7%BB%86%E8%8A%82%E7%9F%A5%E8%AF%86%E7%82%B9/</url>
    <content><![CDATA[<p>上学期Java期末考试前整理的一些不怎么会注意到的细节知识点，结果考试考的挺实在的，基本没有用到。不过既然整理了就发出来吧。<br><span id="more"></span></p>
<h4 id="数值数据类型"><a href="#数值数据类型" class="headerlink" title="数值数据类型"></a><strong>数值数据类型</strong></h4><pre><code>整数
byte 8位带符号数 
short 16位带符号数
int 32位带符号数
long 64位带符号数
浮点数
float 32位，标准IEEE754，单精度
double 64位，标准IEEE754，双精度
</code></pre><h4 id="char和string"><a href="#char和string" class="headerlink" title="char和string"></a><strong>char和string</strong></h4><pre><code>char letter = &apos;a&apos;;
String s = &quot;a&quot;;
&apos;a&apos;是一个字符
&quot;A&quot;是字符串
</code></pre><h4 id="特殊字符转义序列"><a href="#特殊字符转义序列" class="headerlink" title="特殊字符转义序列"></a><strong>特殊字符转义序列</strong></h4><pre><code>\b 退格键
\t Tab键
\n 换行符号
\f 换页
\r 回车键
\\\ 反斜杠
\&apos; 单引号
\&quot; 双引号
</code></pre><h4 id="简易GUI界面"><a href="#简易GUI界面" class="headerlink" title="简易GUI界面"></a><strong>简易GUI界面</strong></h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import javax.swing.JOptionPane;</span><br><span class="line">//接收字符串GUI界面</span><br><span class="line">String s = JOptionPane.showInputDialoge(&quot;Please enter an input&quot;,&quot;Title&quot;,JOptionPane.QUESTION_MESSAGE);</span><br><span class="line">//选择是否的GUI界面</span><br><span class="line">int a = JOptionPane.showConfirmDialog(null,&quot;Continue&quot;);</span><br><span class="line">    /*</span><br><span class="line">    JOptionPane.YES_OPTION = 0</span><br><span class="line">    JOptionPane.NO_OPTION = 1</span><br><span class="line">    JOptionPane.CANCEL_OPTION = 2</span><br><span class="line">    */</span><br><span class="line">//显示信息的GUI界面</span><br><span class="line">JOptionPane.showMessageDialog(null,&quot;The Message!&quot;);</span><br></pre></td></tr></table></figure>
<h4 id="字符串转化为数字"><a href="#字符串转化为数字" class="headerlink" title="字符串转化为数字"></a><strong>字符串转化为数字</strong></h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">int intValue = Integer.parseInt(intString);</span><br><span class="line">double doubleValue = Double.parseDouble(doubleString);</span><br><span class="line">long longValue = Long.parseLong(longString);</span><br><span class="line">byte byteValue = Byte.parseByte(byteString);</span><br><span class="line">short shortValue = Short.parseShort(shortString);</span><br></pre></td></tr></table></figure>
<h4 id="数字转化为字符串"><a href="#数字转化为字符串" class="headerlink" title="数字转化为字符串"></a><strong>数字转化为字符串</strong></h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">String.valueOf();//各种类型的变量都可以用这个方法转化</span><br></pre></td></tr></table></figure>
<h4 id="switch用法"><a href="#switch用法" class="headerlink" title="switch用法"></a><strong>switch用法</strong></h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">char ch = &#x27;a&#x27;;</span><br><span class="line">switch(ch)</span><br><span class="line">&#123;</span><br><span class="line">    case &#x27;a&#x27;:System.out.print(ch);</span><br><span class="line">    case &#x27;b&#x27;:System.out.print(ch);</span><br><span class="line">    case &#x27;c&#x27;:System.out.print(ch);</span><br><span class="line">    default:System.out.print(ch);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>运行结果为：aaaa</p>
<h4 id="三元运算符"><a href="#三元运算符" class="headerlink" title="三元运算符"></a><strong>三元运算符</strong></h4><pre><code>y = (x &gt; 0) ? 1 : -1
</code></pre><h4 id="格式化输出"><a href="#格式化输出" class="headerlink" title="格式化输出"></a><strong>格式化输出</strong></h4><pre><code>常用的标识符
%b 布尔值
%c 字符
%d 十进制整数
%f 浮点数
%e 标准科学计数法
%s 字符串
指定宽度和精度
%5c 指定宽度为5
%6b 指定宽度为6
%10.2f 指定宽度为10 精度为2
</code></pre><h4 id="浮点数来控制循环"><a href="#浮点数来控制循环" class="headerlink" title="浮点数来控制循环"></a><strong>浮点数来控制循环</strong></h4><p>不要使用浮点数来控制循环，因为浮点数通常是用近似值表示的，无法得到像整数一样精确的值，比如以下循环是无限循环<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">double</span> item = <span class="number">1</span>;</span><br><span class="line"><span class="keyword">double</span> sum = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">while</span>(item != <span class="number">0</span>)</span><br><span class="line">&#123;</span><br><span class="line">    sum += item;</span><br><span class="line">    item -= <span class="number">0.1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h4 id="输入和输出重定向"><a href="#输入和输出重定向" class="headerlink" title="输入和输出重定向"></a><strong>输入和输出重定向</strong></h4><pre><code>在终端运行java程序时，可以通过文本文件完成输入和输出
java MyClass &lt; input.txt  通过txt输入数据
java MyClass &gt; output.txt  将运行结果输出到txt
java MyClass &lt; input.txt &gt; output.txt 也可连用
</code></pre><h4 id="for循环"><a href="#for循环" class="headerlink" title="for循环"></a><strong>for循环</strong></h4><pre><code>for( ; ; ) 等价 for( ;true; ) 等价 whlie(true)
</code></pre><h4 id="最小化数值误差"><a href="#最小化数值误差" class="headerlink" title="最小化数值误差"></a><strong>最小化数值误差</strong></h4><p>涉及浮点数的数值误差是不可避免的，如：计算0.01到1.0的数列之和<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">double</span> sum = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">double</span> i = <span class="number">0.01</span>;i &lt;= <span class="number">1.0</span>;i += <span class="number">0.01</span>) </span><br><span class="line">    sum += i;       </span><br><span class="line">System.out.println(sum);<span class="comment">//结果为49.50000000000003，（精确结果应为50.50)</span></span><br></pre></td></tr></table></figure><br>在大数之前先加小数是减小误差的方法，因为例如，100000000.0+0.00000001的精确结果是100000000.0<br>所以在本例中，以（0.01，0.02。。。0.99，1.0）的顺序求和，结果会更精确</p>
<h4 id="蒙特卡罗模拟"><a href="#蒙特卡罗模拟" class="headerlink" title="蒙特卡罗模拟"></a><strong>蒙特卡罗模拟</strong></h4><p>利用随机数和概率解决问题<br>例如：求π<br>（1）随机生成正方形内的一点（2）计算落入内接圆的概率，从而求得PI。<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> inNum = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">int</span> testNum = <span class="number">10000000</span>;<span class="comment">//测试的次数</span></span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;testNum;i++)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">double</span> x = Math.random();</span><br><span class="line">    <span class="keyword">double</span> y = Math.random();</span><br><span class="line">    <span class="keyword">if</span>(Math.sqrt( (Math.pow(x-<span class="number">0.5</span>,<span class="number">2</span>) + Math.pow(y-<span class="number">0.5</span>,<span class="number">2</span>)) ) &lt;<span class="number">0.5</span>)<span class="comment">//记录在圆内的个数</span></span><br><span class="line">        inNum++;</span><br><span class="line"> &#125;</span><br><span class="line">System.out.println(<span class="string">&quot;PI = &quot;</span> + inNum*<span class="number">4</span>/(<span class="keyword">double</span>)testNum);</span><br></pre></td></tr></table></figure></p>
<h4 id="方法的重载"><a href="#方法的重载" class="headerlink" title="方法的重载"></a><strong>方法的重载</strong></h4><p>被重载的方法必须具有不同的参数列表。不能基于不同修饰符号或返回值类型来重载方法，但并不意味着不能修改修饰符号或返回值。例如下面这个例子。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">m1</span><span class="params">(<span class="keyword">int</span> x)</span></span>&#123;&#125;</span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">int</span> <span class="title">m1</span><span class="params">(<span class="keyword">int</span> x,<span class="keyword">int</span> y)</span></span>&#123;<span class="keyword">return</span> <span class="number">12</span>;&#125;</span><br><span class="line"><span class="comment">//public String m1(int x)&#123;return &quot;12&quot;;&#125; //error!Duplicate method m1(int)</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>有时调用重载的方法时，会有多个匹配，此时会产生歧义调用的错误</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="keyword">double</span> m = max(<span class="number">1</span>,<span class="number">2</span>); <span class="comment">//error 无法识别与哪个方法匹配</span></span><br><span class="line">&#125;;</span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">double</span> <span class="title">max</span><span class="params">(<span class="keyword">int</span> num1,<span class="keyword">double</span> num2)</span></span>&#123;&#125;;</span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">double</span> <span class="title">max</span><span class="params">(<span class="keyword">double</span> num1,<span class="keyword">double</span> num2)</span></span>&#123;&#125;;</span><br></pre></td></tr></table></figure>
<h4 id="声明数组的方法"><a href="#声明数组的方法" class="headerlink" title="声明数组的方法"></a><strong>声明数组的方法</strong></h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">elementType[] arrayRefVar = <span class="keyword">new</span> elementType[arraySize];</span><br><span class="line">elementType arrayRefVar[] = <span class="keyword">new</span> elementType[arraySize];</span><br><span class="line">elementType arrayRefVar[] = &#123;,,,&#125;;</span><br></pre></td></tr></table></figure>
<p><strong>与类的实例化不同，分开写会报错，如</strong><br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">double</span>[] myList;</span><br><span class="line">myList = &#123;<span class="number">1.9</span>,<span class="number">2.9</span>,<span class="number">3.4</span>&#125;;<span class="comment">//error</span></span><br></pre></td></tr></table></figure></p>
<h4 id="char"><a href="#char" class="headerlink" title="char[]"></a><strong>char[]</strong></h4><p>对于char[]类型的数组，可以用一条语句打印。<br>如：<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">char</span>[] city = &#123;<span class="string">&#x27;D&#x27;</span>,<span class="string">&#x27;a&#x27;</span>,<span class="string">&#x27;l&#x27;</span>,<span class="string">&#x27;l&#x27;</span>,<span class="string">&#x27;a&#x27;</span>,<span class="string">&#x27;s&#x27;</span>&#125;;</span><br><span class="line">System.out.print(city);</span><br></pre></td></tr></table></figure></p>
<h4 id="for-each循环"><a href="#for-each循环" class="headerlink" title="for-each循环"></a><strong>for-each</strong>循环</h4><p>针对数组使用的循环<br>    for(double u : myList){}</p>
<h4 id="数组复制"><a href="#数组复制" class="headerlink" title="数组复制"></a><strong>数组复制</strong></h4><p>list2 = list1;<br>该语句并不能将list1复制到list2，只会将数组list1的引用传递给list2<br>复制数组的方法：<br>1) 使用循环逐个复制数组的元素。<br>2) 使用System类中的静态方法arraycopy(注意:该方法违背了Java的命名习惯)</p>
<pre><code>System.arraycopy(sourseArray, src_pos, targetArray, tar_pos, length);
</code></pre><p>3) 使用clone方法复制数组 </p>
<h4 id="匿名数组"><a href="#匿名数组" class="headerlink" title="匿名数组"></a><strong>匿名数组</strong></h4><pre><code>new int[]&#123;3,1,2,3,1&#125;
</code></pre><p>没有变量名显式地引用变量,这样的数组称为匿名数组</p>
<h4 id="方法传递数组"><a href="#方法传递数组" class="headerlink" title="方法传递数组"></a><strong>方法传递数组</strong></h4><p>对于数组类型的参数,参数值是数组的引用,给方法传递的是这个引用.<br>例:<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">public static void main(String arguments[])&#123;    </span><br><span class="line">    int[] as = &#123;1,2,3&#125;;</span><br><span class="line">    m(as);</span><br><span class="line">    System.out.println(as[0]);  //输出为100</span><br><span class="line">&#125;</span><br><span class="line">public static void m(int[] array)&#123;</span><br><span class="line">    array[0] = 100;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>array虽然是参数,却成功修改了as[0]的值</p>
<h4 id="可变长参数列表"><a href="#可变长参数列表" class="headerlink" title="可变长参数列表"></a><strong>可变长参数列表</strong></h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">public static void main()&#123;</span><br><span class="line">    m(1.2);</span><br><span class="line">    m(new double[]&#123;1,232,1.2&#125;);</span><br><span class="line">&#125;</span><br><span class="line">public static void m(double... numbers)&#123;&#125;</span><br></pre></td></tr></table></figure>
<p>numbers是可变长参数,所以既可以传double类型的数或者double类型的数组</p>
<h4 id="Arrays类"><a href="#Arrays类" class="headerlink" title="Arrays类"></a><strong>Arrays类</strong></h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">java.util.Arrays.sort(array);<span class="comment">//Sort the whole array</span></span><br><span class="line">java.util.Arrays.sort(array,<span class="number">1</span>,<span class="number">3</span>);<span class="comment">//Sort part of array</span></span><br><span class="line">java.util.Arrays.binarySearch(list,<span class="number">12</span>);<span class="comment">//利用二分法查找列表中某个元素的位置,列表必须排好序</span></span><br><span class="line">java.util.Arrays.fill(list1,<span class="number">5</span>);<span class="comment">//Fill 5 to the whole array</span></span><br><span class="line">java.util.Arrays.fill(list1,<span class="number">1</span>,<span class="number">3</span>,<span class="number">8</span>);<span class="comment">//Fill 8 to a partial array</span></span><br><span class="line">java.util.Arrays.equals(list1,list2);<span class="comment">//判断列表1和列表2的内容是否相同</span></span><br></pre></td></tr></table></figure>
<h4 id="二维数组构建"><a href="#二维数组构建" class="headerlink" title="二维数组构建"></a><strong>二维数组构建</strong></h4><p>使用语法 new int[5][]创建数组时,必须指定第一个下标.语法new int[][]是错误的</p>
<h4 id="基本类型变量和引用类型变量"><a href="#基本类型变量和引用类型变量" class="headerlink" title="基本类型变量和引用类型变量"></a><strong>基本类型变量和引用类型变量</strong></h4><p>int double 等属于基本类型变量<br>数组 各种类的实例化后的变量 属于引用类型变量</p>
]]></content>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>KNN算法实现之KD树</title>
    <url>/2016/05/22/KNN%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0%E4%B9%8BKD%E6%A0%91/</url>
    <content><![CDATA[<h2 id="一、背景"><a href="#一、背景" class="headerlink" title="一、背景"></a>一、背景</h2><p>　　了解了KNN算法后，存在一个问题，由于KNN算法需要将所有数据集读入内存，并需要通过计算未知点与所有训练点的距离，筛选出距离最小的k个点。因此在庞大的训练集面前，计算复杂度和空间复杂度都相当得高，KNN算法就显得非常的无力。<br><span id="more"></span></p>
<h2 id="二、原理"><a href="#二、原理" class="headerlink" title="二、原理"></a>二、原理</h2><p>　　将训练集构建出二叉树，利用回溯算法寻找与样点最近的k个训练点，避免与所有训练集计算距离的需求，大大减少了计算复杂度。</p>
<h2 id="三、算法流程"><a href="#三、算法流程" class="headerlink" title="三、算法流程"></a>三、算法流程</h2><h3 id="1、KD树的构建"><a href="#1、KD树的构建" class="headerlink" title="1、KD树的构建"></a>1、KD树的构建</h3><p>　　Kd-树：是对数据点在k维空间{二维(x，y)，三维(x，y，z)，k维(x，y，z..)}中划分的一种数据结构，主要应用于多维空间关键数据的搜索(如：范围搜索和最近邻搜索)。本质上说，Kd-树就是一种平衡二叉树。<br>　　<br>　　假设有6个二维数据点<code>&#123;(2,3)，(5,4)，(9,6)，(4,7)，(8,1)，(7,2)&#125;</code>，数据点位于二维空间内，根据这些数据点构造一个kd树。如下图：<br>　　　　　　　　　　<img src="https://github.com/Hareric/Lumberroom/raw/master/blog_graph/KDtree%20%E6%95%A3%E7%82%B9%E5%9B%BE.png" alt="散点空间图"></p>
<h4 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h4><p>　　①6个数据点在x，y维度上的数据方差分别为39，28.63，所以在x轴上方差更大，故先选x轴为坐标轴来切分矩形；<br>　　②根据x维上的值将数据排序：<code>&#123;(2,3),(4,7),(5,4),(7,2),(8,1),(9,6)&#125;</code><br>6个数据的中值为7，所以以数据点<code>(7,2)</code>为节点，通过<code>(7,2)</code>并垂直于x轴的直线来把平面切分成两个矩形；<br>　　③确定左子空间和右子空间。x=7将整个空间分为两部分：x&lt;=7的部分为左子空间，包含<code>3个节点=&#123;(2,3),(5,4),(4,7)&#125;</code>；另一部分为右子空间，包含<code>2个节点=&#123;(8,1)，(9,6)&#125;</code>；<br>　　kd树的构建是一个<strong>递归过程</strong>，我们对左子空间和右子空间内的数据重复上述过程将空间和数据集进一步细分，如此往复直到空间中任意两个子区域没有实例存在时，停止划分。<br>　　最后可以获得二叉树,如下图：<br>　　<img src="https://github.com/Hareric/Lumberroom/raw/master/blog_graph/kd%20tree%E4%BA%8C%E5%8F%89%E6%A0%91.png" alt="二叉树图"></p>
<h3 id="2、k-d树上的最邻近查找算法"><a href="#2、k-d树上的最邻近查找算法" class="headerlink" title="2、k-d树上的最邻近查找算法"></a>2、k-d树上的最邻近查找算法</h3><p>　　目的是检索在k-d树中与查询点距离最近的数据点。</p>
<h4 id="步骤："><a href="#步骤：" class="headerlink" title="步骤："></a>步骤：</h4><p>　　假设查询点A。通过二叉搜索，顺着搜索路径很快就能找到最邻近的近似点，也就是叶子节点B。<br>　　而找到的叶子节点B并不一定就是最邻近的，最邻近肯定距离查询点更近，应该位于以查询点为圆心且通过叶子节点的圆域内。<br>　　为了找到真正的最近邻，还需要进行相关的<strong>回溯</strong>操作。也就是说，算法沿搜索路径反向查找是否有距离查询点更近的数据点。</p>
<h4 id="实例："><a href="#实例：" class="headerlink" title="实例："></a>实例：</h4><p>以查询<code>(2.1,3.1)</code>为例：</p>
<p>1.二叉树搜索<br>　　此时搜索路径中的节点为<code>&#123;(7,2)，(5,4)，(2,3)&#125;</code>，以<code>(2,3)</code>作为当前最近邻点，计算其到查询点<code>(2.1,3.1)</code>的距离为<code>0.1414</code><br>　　　<img src="https://github.com/Hareric/Lumberroom/raw/master/blog_graph/%E4%BA%8C%E5%8F%89%E6%A0%91%E6%90%9C%E7%B4%A2.png" alt="二叉树搜索实例图"><br>2.回溯查找<br>　　在得到<code>(2,3)</code>为查询点的最近点之后，回溯到其父节点<code>(5,4)</code>，并判断在该父节点的其他子节点空间中是否有距离查询点更近的数据点。<br>　　以<code>(2.1,3.1)</code>为圆心，以0.1414为半径画圆，如下图所示。发现该圆并不和超平面<code>y = 4</code>交割，因此不用进入<code>(5,4)</code>节点右子空间中<strong>(图中绿色区域)</strong>去搜索；<br>　　最后，再回溯到<code>(7,2)</code>，以<code>(2.1,3.1)</code>为圆心，以0.1414为半径的圆更不会与<code>x = 7</code>超平面交割，因此不用进入<code>(7,2)</code>右子空<strong>间(图中红色区域)</strong>进行查找。至此，搜索路径中的节点已经全部回溯完，结束整个搜索，返回最近邻点<code>(2,3)</code>，最近距离为0.1414。<br>　　　　　<img src="https://github.com/Hareric/Lumberroom/raw/master/blog_graph/KDtree%20%E5%9B%9E%E6%BA%AF%E6%B3%95%E5%AF%BB%E7%82%B9.png" alt="KDtree回溯法找点"></p>
]]></content>
      <tags>
        <tag>算法</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>Java DBhelper类</title>
    <url>/2016/10/11/Java-DBhelper%E7%B1%BB/</url>
    <content><![CDATA[<p>　　简单用Java写的连接mysql的DBhealper类，包含了基本的数据库连接，增删查改等功能。<br><span id="more"></span></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.sql.*;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">* <span class="doctag">@author</span> Eric_Chan</span></span><br><span class="line"><span class="comment">* <span class="doctag">@version</span> 2016.10.11</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DBhelper</span> </span></span><br><span class="line"><span class="class"></span>&#123;</span><br><span class="line">	<span class="keyword">private</span> String ipAddress = <span class="string">&quot;127.0.0.1&quot;</span>;</span><br><span class="line">	<span class="keyword">private</span> <span class="keyword">int</span> port = <span class="number">3306</span>;</span><br><span class="line">	<span class="keyword">private</span> String user = <span class="string">&quot;&quot;</span>;</span><br><span class="line">	<span class="keyword">private</span> String pwd = <span class="string">&quot;&quot;</span>;</span><br><span class="line">	<span class="keyword">private</span> String dbName = <span class="string">&quot;&quot;</span>;</span><br><span class="line">	<span class="keyword">private</span> Connection conn;</span><br><span class="line">	<span class="keyword">private</span> <span class="keyword">static</span> DBhealper instance = <span class="keyword">null</span>;  <span class="comment">// 单例</span></span><br><span class="line">	</span><br><span class="line">	<span class="comment">/**</span></span><br><span class="line"><span class="comment">	 * 检查是否导入 mysql-connector-java.jar</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	<span class="function"><span class="keyword">private</span> <span class="title">DBhealper</span><span class="params">()</span></span></span><br><span class="line"><span class="function">	</span>&#123;</span><br><span class="line">		<span class="keyword">try</span> </span><br><span class="line">		&#123;</span><br><span class="line">			Class.forName(<span class="string">&quot;com.mysql.jdbc.Driver&quot;</span>);</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">catch</span> (ClassNotFoundException e) </span><br><span class="line">		&#123;</span><br><span class="line">			System.out.println(<span class="string">&quot;没有正确导入 connector.jar\n  下载地址http://dev.mysql.com/downloads/connector/j/&quot;</span>);</span><br><span class="line">		&#125; </span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	<span class="comment">/**</span></span><br><span class="line"><span class="comment">	 * 获得唯一连接器</span></span><br><span class="line"><span class="comment">	 * <span class="doctag">@return</span> DbConnection</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> DBhealper <span class="title">getInstance</span><span class="params">()</span></span></span><br><span class="line"><span class="function">	</span>&#123;</span><br><span class="line">		<span class="keyword">if</span> (DBhealper.instance == <span class="keyword">null</span>)</span><br><span class="line">		&#123;</span><br><span class="line">			instance = <span class="keyword">new</span> DBhealper();</span><br><span class="line">			<span class="keyword">return</span> DBhealper.instance;</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">else</span></span><br><span class="line">		&#123;</span><br><span class="line">			<span class="keyword">return</span> DBhealper.instance;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	<span class="comment">/**</span></span><br><span class="line"><span class="comment">	 * 连接数据库</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	<span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">connect</span><span class="params">()</span> <span class="keyword">throws</span> SQLException</span></span><br><span class="line"><span class="function">	</span>&#123;</span><br><span class="line">		String url = String.format(<span class="string">&quot;jdbc:mysql://%s:%s/%s&quot;</span>,<span class="keyword">this</span>.ipAddress, <span class="keyword">this</span>.port, <span class="keyword">this</span>.dbName);</span><br><span class="line">		<span class="keyword">try</span></span><br><span class="line">		&#123;</span><br><span class="line">			<span class="keyword">this</span>.conn = DriverManager.getConnection(url, <span class="keyword">this</span>.user, <span class="keyword">this</span>.pwd);</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">catch</span> (SQLException e) </span><br><span class="line">		&#123;</span><br><span class="line">			System.out.println(<span class="string">&quot;连接失败\n&quot;</span>);</span><br><span class="line">			e.printStackTrace();</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	<span class="comment">/**</span></span><br><span class="line"><span class="comment">	 * 提供参数 并连接数据库 默认为本地数据库，端口为3306</span></span><br><span class="line"><span class="comment">	 * <span class="doctag">@param</span> user 用户名</span></span><br><span class="line"><span class="comment">	 * <span class="doctag">@param</span> pwd 密码</span></span><br><span class="line"><span class="comment">	 * <span class="doctag">@param</span> dbName 数据库名</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">connSQL</span><span class="params">(String user, String pwd, String dbName)</span> <span class="keyword">throws</span> SQLException</span></span><br><span class="line"><span class="function">	</span>&#123;</span><br><span class="line">		<span class="keyword">this</span>.user = user;</span><br><span class="line">		<span class="keyword">this</span>.pwd = pwd;</span><br><span class="line">		<span class="keyword">this</span>.dbName = dbName;</span><br><span class="line">		<span class="keyword">this</span>.connect();</span><br><span class="line">		System.out.println(<span class="string">&quot;连接成功\nconn-------------&quot;</span> + conn + <span class="string">&#x27;\n&#x27;</span>);</span><br><span class="line">		<span class="keyword">this</span>.free(<span class="keyword">this</span>.conn, <span class="keyword">null</span>, <span class="keyword">null</span>);</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">connSQL</span><span class="params">(String user, String pwd, String dbName, <span class="keyword">int</span> port)</span> <span class="keyword">throws</span> SQLException</span></span><br><span class="line"><span class="function">	</span>&#123;</span><br><span class="line">		<span class="keyword">this</span>.port = port;</span><br><span class="line">		<span class="keyword">this</span>.connSQL(user, pwd, dbName);</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">connSQL</span><span class="params">(String user, String pwd, String dbName, String ipAddress)</span> <span class="keyword">throws</span> SQLException</span></span><br><span class="line"><span class="function">	</span>&#123;</span><br><span class="line">		<span class="keyword">this</span>.ipAddress = ipAddress;</span><br><span class="line">		<span class="keyword">this</span>.connSQL(user, pwd, dbName);</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">connSQL</span><span class="params">(String user, String pwd, String dbName,String ipAddress, <span class="keyword">int</span> port)</span> <span class="keyword">throws</span> SQLException</span></span><br><span class="line"><span class="function">	</span>&#123;</span><br><span class="line">		<span class="keyword">this</span>.ipAddress = ipAddress;</span><br><span class="line">		<span class="keyword">this</span>.port = port;</span><br><span class="line">		<span class="keyword">this</span>.connSQL(user, pwd, dbName);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">/**</span></span><br><span class="line"><span class="comment">	 * 将表内数据输出至控制台</span></span><br><span class="line"><span class="comment">	 * <span class="doctag">@param</span> tableName 表名</span></span><br><span class="line"><span class="comment">	 * <span class="doctag">@throws</span> Exception</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">showTable</span><span class="params">(String tableName)</span> <span class="keyword">throws</span> SQLException</span></span><br><span class="line"><span class="function">	</span>&#123;</span><br><span class="line">		<span class="keyword">this</span>.connect();</span><br><span class="line">		Statement stmt = <span class="keyword">null</span>;</span><br><span class="line">		ResultSet rs = <span class="keyword">null</span>;</span><br><span class="line">		<span class="keyword">try</span></span><br><span class="line">		&#123;</span><br><span class="line">			String sql = <span class="string">&quot;SELECT * FROM &quot;</span> + tableName;</span><br><span class="line">			stmt = conn.createStatement();</span><br><span class="line">			rs = stmt.executeQuery(sql);</span><br><span class="line">			DBhealper.showResultSet(rs);</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">catch</span>(SQLException e)</span><br><span class="line">		&#123;</span><br><span class="line">			e.printStackTrace();</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">finally</span></span><br><span class="line">		&#123;</span><br><span class="line">			<span class="keyword">this</span>.free(<span class="keyword">this</span>.conn, stmt, rs);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 查【Query】</span></span><br><span class="line"><span class="comment">     * 无参查找</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> sql</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> ResultSet</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> ResultSet <span class="title">executeQuery</span><span class="params">(String sql)</span> <span class="keyword">throws</span> SQLException</span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.connect();</span><br><span class="line">        Statement stmt = <span class="keyword">null</span>;</span><br><span class="line">        ResultSet rs = <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">try</span> </span><br><span class="line">        &#123;</span><br><span class="line">            stmt = conn.createStatement();</span><br><span class="line">            rs = stmt.executeQuery(sql);</span><br><span class="line">        &#125; </span><br><span class="line">        <span class="keyword">catch</span> (SQLException e) </span><br><span class="line">        &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">            <span class="keyword">this</span>.free(conn, stmt, rs);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> rs;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 查【Query】</span></span><br><span class="line"><span class="comment">     * 有参查找</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> sql</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> obj</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> ResultSet</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> ResultSet <span class="title">executeQuery</span><span class="params">(String sql, Object... obj)</span> <span class="keyword">throws</span> SQLException</span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">    	<span class="keyword">this</span>.connect();</span><br><span class="line">        PreparedStatement pstmt = <span class="keyword">null</span>;</span><br><span class="line">        ResultSet rs = <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">try</span> </span><br><span class="line">        &#123;</span><br><span class="line">            pstmt = conn.prepareStatement(sql);</span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; obj.length; i++) </span><br><span class="line">            &#123;</span><br><span class="line">                pstmt.setObject(i + <span class="number">1</span>, obj[i]);</span><br><span class="line">            &#125;</span><br><span class="line">            rs = pstmt.executeQuery();</span><br><span class="line">        &#125; </span><br><span class="line">        <span class="keyword">catch</span> (SQLException e) </span><br><span class="line">        &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">            <span class="keyword">this</span>.free(conn, pstmt, rs);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> rs;</span><br><span class="line">    &#125;</span><br><span class="line"> 	<span class="comment">/**</span></span><br><span class="line"><span class="comment">	 * 更新【update】 无参更新</span></span><br><span class="line"><span class="comment">	 * </span></span><br><span class="line"><span class="comment">	 * <span class="doctag">@param</span> sql</span></span><br><span class="line"><span class="comment">	 * <span class="doctag">@return</span> int</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">executeUpdate</span><span class="params">(String sql)</span> </span>&#123;</span><br><span class="line">		<span class="keyword">this</span>.connect();</span><br><span class="line">		Statement stmt = <span class="keyword">null</span>;</span><br><span class="line">		<span class="keyword">int</span> rs = <span class="number">0</span>;</span><br><span class="line">		<span class="keyword">try</span> &#123;</span><br><span class="line">			stmt = conn.createStatement();</span><br><span class="line">			rs = stmt.executeUpdate(sql);</span><br><span class="line">		&#125; <span class="keyword">catch</span> (SQLException e) &#123;</span><br><span class="line">			e.printStackTrace();</span><br><span class="line">			<span class="keyword">this</span>.free(conn, stmt, <span class="keyword">null</span>);</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">return</span> rs;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">/**</span></span><br><span class="line"><span class="comment">	 * 更新【update】 有参更新</span></span><br><span class="line"><span class="comment">	 * </span></span><br><span class="line"><span class="comment">	 * <span class="doctag">@param</span> sql</span></span><br><span class="line"><span class="comment">	 * <span class="doctag">@param</span> obj</span></span><br><span class="line"><span class="comment">	 * <span class="doctag">@return</span> int</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">executeUpdate</span><span class="params">(String sql, Object... obj)</span> </span>&#123;</span><br><span class="line">		<span class="keyword">this</span>.connect();</span><br><span class="line">		PreparedStatement pstmt = <span class="keyword">null</span>;</span><br><span class="line">		<span class="keyword">int</span> rs = <span class="number">0</span>;</span><br><span class="line">		<span class="keyword">try</span> &#123;</span><br><span class="line">			pstmt = conn.prepareStatement(sql);</span><br><span class="line">			<span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; obj.length; i++) &#123;</span><br><span class="line">				pstmt.setObject(i + <span class="number">1</span>, obj[i]);</span><br><span class="line">			&#125;</span><br><span class="line">			rs = pstmt.executeUpdate();</span><br><span class="line">		&#125; <span class="keyword">catch</span> (SQLException e) &#123;</span><br><span class="line">			e.printStackTrace();</span><br><span class="line">			<span class="keyword">this</span>.free(conn, pstmt, <span class="keyword">null</span>);</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">return</span> rs;</span><br><span class="line">	&#125;</span><br><span class="line">    </span><br><span class="line">	<span class="comment">/**</span></span><br><span class="line"><span class="comment">	 * 将ResultSet内的数据输出至控制台</span></span><br><span class="line"><span class="comment">	 * <span class="doctag">@param</span> rs</span></span><br><span class="line"><span class="comment">	 * <span class="doctag">@throws</span> SQLException</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">showResultSet</span><span class="params">(ResultSet rs)</span> <span class="keyword">throws</span> SQLException</span></span><br><span class="line"><span class="function">	</span>&#123;</span><br><span class="line">	    ResultSetMetaData rsmd = rs.getMetaData();   </span><br><span class="line">	    <span class="keyword">int</span> columnCount = rsmd.getColumnCount();   </span><br><span class="line">	    <span class="comment">// 输出列名   </span></span><br><span class="line">	    <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">1</span>; i&lt;=columnCount; i++)</span><br><span class="line">	    &#123;   </span><br><span class="line">	        System.out.print(rsmd.getColumnName(i));   </span><br><span class="line">	        System.out.print(<span class="string">&quot;(&quot;</span> + rsmd.getColumnTypeName(i) + <span class="string">&quot;)&quot;</span>);   </span><br><span class="line">	        System.out.print(<span class="string">&quot; | &quot;</span>);   </span><br><span class="line">	    &#125;   </span><br><span class="line">	    System.out.println();   </span><br><span class="line">	    <span class="comment">// 输出数据   </span></span><br><span class="line">	    <span class="keyword">while</span> (rs.next())</span><br><span class="line">	    &#123;   </span><br><span class="line">	        <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">1</span>; i&lt;=columnCount; i++)</span><br><span class="line">	        &#123;   </span><br><span class="line">	            System.out.print(rs.getString(i) + <span class="string">&quot;  |  &quot;</span>);   </span><br><span class="line">	        &#125;   </span><br><span class="line">	        System.out.println();   </span><br><span class="line">	    &#125;  </span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	<span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 判断记录是否存在</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> sql</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> Boolean</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Boolean <span class="title">isExist</span><span class="params">(String sql)</span> <span class="keyword">throws</span> SQLException</span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.connect();</span><br><span class="line">        Statement stmt = <span class="keyword">null</span>;</span><br><span class="line">        Boolean isEx = <span class="keyword">false</span>;</span><br><span class="line">        ResultSet rs = <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">try</span> </span><br><span class="line">        &#123;</span><br><span class="line">            stmt = conn.createStatement();</span><br><span class="line">            rs = stmt.executeQuery(sql);</span><br><span class="line">            rs.last();</span><br><span class="line">            isEx = rs.getRow()&gt;<span class="number">0</span>; </span><br><span class="line">        &#125; </span><br><span class="line">        <span class="keyword">catch</span> (SQLException e) </span><br><span class="line">        &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">finally</span></span><br><span class="line">        &#123;</span><br><span class="line">        	<span class="keyword">this</span>.free(conn, stmt, rs);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> isEx;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 判断记录是否存在</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> sql</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> Boolean</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Boolean <span class="title">isExist</span><span class="params">(String sql, Object... obj)</span> <span class="keyword">throws</span> SQLException</span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">    	<span class="keyword">this</span>.connect();</span><br><span class="line">        PreparedStatement pstmt = <span class="keyword">null</span>;</span><br><span class="line">        Boolean isEx = <span class="keyword">false</span>;</span><br><span class="line">        ResultSet rs = <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">try</span> </span><br><span class="line">        &#123;</span><br><span class="line">            pstmt = conn.prepareStatement(sql);</span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; obj.length; i++) </span><br><span class="line">            &#123;</span><br><span class="line">                pstmt.setObject(i + <span class="number">1</span>, obj[i]);</span><br><span class="line">            &#125;</span><br><span class="line">            rs = pstmt.executeQuery();</span><br><span class="line">            rs.last();</span><br><span class="line">            isEx = rs.getRow()&gt;<span class="number">0</span>;</span><br><span class="line">        &#125; </span><br><span class="line">        <span class="keyword">catch</span> (SQLException e) </span><br><span class="line">        &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">finally</span></span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">this</span>.free(conn, pstmt, rs);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> isEx;</span><br><span class="line">    &#125;</span><br><span class="line">	<span class="comment">/**</span></span><br><span class="line"><span class="comment">	 * 用来释放所有数据资源</span></span><br><span class="line"><span class="comment">	 * <span class="doctag">@param</span> conn </span></span><br><span class="line"><span class="comment">	 * <span class="doctag">@param</span> stmt</span></span><br><span class="line"><span class="comment">	 * <span class="doctag">@param</span> rs</span></span><br><span class="line"><span class="comment">	 * <span class="doctag">@throws</span> SQLException</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">free</span><span class="params">(Connection conn, Statement stmt, ResultSet rs)</span> <span class="keyword">throws</span> SQLException</span></span><br><span class="line"><span class="function">	</span>&#123;</span><br><span class="line">		<span class="keyword">if</span> (conn!=<span class="keyword">null</span>)</span><br><span class="line">		&#123;</span><br><span class="line">			<span class="keyword">try</span></span><br><span class="line">			&#123;</span><br><span class="line">				conn.close();</span><br><span class="line">			&#125;</span><br><span class="line">			<span class="keyword">catch</span>(SQLException e)</span><br><span class="line">			&#123;</span><br><span class="line">				e.printStackTrace();</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">if</span> (stmt!=<span class="keyword">null</span>)</span><br><span class="line">		&#123;</span><br><span class="line">			<span class="keyword">try</span></span><br><span class="line">			&#123;</span><br><span class="line">				stmt.close();</span><br><span class="line">			&#125;</span><br><span class="line">			<span class="keyword">catch</span>(SQLException e)</span><br><span class="line">			&#123;</span><br><span class="line">				e.printStackTrace();</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">if</span> (rs!=<span class="keyword">null</span>)</span><br><span class="line">		&#123;</span><br><span class="line">			<span class="keyword">try</span></span><br><span class="line">			&#123;</span><br><span class="line">				rs.close();</span><br><span class="line">			&#125;</span><br><span class="line">			<span class="keyword">catch</span>(SQLException e)</span><br><span class="line">			&#123;</span><br><span class="line">				e.printStackTrace();</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">()</span></span></span><br><span class="line"><span class="function">	</span>&#123;</span><br><span class="line">		<span class="keyword">try</span></span><br><span class="line">		&#123;</span><br><span class="line">			<span class="keyword">this</span>.conn.close();</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">catch</span> (SQLException e)</span><br><span class="line">		&#123;</span><br><span class="line">			e.printStackTrace();</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	</span><br><span class="line">	</span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String args[])</span> <span class="keyword">throws</span> SQLException</span></span><br><span class="line"><span class="function">	</span>&#123;</span><br><span class="line">		DBhealper connector = DBhealper.getInstance();</span><br><span class="line">		connector.connSQL(<span class="string">&quot;root&quot;</span>, <span class="string">&quot;1q2w3e&quot;</span>, <span class="string">&quot;student&quot;</span>, <span class="number">3307</span>);</span><br><span class="line">		<span class="comment">// connector.showTable(&quot;student&quot;);</span></span><br><span class="line">		<span class="comment">//ResultSet rs = connector.executeQuery(&quot;SELECT * FROM student WHERE st_name=? and st_Password=?&quot;, &quot;Jack&quot;, &quot;1234&quot;);</span></span><br><span class="line">		<span class="comment">//DBhealper.showResultSet(rs);</span></span><br><span class="line">		Boolean isEx = connector.isExist(<span class="string">&quot;SELECT * FROM student WHERE st_name=? and st_Password=?&quot;</span>, <span class="string">&quot;Jack&quot;</span>, <span class="string">&quot;1234&quot;</span>);</span><br><span class="line">		System.out.println(isEx);</span><br><span class="line">		connector.close();</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      <tags>
        <tag>Java</tag>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title>MapReduce的类型与格式</title>
    <url>/2019/02/18/MapReduce%E7%9A%84%E7%B1%BB%E5%9E%8B%E4%B8%8E%E6%A0%BC%E5%BC%8F/</url>
    <content><![CDATA[<h1 id="MapReduce的类型与格式"><a href="#MapReduce的类型与格式" class="headerlink" title="MapReduce的类型与格式"></a>MapReduce的类型与格式</h1><p><a href="https://www.zybuluo.com/zqbinggong/note/1182776">转载来源</a></p>
<h2 id="MapReduce的类型"><a href="#MapReduce的类型" class="headerlink" title="MapReduce的类型"></a>MapReduce的类型</h2><h3 id="默认的MR作业"><a href="#默认的MR作业" class="headerlink" title="默认的MR作业"></a>默认的MR作业</h3><ol>
<li>默认的mapper是Ｍapper类，它将输入的键和值原封不动地写到输出中</li>
<li>默认的partitioner是HashPartitioner，它对每条记录的键进行哈希操作以决定该记录应该属于哪个分区（每个分区对应于一个reduce任务）</li>
<li>默认的reducer是Reducer类，它将所有的输入写到输出中</li>
<li>map任务的数量等于输入文件被划分成的块数</li>
<li>reduce任务的个数的选择： 一个经验法则是目标reducer保持在每个运行5分钟左右且产生至少一个HDFS块的输出比较合适</li>
<li>默认的输入格式是TexInputFormat，输出是TextOutpFormat<span id="more"></span>
</li>
</ol>
<h2 id="输入格式"><a href="#输入格式" class="headerlink" title="输入格式"></a>输入格式</h2><h3 id="输入分片与记录"><a href="#输入分片与记录" class="headerlink" title="输入分片与记录"></a>输入分片与记录</h3><ul>
<li>一个输入分片就是由单个map操作来处理的数据块，并且每一个map只处理一个分片、</li>
<li>每个输入分片分为若干个记录，每条记录就是 一个键值对，map将一个接一个地处理记录</li>
<li>输入分片和记录都是逻辑概念，不一定对应着文件，也可能对应其他数据形式，如对于数据库，输入分片就是对应于一个表上的若干行，一条记录对应着其中的一行</li>
<li><p>输入分片只是指向数据的引用，不包含数据本身</p>
<ol>
<li>InputSpilt接口（Java中的实现），包含  <ul>
<li>以字节为单位的长度，表示分片的大小，用以排序分片，以便优先处理最大的分片，从而最小化作业运行时间</li>
<li>一组存储位置，供MR系统使用一边将map任务尽可能放在分片数据附近</li>
<li>该接口由InputFormat创建</li>
</ul>
</li>
<li>InputFormat  <ul>
<li>运行作业的客户端使用getSplits方法计算分片，并将结果告知application master，后者使用其存储信息来调度map任务从而在集群集群上处理这些分片数据</li>
<li>map任务将输入分片传给createRecordReader方法来获取这个分片的RecordReader（就像是记录上的迭代器），map任务用这个RecordReader来生成记录的键值对，然后再将键值对传递给map函数（参见run方法）</li>
</ul>
</li>
</ol>
</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/////InputFormat接口</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">InputFormat</span>&lt;<span class="title">K</span>, <span class="title">V</span>&gt; </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> List&lt;InputSplit&gt; <span class="title">getSplits</span><span class="params">(JobContext context)</span> <span class="keyword">throws</span> IOException, InterruptedException</span>;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> RecordReader&lt;K, V&gt; <span class="title">createRecordReader</span><span class="params">(InputSplit split, TaskAttemptContext context)</span> <span class="keyword">throws</span> IOException, InterruptedException</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/////Mapper的run方法</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">(Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">    setup(context);</span><br><span class="line">    <span class="keyword">while</span> (context.nextKeyValue()<span class="comment">/*委托给RecorReader的同名方法，为mapper产生键值对*/</span>) &#123;</span><br><span class="line">        map(context.getCurrentKey(), context.getCurrentValue(), context);<span class="comment">//从RecordReader中检索出并传递给map方法</span></span><br><span class="line">    &#125;</span><br><span class="line">    cleanup(context);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="文件输入–FileInputFormat"><a href="#文件输入–FileInputFormat" class="headerlink" title="文件输入–FileInputFormat"></a>文件输入–FileInputFormat</h3><ol>
<li>FileInputFormat类提供两个功能：  <ul>
<li>指出作业的输入文件位置</li>
<li>实现了为输入文件产生输入分片的功能（把分片切割成记录的功能由其子类完成）<br><img src="/img/tuchuang/master/resource/2019-02/inputformat.jpg" alt="此处输入图片的描述"></li>
</ul>
</li>
<li><p>输入路径<br><code>public static void addInputPath(Job job, Path path)</code><br><code>public static void addInputPaths(Job job, String commaSeparatedPaths)</code><br><code>public static void setInputPaths(Job job, Path... inputPaths)</code><br><code>public static void setInputPaths(Job job, String commaSeparatedPaths)</code></p>
<ul>
<li>前两者用于加入一个或多个路径到路径列表中，后两者一次设定完整的路径列表（replacing any paths set on the Job in previous calls）</li>
<li>一条路径可以是文件、目录或者glob（文件和目录的结合），但是目录在默认情况下不会进行递归处理，如果目录下存在子目录，则要么采用glob的形式，要么设置过滤器过滤子目录（因为子目录会被当作文件而报错），或者更改属性设置让其可以递归处理</li>
<li>FileInputFormat有默认过滤器，用以过滤隐藏文件（自定义的过滤器会和这个默认的一起工作）</li>
</ul>
</li>
</ol>
<ol start="3">
<li>输入分片： FileInputFormat只分割大文件（超过块的大小）  <ul>
<li>分片计算公式 <code>max(minimumSize, min(maximumSize, blockSize))</code></li>
<li>默认情况 <code>minimumSize &lt; blockSize &lt; maximumSize</code></li>
</ul>
</li>
<li><p>小文件与CombineFileInputFormat</p>
<ul>
<li>CombineFileInputFormat类可以把多个文件打包到一个分片中（在决定将哪些块放到同一分片时，会考虑节点和机架的因素）</li>
</ul>
</li>
<li>避免切分<ul>
<li>设置最小分片大小以避免切分、</li>
<li>重写isSplitable方法</li>
</ul>
</li>
<li>mapper中文件信息<ul>
<li>调用Mapper类中Context对象的getInputSplit方法来获得InputSplit，对于FileInputFormat，它会被转成FileSplit</li>
<li>注意此处的getInputSplit方法和InputFormat中的getSplit方法，后者是用于为整个输入计算分片，而前者是为某个mapper获取该输入分片的相关信息<br><img src="/img/tuchuang/master/resource/2019-02/file_split.jpg" alt="此处输入图片的描述"></li>
</ul>
</li>
<li><p>把整个文件作为一条记录处理</p>
<ul>
<li>即便不分割文件，仍然需要一个RecordReader来读取文件内容作为record的值</li>
<li><a href="https://github.com/tomwhite/hadoop-book/blob/master/ch08-mr-types/src/main/java/WholeFileRecordReader.java">WholeFileRecordReader,java</a></li>
</ul>
</li>
</ol>
<h3 id="文本输入–TextInputFormat"><a href="#文本输入–TextInputFormat" class="headerlink" title="文本输入–TextInputFormat"></a>文本输入–TextInputFormat</h3><p>Hadoop非常擅长处理非结构化文本数据</p>
<ol>
<li><p>TextInputFormat是默认的InputFormat</p>
<ul>
<li>每条记录是一条输入，键是LongWritable，存储该行在整个文件中的字节偏移量，值是该行的内容（不包括任何行终止符）</li>
<li>由于此处的逻辑记录是以行为单位的，因而可能出现某一行会跨文件块存放，从未会为‘本地化’的map任务带来远程读操作的开销（这是因为分片是和行对齐的而不是hdfs块，参考图示）</li>
<li><img src="/img/tuchuang/master/resource/2019-02/logic_record_HDFS.jpg" alt="此处输入图片的描述"></li>
</ul>
</li>
<li><p>控制一行最大的长度</p>
<ul>
<li>目的是应对损坏的文件，文件的损坏可能对应一个超长行，从而导致内存溢出</li>
<li>长度通过属性mapreduce.input.linerecordreader.line.maxlength设置</li>
</ul>
</li>
<li><p>关于KeyValueTextInputFFormat</p>
<ul>
<li>目的是应对那些每行内容是一个键值对的文件（之所以是键值对，是因为它经过了一些操作，比如TextOutputFormat的输出就会将键值对写入文件，两者之间使用分隔符分开）</li>
<li>所以使用时要指定键值对之间的分隔符，默认是制表符（属性mapreduce.input.keyvaluelinere cordreader.key.value.separator），且保持原来的键而不是使用偏移量作为键</li>
</ul>
</li>
<li><p>关于NLineInputFormat</p>
<ul>
<li>一般每个mapper收到的行数不同（行数取决于分片大小和行长度），通过该类可是使每个mapper收到的行数相同</li>
<li>键是文件中行的字节偏移量，值是行本身</li>
<li>应用场景  <ul>
<li>仿真</li>
<li>用Hadoop引导从多个数据源（如数据库）加载数据，每行一个数据源</li>
</ul>
</li>
</ul>
</li>
<li>关于xml  <ul>
<li>StreamXmlReccordReader</li>
</ul>
</li>
</ol>
]]></content>
      <tags>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title>MapReduce实践 Youtube数据分析</title>
    <url>/2019/02/19/MapReduce%E5%AE%9E%E8%B7%B5-Youtube%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/</url>
    <content><![CDATA[<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>这篇博客是关于如何在Hadoop MapReduce中进行YouTube数据分析的。<br>使用该数据集执行一些分析，并将提取一些有用的信息，例如YouTube上排名前10位的视频，他们上传了最多的视频。<br><span id="more"></span></p>
<h2 id="数据"><a href="#数据" class="headerlink" title="数据"></a>数据</h2><p><a href="/img/tuchuang/master/resource/2019-02/youtubedata.txt">数据下载</a></p>
<p><strong>数据展示</strong><br><img src="/img/tuchuang/master/resource/2019-02/dataset_youtube.png" alt="数据展示"></p>
<p><strong>数据说明</strong><br>Column 1: Video id of 11 characters.<br>Column 2: uploader of the video<br>Column 3: Interval between the day of establishment of Youtube and the date of uploading of the video.<br>Column 4: Category of the video.<br>Column 5: Length of the video.<br>Column 6: Number of views for the video.<br>Column 7: Rating on the video.<br>Column 8: Number of ratings given for the video<br>Column 9: Number of comments done on the videos.<br>Column 10: Related video ids with the uploaded video.</p>
<h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h2><p>寻找Top N个最多视频的类别</p>
<h2 id="MapReduce实现"><a href="#MapReduce实现" class="headerlink" title="MapReduce实现"></a>MapReduce实现</h2><h3 id="Mapper"><a href="#Mapper" class="headerlink" title="Mapper"></a>Mapper</h3><p>对每一行数据进行划分，统计各个视频类别的数量（Column 4）。数据集中部分数据缺失，因此忽略了划分后少于5个属性的数据。<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">CategoryMapper</span> <span class="keyword">extends</span> <span class="title">Mapper</span>&lt;<span class="title">Object</span>, <span class="title">Text</span>, <span class="title">Text</span>, <span class="title">IntWritable</span>&gt;</span></span><br><span class="line"><span class="class"></span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">static</span> IntWritable one = <span class="keyword">new</span> IntWritable(<span class="number">1</span>); <span class="comment">// 值为1</span></span><br><span class="line">    <span class="keyword">private</span> Text category = <span class="keyword">new</span> Text();</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(Object key, Text value, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException</span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        String[] attributeArray = value.toString().split(<span class="string">&quot;\t&quot;</span>);<span class="comment">// 对字符串进行切分</span></span><br><span class="line">        <span class="keyword">if</span> (attributeArray.length &gt; <span class="number">5</span>)  <span class="comment">// 忽略属性值少于5的错误数据  </span></span><br><span class="line">        &#123;</span><br><span class="line">            category.set(attributeArray[<span class="number">3</span>]);</span><br><span class="line">            context.write(category, one);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h3 id="Combiner"><a href="#Combiner" class="headerlink" title="Combiner"></a>Combiner</h3><p>Combiner的作用就是对map端的输出先做一次合并，以减少在map和reduce节点之间的数据传输量，以提高网络IO性能，是MapReduce的一种优化手段之一。<br>Combiner实质就是在本地端先运行的一次Reducer。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">SumReducer</span> <span class="keyword">extends</span> <span class="title">Reducer</span>&lt;<span class="title">Text</span>, <span class="title">IntWritable</span>, <span class="title">Text</span>, <span class="title">IntWritable</span>&gt;</span></span><br><span class="line"><span class="class"></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">reduce</span><span class="params">(Text key, Iterable&lt;IntWritable&gt; values, Context context)</span></span></span><br><span class="line"><span class="function">            <span class="keyword">throws</span> IOException, InterruptedException</span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> sum = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (IntWritable val : values)</span><br><span class="line">        &#123;</span><br><span class="line">            sum += val.get();</span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line">        context.write(key, <span class="keyword">new</span> IntWritable(sum));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="Reducer"><a href="#Reducer" class="headerlink" title="Reducer"></a>Reducer</h3><p>因为需要对，<code>[视频类别, 视频数]</code>数组进行排序比较，因此首先定义一个二元组类，包含视频类别和视频数，分别对应first和second。并定义了Comparable接口，用于后面排序的需要。<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">TwoTuple</span> <span class="keyword">implements</span> <span class="title">Comparable</span>&lt;<span class="title">TwoTuple</span>&gt;</span></span><br><span class="line"><span class="class"></span>&#123;</span><br><span class="line">    <span class="keyword">public</span>  String first;</span><br><span class="line">    <span class="keyword">public</span>  <span class="keyword">int</span> second;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">TwoTuple</span><span class="params">(String a, <span class="keyword">int</span> b)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        first = a;</span><br><span class="line">        second = b;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">toString</span><span class="params">()</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;(&quot;</span> + first + <span class="string">&quot;, &quot;</span> + second + <span class="string">&quot;)&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">compareTo</span><span class="params">(TwoTuple tt)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> second - tt.second;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>使用Reducer实现提取Top N值的算法。</p>
<p>首先需要介绍<code>setup()</code>函数和<code>cleanup()</code>函数，与<code>reduce()</code>函数不同，不会根据key的数目多次执行，只会执行1次。</p>
<p><strong>setup()</strong> 此方法被MapReduce框架仅且执行一次，在执行Map任务前，进行相关变量或者资源的集中初始化工作。若是将资源初始化工作放在方法map()中，导致Mapper任务在解析每一行输入时都会进行资源初始化工作，导致重复，程序运行效率不高。</p>
<p><strong>cleanup()</strong> 此方法被MapReduce框架仅且执行一次，在执行完毕Map任务后，进行相关变量或资源的释放工作。若是将释放资源工作放入方法map()中，也会导致Mapper任务在解析、处理每一行文本后释放资源，而且在下一行文本解析前还要重复初始化，导致反复重复，程序运行效率不高。</p>
<p><strong>算法介绍</strong><br>在<code>setup()</code>函数中，主要用来从配置中获取需要提取Top N的N值，并初始化<code>top[]</code>数组；<br>在<code>reduce()</code>函数中，计算出每个Category的视频总数后覆盖放入top[0]数组并进行排序；<br>在<code>cleanup()</code>函数中，将覆盖排序多次后的top数组写入output。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">TopNReducer</span> <span class="keyword">extends</span> <span class="title">Reducer</span>&lt;<span class="title">Text</span>, <span class="title">IntWritable</span>, <span class="title">Text</span>, <span class="title">IntWritable</span>&gt;</span></span><br><span class="line"><span class="class"></span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">int</span> len;</span><br><span class="line">    TwoTuple[] top;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">setup</span><span class="params">(Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException</span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        len =context.getConfiguration().getInt(<span class="string">&quot;N&quot;</span>, <span class="number">10</span>);  <span class="comment">// 从配置中获取top N的N值，若无则默认为10</span></span><br><span class="line">        top = <span class="keyword">new</span> TwoTuple[len + <span class="number">1</span>];</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;=len; i++)</span><br><span class="line">        &#123;</span><br><span class="line">            top[i] = <span class="keyword">new</span> TwoTuple(<span class="string">&quot;null&quot;</span>, <span class="number">0</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">cleanup</span><span class="params">(Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException</span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = len; i &gt; <span class="number">0</span>; i--)</span><br><span class="line">        &#123;</span><br><span class="line">            context.write(<span class="keyword">new</span> Text(top[i].first), <span class="keyword">new</span> IntWritable(top[i].second));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">reduce</span><span class="params">(Text key, Iterable&lt;IntWritable&gt; values, Context context)</span></span></span><br><span class="line"><span class="function">            <span class="keyword">throws</span> IOException, InterruptedException</span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> sum = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (IntWritable val : values)</span><br><span class="line">        &#123;</span><br><span class="line">            sum += val.get();</span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line">        add(key.toString(), sum);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">add</span><span class="params">(String key, <span class="keyword">int</span> val)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        top[<span class="number">0</span>].first = key;</span><br><span class="line">        top[<span class="number">0</span>].second = val;  <span class="comment">// 替换掉最小值</span></span><br><span class="line">        Arrays.sort(top); <span class="comment">// 排序，从小到大顺序</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="main-amp-conf"><a href="#main-amp-conf" class="headerlink" title="main&amp;conf"></a>main&amp;conf</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception</span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">    conf.addResource(<span class="string">&quot;classpath:/hadoop/core-site.xml&quot;</span>);</span><br><span class="line">    conf.addResource(<span class="string">&quot;classpath:/hadoop/hdfs-site.xml&quot;</span>);</span><br><span class="line">    conf.addResource(<span class="string">&quot;classpath:/hadoop/mapred-site.xml&quot;</span>);</span><br><span class="line">    conf.setInt(<span class="string">&quot;N&quot;</span>, <span class="number">5</span>);</span><br><span class="line">    <span class="comment">// String[] otherArgs = new GenericOptionsParser(conf,</span></span><br><span class="line">    <span class="comment">// args).getRemainingArgs();</span></span><br><span class="line">    String[] otherArgs = &#123; <span class="string">&quot;/youtube&quot;</span>, <span class="string">&quot;/youtube_category_Top5&quot;</span> &#125;;</span><br><span class="line">    <span class="keyword">if</span> (otherArgs.length != <span class="number">2</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        System.err.println(<span class="string">&quot;Usage: wordcount &lt;in&gt; &lt;out&gt;&quot;</span>);</span><br><span class="line">        System.exit(<span class="number">2</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    Job job = <span class="keyword">new</span> Job(conf, <span class="string">&quot;youtube&quot;</span>);</span><br><span class="line">    job.setJarByClass(FindMaxCategory.class);</span><br><span class="line">    job.setMapperClass(CategoryMapper.class);</span><br><span class="line">    job.setCombinerClass(SumReducer.class);</span><br><span class="line"><span class="comment">//		job.setReducerClass(SumReducer.class);  // 统计每个类别的总量</span></span><br><span class="line">    job.setReducerClass(TopNReducer.class);  <span class="comment">// 统计TopN的类别的总量</span></span><br><span class="line">    job.setOutputKeyClass(Text.class);</span><br><span class="line">    job.setOutputValueClass(IntWritable.class);</span><br><span class="line">    FileInputFormat.setInputDirRecursive(job, <span class="keyword">true</span>);</span><br><span class="line">    FileInputFormat.addInputPath(job, <span class="keyword">new</span> Path(otherArgs[<span class="number">0</span>]));</span><br><span class="line">    FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> Path(otherArgs[<span class="number">1</span>]));</span><br><span class="line">    System.exit(job.waitForCompletion(<span class="keyword">true</span>) ? <span class="number">0</span> : <span class="number">1</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="输出"><a href="#输出" class="headerlink" title="输出"></a>输出</h2><p><img src="/img/tuchuang/master/resource/2019-02/youtube_outputresult.png" alt="result"></p>
<p><a href="https://github.com/Hareric/HadoopLearn/tree/master/src/main/java/youtube">完整代码</a></p>
]]></content>
      <tags>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title>MapReduce实践 Uber数据分析</title>
    <url>/2019/02/21/MapReduce%E5%AE%9E%E8%B7%B5%20Uber%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/</url>
    <content><![CDATA[<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>这篇博客是关于如何在Hadoop MapReduce中进行Uber数据分析的。<br><span id="more"></span></p>
<h2 id="数据"><a href="#数据" class="headerlink" title="数据"></a>数据</h2><p><a href="/img/tuchuang/master/resource/2019-02/uber_data.txt">数据下载</a></p>
<p><strong>数据展示</strong><br><img src="/img/tuchuang/master/resource/2019-02/uber_data_view.png" alt="data view"></p>
<p><strong>数据说明</strong></p>
<p>该数据有4列：</p>
<ol>
<li>dispatching_base_number</li>
<li>date</li>
<li>active_vehicles </li>
<li>trips</li>
</ol>
<h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h2><p>计算每个Basement每个周几总共有多少trips</p>
<h2 id="MapReduce实现"><a href="#MapReduce实现" class="headerlink" title="MapReduce实现"></a>MapReduce实现</h2><h3 id="Mapper"><a href="#Mapper" class="headerlink" title="Mapper"></a>Mapper</h3><p>在Mapper中 使用<code>java.time.LocalDate</code>来获取每个年月日具体是星期几，并将<code>Basement_number+dayofweek</code>作为keys，<code>tripNum</code>作为value。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">ExtractTripMapper</span> <span class="keyword">extends</span> <span class="title">Mapper</span>&lt;<span class="title">Object</span>, <span class="title">Text</span>, <span class="title">Text</span>, <span class="title">IntWritable</span>&gt;</span></span><br><span class="line"><span class="class"></span>&#123;</span><br><span class="line">    <span class="keyword">private</span> IntWritable tripNum; <span class="comment">// trip 值</span></span><br><span class="line">    String specifyDate = <span class="string">&quot;MM/DD/YYYY&quot;</span>;</span><br><span class="line">    DateTimeFormatter formatter = DateTimeFormatter.ofPattern(<span class="string">&quot;M/d/y&quot;</span>);  <span class="comment">// date转化格式</span></span><br><span class="line">    LocalDate date;</span><br><span class="line">    String dayOfWeek;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(Object key, Text value, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException</span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        String[] splitArray = value.toString().split(<span class="string">&quot;,&quot;</span>); <span class="comment">// 对字符串进行切分</span></span><br><span class="line">        specifyDate = splitArray[<span class="number">1</span>];</span><br><span class="line">        <span class="comment">// 使用try来处理不和谐的数据</span></span><br><span class="line">        <span class="keyword">try</span>&#123;</span><br><span class="line">            date = LocalDate.parse(specifyDate,formatter);</span><br><span class="line">            dayOfWeek = date.getDayOfWeek().toString();</span><br><span class="line">            tripNum =  <span class="keyword">new</span> IntWritable(<span class="keyword">new</span> Integer(splitArray[<span class="number">3</span>]));</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">catch</span> (DateTimeParseException e)&#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        context.write(<span class="keyword">new</span> Text(splitArray[<span class="number">0</span>] + <span class="string">&quot;+&quot;</span> + dayOfWeek), tripNum);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="Combiner-amp-Reducer"><a href="#Combiner-amp-Reducer" class="headerlink" title="Combiner&amp;Reducer"></a>Combiner&amp;Reducer</h3><p>之后就与WordCont相同，进行简单的统计和合并。<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">SumReducer</span> <span class="keyword">extends</span> <span class="title">Reducer</span>&lt;<span class="title">Text</span>, <span class="title">IntWritable</span>, <span class="title">Text</span>, <span class="title">IntWritable</span>&gt;</span></span><br><span class="line"><span class="class"></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">reduce</span><span class="params">(Text key, Iterable&lt;IntWritable&gt; values, Context context)</span></span></span><br><span class="line"><span class="function">            <span class="keyword">throws</span> IOException, InterruptedException</span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> sum = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (IntWritable val : values)</span><br><span class="line">        &#123;</span><br><span class="line">            sum += val.get();</span><br><span class="line">        &#125;</span><br><span class="line">        context.write(key, <span class="keyword">new</span> IntWritable(sum));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h2 id="输出"><a href="#输出" class="headerlink" title="输出"></a>输出</h2><p><img src="/img/tuchuang/master/resource/2019-02/uber_output.png" alt="result"></p>
<p><a href="https://github.com/Hareric/HadoopLearn/tree/master/src/main/java/uber">完整代码</a></p>
]]></content>
      <tags>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title>Hello World</title>
    <url>/2016/04/22/hello-world/</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/deployment.html">Deployment</a></p>
]]></content>
  </entry>
  <entry>
    <title>k-近邻算法(K Nearest Neighbor)</title>
    <url>/2016/04/29/k-%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95(K%20Nearest%20Neighbor)/</url>
    <content><![CDATA[<h3 id="工作原理"><a href="#工作原理" class="headerlink" title="工作原理"></a>工作原理</h3><p>　　存在一份训练样本集，并且每个样本都有属于自己的标签，即我们知道每个样本集中所属于的类别。输入没有标签的新数据后，将新数据的每个特征与样本集中数据对应的特征进行比较，然后提取样本集中与之最相近的k个样本。观察并统计这k个样本的标签，选择数量最大的标签作为这个新数据的标签。<br><span id="more"></span><br>　　用以下这幅图可以很好的解释kNN算法：<br>　　<br>　　　　　　　　　　　　　　　　　　<img src="https://upload.wikimedia.org/wikipedia/commons/e/e7/KnnClassification.svg" alt="kNN算法示意图"><br>　　不同形状的点，为不同标签的点。其中绿色点为未知标签的数据点。现在要对绿色点进行预测。由图不难得出：</p>
<ul>
<li>如果k=3，那么离绿色点最近的有2个红色三角形和1个蓝色的正方形，这3个点投票，于是绿色的这个待分类点属于红色的三角形。</li>
<li>如果k=5，那么离绿色点最近的有2个红色三角形和3个蓝色的正方形，这5个点投票，于是绿色的这个待分类点属于蓝色的正方形。<h1 id=""><a href="#" class="headerlink" title=" "></a> </h1><h3 id="kNN算法实施"><a href="#kNN算法实施" class="headerlink" title="kNN算法实施"></a>kNN算法实施</h3><strong>伪代码</strong><br>对未知属性的数据集中的每个点执行以下操作</li>
</ul>
<ol>
<li>计算已知类型类别数据集中的点与当前点之间的距离</li>
<li>按照距离递增次序排序</li>
<li>选取与当前点距离最小的k个点</li>
<li>确定前k个点所在类别的出现频率</li>
<li>返回前k个点出现频率最高的类别作为当前点的预测分类</li>
</ol>
<p><strong>欧式距离(计算两点之间的距离公式)</strong><br>计算点x与点y之间欧式距离<br>　　　　　　　　　<img src="https://upload.wikimedia.org/math/f/d/6/fd67b246c3f6b5478664deb9a8413f5b.png" alt="欧式距离公式"></p>
<p><strong>python代码实现</strong><br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> operator</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练集</span></span><br><span class="line">data_set = np.array([[<span class="number">1.</span>, <span class="number">1.1</span>],</span><br><span class="line">                     [<span class="number">1.0</span>, <span class="number">1.0</span>],</span><br><span class="line">                     [<span class="number">0.</span>, <span class="number">0.</span>],</span><br><span class="line">                     [<span class="number">0</span>, <span class="number">0.1</span>]])</span><br><span class="line">labels = [<span class="string">&#x27;A&#x27;</span>, <span class="string">&#x27;A&#x27;</span>, <span class="string">&#x27;B&#x27;</span>, <span class="string">&#x27;B&#x27;</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">classify_knn</span>(<span class="params">in_vector, training_data, training_label, k</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    :param in_vector: 待分类向量</span></span><br><span class="line"><span class="string">    :param training_data: 训练集向量</span></span><br><span class="line"><span class="string">    :param training_label: 训练集标签</span></span><br><span class="line"><span class="string">    :param k: 选择最近邻居的数目</span></span><br><span class="line"><span class="string">    :return: 分类器对 in_vector 分类的类别</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    data_size = training_data.shape[<span class="number">0</span>]  <span class="comment"># .shape[0] 返回二维数组的行数</span></span><br><span class="line">    diff_mat = np.tile(in_vector, (data_size, <span class="number">1</span>)) - data_set  <span class="comment"># np.tile(array, (3, 2)) 对 array 进行 3×2 扩展为二维数组</span></span><br><span class="line">    sq_diff_mat = diff_mat ** <span class="number">2</span></span><br><span class="line">    sq_distances = sq_diff_mat.<span class="built_in">sum</span>(axis=<span class="number">1</span>)  <span class="comment"># .sum(axis=1) 矩阵以列求和</span></span><br><span class="line">    <span class="comment"># distances = sq_distances ** 0.5  # 主要是通过比较求最近点,所以没有必要求平方根</span></span><br><span class="line">    distances_sorted_index = sq_distances.argsort()  <span class="comment"># .argsort() 对array进行排序 返回排序后对应的索引</span></span><br><span class="line">    class_count_dict = &#123;&#125;  <span class="comment"># 用于统计类别的个数</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(k):</span><br><span class="line">        label = training_label[distances_sorted_index[i]]</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            class_count_dict[label] += <span class="number">1</span></span><br><span class="line">        <span class="keyword">except</span> KeyError:</span><br><span class="line">            class_count_dict[label] = <span class="number">1</span></span><br><span class="line">    class_count_dict = <span class="built_in">sorted</span>(class_count_dict.iteritems(), key=operator.itemgetter(<span class="number">1</span>), reverse=<span class="literal">True</span>)  <span class="comment"># 根据字典的value值对字典进行逆序排序</span></span><br><span class="line">    <span class="keyword">return</span> class_count_dict[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    vector = [<span class="number">0</span>, <span class="number">0</span>]  <span class="comment"># 待分类数据集</span></span><br><span class="line">    <span class="built_in">print</span> classify_knn(in_vector=vector, training_data=data_set, training_label=labels, k=<span class="number">3</span>)</span><br></pre></td></tr></table></figure></p>
<h1 id="-1"><a href="#-1" class="headerlink" title=" "></a> </h1><h3 id="算法评价"><a href="#算法评价" class="headerlink" title="算法评价"></a>算法评价</h3><ul>
<li>优点：精度高、对异常值不敏感、无数据输入假定</li>
<li>缺点：计算复杂度高、空间复杂度高</li>
<li>使用数据范围：数据型和标称型</li>
<li>适用：kNN方法通常用于一个更复杂分类算法的一部分。例如，我们可以用它的估计值做为一个对象的特征。有时候，一个简单的kNN算法在良好选择的特征上会有很出色的表现。</li>
</ul>
]]></content>
      <tags>
        <tag>python</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL命令行--导入导出数据库</title>
    <url>/2016/04/23/MySQL%E5%91%BD%E4%BB%A4%E8%A1%8C--%E5%AF%BC%E5%85%A5%E5%AF%BC%E5%87%BA%E6%95%B0%E6%8D%AE%E5%BA%93/</url>
    <content><![CDATA[<h3 id="MySQL命令行导出数据库："><a href="#MySQL命令行导出数据库：" class="headerlink" title="MySQL命令行导出数据库："></a>MySQL命令行导出数据库：</h3><p>mysqldump -u 用户名 -p 数据库名 &gt; 导出的地址/导出的文件名<br>如我输入的命令行:mysqldump -u root -p swpu &gt; ‘/Users/frand/Desktop/swpu.sql’,输入后会让你输入进入MySQL的密码,输入密码即可看到swpu.sql出现在桌面上。<br><span id="more"></span></p>
<h3 id="MySQL命令行导出一个表："><a href="#MySQL命令行导出一个表：" class="headerlink" title="MySQL命令行导出一个表："></a>MySQL命令行导出一个表：</h3><p>mysqldump -u 用户名 -p 数据库名 表名&gt; 导出的地址/导出的文件名<br>如我输入的命令行：mysqldump -u root -p swpu users&gt; ‘/Users/frand/Desktop/swpu_users.sql’,输入后会让你输入进入MySQL的密码,输入密码即可看到swpu_users.sql出现在桌面上。</p>
<h3 id="MySQL命令行导入一个数据库"><a href="#MySQL命令行导入一个数据库" class="headerlink" title="MySQL命令行导入一个数据库"></a>MySQL命令行导入一个数据库</h3><p>1，先进入数据库，如我输入的命令行:mysql -u root -p   (输入同样后会让你输入MySQL的密码)<br>2，在MySQL-Front中新建你要建的数据库，这时是空数据库，如新建一个名为news的目标数据库<br>3，输入：use 目标数据库名,如我输入的命令行:use news;<br>4，导入文件：source 导入的文件名,如我输入的命令行：source /Users/frand/Desktop/swpu.sqls;</p>
<h3 id="MySQL命令行导入一个数据表"><a href="#MySQL命令行导入一个数据表" class="headerlink" title="MySQL命令行导入一个数据表"></a>MySQL命令行导入一个数据表</h3><p>1，先进入数据库，如我输入的命令行:mysql -u root -p   (输入同样后会让你输入MySQL的密码)<br>2，在MySQL-Front中新建你要建的数据库，这时是空数据库，如新建一个名为news的目标数据库<br>3，输入：use 目标数据库名,如我输入的命令行:use news;<br>4，导入文件：source 导入的文件名,如我输入的命令行：source /Users/frand/Desktop/swpu_falcatys.sqls;<br>MySQL备份和还原,都是利用mysqldump、mysql和source命令来完成的。</p>
]]></content>
      <tags>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title>json解析工具</title>
    <url>/2021/05/29/json%E8%A7%A3%E6%9E%90%E5%B7%A5%E5%85%B7/</url>
    <content><![CDATA[<iframe  
 height=900 
 width=100% 
 src="/json_viewer"  
 frameborder=0  
 allowfullscreen><br> </iframe>]]></content>
      <tags>
        <tag>开发工具</tag>
      </tags>
  </entry>
  <entry>
    <title>Parquet学习笔记</title>
    <url>/2019/02/15/Parquet%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>Apache Parquet是Hadoop生态圈中一种新型列式存储格式，它可以兼容Hadoop生态圈中大多数计算框架(Hadoop、Spark等)，被多种查询引擎支持(Hive、Impala、Drill等)，并且它是语言和平台无关的。<br><span id="more"></span></p>
<h2 id="Definition-level-amp-Repetition-level"><a href="#Definition-level-amp-Repetition-level" class="headerlink" title="Definition level &amp; Repetition level"></a>Definition level &amp; Repetition level</h2><h3 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h3><h4 id="definition-Level"><a href="#definition-Level" class="headerlink" title="definition Level"></a><strong>definition Level</strong></h4><p>Definition level指明该列的路径上多少个可选field被定义了。</p>
<p>definition Level是该路径上有定义的repeated field 和 optional field的个数，不包括required field，因为required field是必须有定义的。</p>
<h4 id="Repetition-levels"><a href="#Repetition-levels" class="headerlink" title="Repetition levels"></a><strong>Repetition levels</strong></h4><p>Repetition level指明该值在路径中哪个repeated field重复。</p>
<h3 id="DL和RL的计算"><a href="#DL和RL的计算" class="headerlink" title="DL和RL的计算"></a>DL和RL的计算</h3><p><img src="/img/tuchuang/master/resource/2019-02/parquet_note.png" alt="parquet"></p>
<p>我们用深度0表示一个纪录的开头（虚拟的根节点），深度的计算忽略非重复字段（标签不是repeated的字段都不算在深度里）。所以在Name.Language.Code这个路径中，包含两个重复字段，Name和Language，如果在Name处重复，重复深度为1（虚拟的根节点是0，下一级就是1），在Language处重复就是2，不可能在Code处重复，它是required类型，表示有且仅有一个；同样的，在路径Links.Forward中，Links是optional的，不参与深度计算（不可能重复），Forward是repeated的，因此只有在Forward处重复时重复深度为1。</p>
<h2 id="Parquet-Java-example"><a href="#Parquet-Java-example" class="headerlink" title="Parquet Java example"></a>Parquet Java example</h2><p><a href="https://note.abeffect.com/note/articles/2018/06/22/1529669663974.html">来源</a><br><strong>pom文件</strong><br><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.parquet<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>parquet-avro<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">version</span>&gt;</span>1.10.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-mapreduce-client-core<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">version</span>&gt;</span>0.23.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">	<span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-common<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">version</span>&gt;</span>2.7.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br></pre></td></tr></table></figure><br><strong>WriteParquet.java</strong><br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.avro.Schema;</span><br><span class="line"><span class="keyword">import</span> org.apache.avro.Schema.Field;</span><br><span class="line"><span class="keyword">import</span> org.apache.avro.Schema.Type;</span><br><span class="line"><span class="keyword">import</span> org.apache.avro.generic.GenericData;</span><br><span class="line"><span class="keyword">import</span> org.apache.avro.generic.GenericData.Record;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.parquet.avro.AvroParquetWriter;</span><br><span class="line"><span class="keyword">import</span> org.apache.parquet.hadoop.ParquetWriter;</span><br><span class="line"><span class="keyword">import</span> org.apache.parquet.hadoop.metadata.CompressionCodecName;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">WriteParquet</span> </span>&#123;</span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IllegalArgumentException, IOException </span>&#123;</span><br><span class="line"></span><br><span class="line">		List&lt;Field&gt; fields = <span class="keyword">new</span> ArrayList&lt;Field&gt;();</span><br><span class="line">		Object defaultValue = <span class="keyword">null</span>;</span><br><span class="line">		fields.add(<span class="keyword">new</span> Field(<span class="string">&quot;x&quot;</span>, Schema.create(Type.INT), <span class="string">&quot;x&quot;</span>, defaultValue));</span><br><span class="line">		fields.add(<span class="keyword">new</span> Field(<span class="string">&quot;y&quot;</span>, Schema.create(Type.INT), <span class="string">&quot;y&quot;</span>, defaultValue));</span><br><span class="line"></span><br><span class="line">		Schema schema = Schema.createRecord(<span class="string">&quot;name&quot;</span>, <span class="string">&quot;doc&quot;</span>, <span class="string">&quot;namespace&quot;</span>, <span class="keyword">false</span>, fields);</span><br><span class="line"></span><br><span class="line">		<span class="keyword">try</span> (ParquetWriter&lt;GenericData.Record&gt; writer = AvroParquetWriter.&lt;GenericData.Record&gt;builder(</span><br><span class="line">				<span class="keyword">new</span> Path(<span class="string">&quot;my-file.parquet&quot;</span>)).withSchema(schema).withCompressionCodec(CompressionCodecName.SNAPPY)</span><br><span class="line">				.build()) &#123;</span><br><span class="line"></span><br><span class="line">			<span class="comment">// 模拟10000行数据</span></span><br><span class="line">			<span class="keyword">for</span> (<span class="keyword">int</span> r = <span class="number">0</span>; r &lt; <span class="number">10000</span>; ++r) &#123;</span><br><span class="line">				Record record = <span class="keyword">new</span> Record(schema);</span><br><span class="line">				record.put(<span class="number">0</span>, r);</span><br><span class="line">				record.put(<span class="number">1</span>, r * <span class="number">3</span>);</span><br><span class="line">				writer.write(record);</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br><strong>ReadParquet.java</strong><br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.avro.generic.GenericRecord;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.parquet.avro.AvroParquetReader;</span><br><span class="line"><span class="keyword">import</span> org.apache.parquet.hadoop.ParquetReader;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ReadParquet</span> </span>&#123;</span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IllegalArgumentException, IOException </span>&#123;</span><br><span class="line"></span><br><span class="line">		ParquetReader&lt;GenericRecord&gt; reader = AvroParquetReader.&lt;GenericRecord&gt;builder(<span class="keyword">new</span> Path(<span class="string">&quot;my-file.parquet&quot;</span>))</span><br><span class="line">				.build();</span><br><span class="line">		GenericRecord record;</span><br><span class="line"></span><br><span class="line">		<span class="keyword">while</span> ((record = reader.read()) != <span class="keyword">null</span>) &#123;</span><br><span class="line">			System.out.println(record);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
]]></content>
      <tags>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title>mac中XAMPP如何开启局域网访问</title>
    <url>/2016/06/17/mac%E4%B8%ADXAMPP%E5%A6%82%E4%BD%95%E5%BC%80%E5%90%AF%E5%B1%80%E5%9F%9F%E7%BD%91%E8%AE%BF%E9%97%AE/</url>
    <content><![CDATA[<p>XAMPP作为apache服务器默认的时候是无法再局域网的其他机器上访问设置界面的。那么怎样启用局域网访问呢？<br><span id="more"></span><br><strong>1、找到该文件</strong><br>在XAMPP的安装路径中找到该文件<br><code>/Applications/XAMPP/xamppfiles/etc/extra/httpd-xampp.conf</code><br>用sublime或者使用vim编辑器打开 <code>sudo vim /Applications/XAMPP/xamppfiles/etc/extra/httpd-xampp.conf</code></p>
<p><strong>2、修改访问权限</strong><br>找到以下代码<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># since XAMPP 1.4.3</span></span><br><span class="line">&lt;Directory <span class="string">&quot;/Applications/XAMPP/xamppfiles/phpmyadmin&quot;</span>&gt;</span><br><span class="line">    AllowOverride AuthConfig Limit</span><br><span class="line">    Require <span class="built_in">local</span></span><br><span class="line">    ErrorDocument 403 /error/XAMPP_FORBIDDEN.html.var</span><br><span class="line">&lt;/Directory&gt;</span><br><span class="line"></span><br><span class="line">&lt;Directory <span class="string">&quot;/Applications/XAMPP/xamppfiles/phpsqliteadmin&quot;</span>&gt;</span><br><span class="line">    AllowOverride AuthConfig Limit</span><br><span class="line">    Require <span class="built_in">local</span></span><br><span class="line">    ErrorDocument 403 /error/XAMPP_FORBIDDEN.html.var</span><br><span class="line">&lt;/Directory&gt;</span><br></pre></td></tr></table></figure><br>修改为<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">&lt;Directory <span class="string">&quot;/Applications/XAMPP/xamppfiles/phpmyadmin&quot;</span>&gt;</span><br><span class="line">    AllowOverride AuthConfig Limit</span><br><span class="line">    <span class="comment"># Require local</span></span><br><span class="line">    Require all granted</span><br><span class="line">    Order allow,deny</span><br><span class="line">    Allow from all</span><br><span class="line">    ErrorDocument 403 /error/XAMPP_FORBIDDEN.html.var</span><br><span class="line">&lt;/Directory&gt;</span><br><span class="line"></span><br><span class="line">&lt;Directory <span class="string">&quot;/Applications/XAMPP/xamppfiles/phpsqliteadmin&quot;</span>&gt;</span><br><span class="line">    AllowOverride AuthConfig Limit</span><br><span class="line">    <span class="comment"># Require local</span></span><br><span class="line">    Require all granted</span><br><span class="line">    Order allow,deny</span><br><span class="line">    Allow from all</span><br><span class="line">    ErrorDocument 403 /error/XAMPP_FORBIDDEN.html.var</span><br><span class="line">&lt;/Directory&gt;</span><br></pre></td></tr></table></figure></p>
<p><strong>3、使用IP地址访问</strong><br>在终端使用<code>ifconfig</code>查询本机的ip地址，然后在局域网中输入IP地址便可以在局域网中访问自己的服务器了。</p>
]]></content>
      <tags>
        <tag>XAMPP</tag>
      </tags>
  </entry>
  <entry>
    <title>python学习笔记----第7章类和类型</title>
    <url>/2016/04/23/python%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0----%E7%AC%AC7%E7%AB%A0%E7%B1%BB%E5%92%8C%E7%B1%BB%E5%9E%8B/</url>
    <content><![CDATA[<p>与其它编程语言相比，Python的类机制添加了最小的新语法和语义。它是C++和Modula-3中的类机制的混合。Python的类提供了面向对象编程的所有的标准特性，类继承机制允许有多个基类，一个子类可以重写基类中的任何方法，一个方法可以调用基类里面的同名方法。对象可以包含任意数量和种类的数据。就像模块那样，类参与Python的动态天性，在运行时被创建，创建后可以被进一步修改。<br><span id="more"></span></p>
<h2 id="创建简单类"><a href="#创建简单类" class="headerlink" title="创建简单类"></a>创建简单类</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Employee</span>:</span></span><br><span class="line">   <span class="string">&#x27;所有员工的基类&#x27;</span></span><br><span class="line">   empCount = <span class="number">0</span>   <span class="comment">#开头没有self的数据域,且写在方法外类似于静态变量private</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 构造方法，实例化后第一时间自动调用</span></span><br><span class="line">   <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, name, salary</span>):</span>  <span class="comment">#注意：1、双下划线 2、是init不是int</span></span><br><span class="line">      self.name = name  <span class="comment">#开头有self的数据可以让类的其他方法使用</span></span><br><span class="line">      self.salary = salary</span><br><span class="line">      Employee.empCount += <span class="number">1</span></span><br><span class="line">   </span><br><span class="line">   <span class="function"><span class="keyword">def</span> <span class="title">displayCount</span>(<span class="params">self</span>):</span></span><br><span class="line">     <span class="built_in">print</span> <span class="string">&quot;Total Employee %d&quot;</span> % Employee.empCount</span><br><span class="line"></span><br><span class="line">   <span class="function"><span class="keyword">def</span> <span class="title">displayEmployee</span>(<span class="params">self</span>):</span></span><br><span class="line">      <span class="built_in">print</span> <span class="string">&quot;Name : &quot;</span>, self.name,  <span class="string">&quot;, Salary: &quot;</span>, self.salary</span><br><span class="line"></span><br><span class="line"><span class="comment">#创建实例对象      </span></span><br><span class="line"><span class="string">&quot;创建 Employee 类的第一个对象&quot;</span></span><br><span class="line">emp1 = Employee(<span class="string">&quot;Zara&quot;</span>, <span class="number">2000</span>)</span><br><span class="line"><span class="string">&quot;创建 Employee 类的第二个对象&quot;</span></span><br><span class="line">emp2 = Employee(<span class="string">&quot;Manni&quot;</span>, <span class="number">5000</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#访问属性</span></span><br><span class="line">emp1.displayEmployee()</span><br><span class="line">emp2.displayEmployee()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> <span class="string">&quot;Total Employee %d&quot;</span> % Employee.empCount </span><br></pre></td></tr></table></figure>
<blockquote>
<p><strong>输出结果</strong><br>Name :  Zara ,Salary:  2000<br>Name :  Manni ,Salary:  5000<br>Total Employee 2</p>
</blockquote>
<h1 id=""><a href="#" class="headerlink" title=" "></a> </h1><h2 id="重绑定empCount"><a href="#重绑定empCount" class="headerlink" title="重绑定empCount"></a>重绑定empCount</h2><h4 id="新的empCount值被写到emp1得特性中，屏蔽了类范围内的变量"><a href="#新的empCount值被写到emp1得特性中，屏蔽了类范围内的变量" class="headerlink" title="新的empCount值被写到emp1得特性中，屏蔽了类范围内的变量"></a>新的empCount值被写到emp1得特性中，屏蔽了类范围内的变量</h4><blockquote>
<p>emp1.empCount<br>2<br>emp2.empCount<br>2<br>emp1.empCount = “two”<br>emp1.empCount<br>“two”<br>emp2.empCount<br>2</p>
</blockquote>
<h1 id="-1"><a href="#-1" class="headerlink" title=" "></a> </h1><h2 id="类方法和静态方法"><a href="#类方法和静态方法" class="headerlink" title="类方法和静态方法"></a>类方法和静态方法</h2><p>@classmethod<br>我们要写一个只在类中运行而不在实例中运行的方法. 如果我们想让方法不在实例中运行，可以这么做:<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">iget_no_of_instance</span>(<span class="params">ins_obj</span>):</span></span><br><span class="line">    <span class="keyword">return</span> ins_obj.__class__.no_inst</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Kls</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    no_inst = <span class="number">0</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">    Kls.no_inst = Kls.no_inst + <span class="number">1</span></span><br><span class="line">ik1 = Kls()</span><br><span class="line">ik2 = Kls()</span><br><span class="line"><span class="built_in">print</span> iget_no_of_instance(ik1)</span><br></pre></td></tr></table></figure><br>输出：2</p>
<p>在Python2.2以后可以使用@classmethod装饰器来创建类方法.<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Kls</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    no_inst = <span class="number">0</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        Kls.no_inst = Kls.no_inst + <span class="number">1</span></span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_no_of_instance</span>(<span class="params">cls_obj</span>):</span></span><br><span class="line">        <span class="keyword">return</span> cls_obj.no_inst</span><br><span class="line">ik1 = Kls()</span><br><span class="line">ik2 = Kls()</span><br><span class="line"><span class="built_in">print</span> ik1.get_no_of_instance()</span><br><span class="line"><span class="built_in">print</span> Kls.get_no_of_instance()</span><br></pre></td></tr></table></figure><br>输出:<br>2<br>2<br>这样的好处是: 不管这个方式是从实例调用还是从类调用，它都用第一个参数把类传递过来.</p>
]]></content>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>scikit-learn的安装和基本使用教程</title>
    <url>/2016/05/22/scikit-learn%E7%9A%84%E5%AE%89%E8%A3%85%E5%92%8C%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/</url>
    <content><![CDATA[<h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>　　scikit-learn是Python的一个开源机器学习模块，它建立在NumPy，SciPy和matplotlib模块之上能够为用户提供各种机器学习算法接口，可以让用户简单、高效地进行数据挖掘和数据分析。<br><span id="more"></span></p>
<h2 id="scikit-learn安装"><a href="#scikit-learn安装" class="headerlink" title="scikit-learn安装"></a>scikit-learn安装</h2><p>python 中安装许多模板库之前都有依赖关系,安装 scikit-learn 之前需要以下先决条件:</p>
<pre><code>Python(&gt;= 2.6 or &gt;= 3.3)
NumPy (&gt;= 1.6.1)
SciPy (&gt;= 0.9)
</code></pre><p>如无意外,下面用 pip 的安装方法可以顺利完成~~<br><strong>安装 numpy</strong></p>
<pre><code>sudo pip install numpy
</code></pre><p><strong>安装 scipy</strong><br>需要先安装 matplotlib ipython ipython-notebook pandas sympy</p>
<pre><code>sudo apt-get install python-matplotlib ipython ipython-notebook
sudo apt-get install python-pandas python-sympy python-nose
sudo pip install scipy
</code></pre><p><strong>安装 scikit-learn</strong></p>
<pre><code>sudo pip install -U scikit-learn
</code></pre><p><strong>测试</strong><br>在 terminal 里面输入</p>
<pre><code>pip list
</code></pre><p>这个会列出 pip 安装的所有东西,如果里面有 sklearn 这一项,应该就是大功告成了!<br>或者尝试着将几个模板库导入进来</p>
<pre><code>import numpy
import scipy
import sklearn
</code></pre><h2 id="加载数据-Data-Loading"><a href="#加载数据-Data-Loading" class="headerlink" title="加载数据(Data Loading)"></a>加载数据(Data Loading)</h2><p>　　本文所使用的数据集为‘今日头条’近期两篇热门新闻“<a href="http://toutiao.com/a6285399016554496258/">牛！川大学霸寝室5人获16份名校通知书</a>”、“<a href="http://toutiao.com/a6282837243963048194/">张超凡的最后14天：山西15岁休学少年是如何殒命网吧的</a>”分别500条评论，共1000条评论。<br>　　去除停用词后得到了词库大小为3992的词库。因此构建了<code>1000×3992</code>的特征矩阵，以及长度为<code>1000</code>的对应评论所属类别列表<br>　　<a href="https://github.com/Hareric/Preprocessing">具体爬虫和特征矩阵构建代码</a><br>　　<a href="https://github.com/Hareric/Preprocessing/raw/master/dataSet/class_result_save.npy">class_result_save.npy下载</a>　　<a href="https://github.com/Hareric/Preprocessing/raw/master/dataSet/feature_matrix_save.npy">feature_matrix_save.npy下载</a><br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">feature_matrix = np.load(<span class="string">&#x27;dataSet/feature_matrix_save.npy&#x27;</span>)</span><br><span class="line">class_list = np.load(<span class="string">&#x27;dataSet/class_result_save.npy&#x27;</span>)</span><br></pre></td></tr></table></figure></p>
<h2 id="数据归一化-Data-Normalization"><a href="#数据归一化-Data-Normalization" class="headerlink" title="数据归一化(Data Normalization)"></a>数据归一化(Data Normalization)</h2><p>　　大多数机器学习算法中的梯度方法对于数据的缩放和尺度都是很敏感的，在开始跑算法之前，我们应该进行归一化或者标准化的过程，这使得特征数据缩放到0-1范围中。scikit-learn提供了归一化的方法：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> preprocessing</span><br><span class="line"><span class="comment"># 归一化（Normalization）</span></span><br><span class="line">normalized_X = preprocessing.normalize(feature_matrix)</span><br><span class="line"><span class="built_in">print</span> normalized_X</span><br><span class="line"><span class="comment"># 标准化（Standardization）</span></span><br><span class="line">standardized_X = preprocessing.scale(feature_matrix)</span><br><span class="line"><span class="built_in">print</span> standardized_X</span><br></pre></td></tr></table></figure></p>
<h2 id="特征选择-Feature-Selection"><a href="#特征选择-Feature-Selection" class="headerlink" title="特征选择(Feature Selection)"></a>特征选择(Feature Selection)</h2><p>　　在解决一个实际问题的过程中，选择合适的特征或者构建特征的能力特别重要。这成为特征选择或者特征工程。<br>特征选择时一个很需要创造力的过程，更多的依赖于直觉和专业知识，并且有很多现成的算法来进行特征的选择。<br>下面的树算法(Tree algorithms)计算特征的信息量：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> ExtraTreesClassifier</span><br><span class="line">model = ExtraTreesClassifier()</span><br><span class="line"><span class="built_in">print</span> feature_matrix.shape  <span class="comment"># 原特征矩阵规模</span></span><br><span class="line">feature_matrix = model.fit(feature_matrix, class_list).transform(feature_matrix)</span><br><span class="line"><span class="built_in">print</span> feature_matrix.shape  <span class="comment"># 特征选择后 特征矩阵的规模</span></span><br></pre></td></tr></table></figure></p>
<h2 id="特征提取-Feature-Extraction"><a href="#特征提取-Feature-Extraction" class="headerlink" title="特征提取(Feature Extraction)"></a>特征提取(Feature Extraction)</h2><p>　　用TFIDF算法来计算特征词的权重值是表示当一个词在这篇文档中出现的频率越高，同时在其他文档中出现的次数越少，则表明该词对于表示这篇文档的区分能力越强，所以其权重值就应该越大。<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> TfidfTransformer</span><br><span class="line">tfidf_transformer = TfidfTransformer()</span><br><span class="line">feature_matrix = tfidf_transformer.fit_transform(feature_matrix).toarray()</span><br></pre></td></tr></table></figure></p>
<h2 id="朴素贝叶斯-Naive-Bayes"><a href="#朴素贝叶斯-Naive-Bayes" class="headerlink" title="朴素贝叶斯(Naive Bayes)"></a>朴素贝叶斯(Naive Bayes)</h2><p>　　朴素贝叶斯是一个很著名的机器学习算法，主要是根据训练样本的特征来计算各个类别的概率，在多分类问题上用的比较多。<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"><span class="keyword">from</span> sklearn.naive_bayes <span class="keyword">import</span> GaussianNB</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构建朴素贝叶斯模型</span></span><br><span class="line">model = GaussianNB()</span><br><span class="line">model.fit(feature_matrix, class_list)</span><br><span class="line"><span class="built_in">print</span> model</span><br><span class="line"><span class="comment"># 使用测试集进行测试(此处将训练集做测试集)</span></span><br><span class="line">expected = class_list</span><br><span class="line">predicted = model.predict(feature_matrix)</span><br><span class="line"><span class="comment"># 输出测试效果</span></span><br><span class="line"><span class="built_in">print</span> metrics.classification_report(expected, predicted)</span><br><span class="line"><span class="built_in">print</span> metrics.confusion_matrix(expected, predicted)</span><br></pre></td></tr></table></figure></p>
<h2 id="k近邻-k-Nearest-Neighbours"><a href="#k近邻-k-Nearest-Neighbours" class="headerlink" title="k近邻(k-Nearest Neighbours)"></a>k近邻(k-Nearest Neighbours)</h2><p>　　k近邻算法常常被用作是分类算法一部分，比如可以用它来评估特征，在特征选择上我们可以用到它。<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构建knn模型</span></span><br><span class="line">model = KNeighborsClassifier()</span><br><span class="line">model.fit(feature_matrix, class_list)</span><br><span class="line"><span class="built_in">print</span> model</span><br><span class="line"><span class="comment"># 使用测试集进行测试(此处将训练集做测试集)</span></span><br><span class="line">expected = class_list</span><br><span class="line">predicted = model.predict(feature_matrix)</span><br><span class="line"><span class="comment"># 输出测试效果</span></span><br><span class="line"><span class="built_in">print</span> metrics.classification_report(expected, predicted)</span><br><span class="line"><span class="built_in">print</span> metrics.confusion_matrix(expected, predicted)</span><br></pre></td></tr></table></figure></p>
<h2 id="决策树-Decision-Tree"><a href="#决策树-Decision-Tree" class="headerlink" title="决策树(Decision Tree)"></a>决策树(Decision Tree)</h2><p>　　分类与回归树(Classification and Regression Trees ,CART)算法常用于特征含有类别信息的分类或者回归问题，这种方法非常适用于多分类情况。<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构建决策数模型</span></span><br><span class="line">model = DecisionTreeClassifier()</span><br><span class="line">model.fit(feature_matrix, class_list)</span><br><span class="line"><span class="built_in">print</span> model</span><br><span class="line"><span class="comment"># 使用测试集进行测试(此处将训练集做测试集)</span></span><br><span class="line">expected = class_list</span><br><span class="line">predicted = model.predict(feature_matrix)</span><br><span class="line"><span class="comment"># 输出测试效果</span></span><br><span class="line"><span class="built_in">print</span> metrics.classification_report(expected, predicted)</span><br><span class="line"><span class="built_in">print</span> metrics.confusion_matrix(expected, predicted)</span><br></pre></td></tr></table></figure></p>
]]></content>
      <tags>
        <tag>python</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>《Hadoop权威指南》ch5 Compression</title>
    <url>/2019/01/23/%E3%80%8AHadoop%E6%9D%83%E5%A8%81%E6%8C%87%E5%8D%97%E3%80%8Bch5%20Compression/</url>
    <content><![CDATA[<h2 id="Compression-压缩"><a href="#Compression-压缩" class="headerlink" title="Compression (压缩)"></a>Compression (压缩)</h2><p><strong>压缩的好处</strong></p>
<ul>
<li>减少文件所需空间</li>
<li>加速数据的在网络和磁盘上的传输<span id="more"></span>
<h3 id="Codec-Code-Decode"><a href="#Codec-Code-Decode" class="headerlink" title="Codec (Code-Decode)"></a>Codec (Code-Decode)</h3>Codec是Hadoop中的压缩-解压算法的实现。在hadoop中，实现<code>CompressionCodec</code>接口的类代表一个codec，下表列举了Hadoop实现的codec。</li>
</ul>
<p><img src="/img/tuchuang/master/resource/2019-01/hadoop_compression_format.png" alt="Hadoop_Compression_format"></p>
<h4 id="CompressionCodec"><a href="#CompressionCodec" class="headerlink" title="CompressionCodec"></a>CompressionCodec</h4><p><code>CompressionCode</code>包含两个函数，用于压缩和解压缩数据。</p>
<ul>
<li>压缩：通过<code>createOutputStream(OutputStream out)</code>方法获得<code>CompressionOutputStream</code>对象</li>
<li>解压：通过<code>createInputStream(InputStream in)</code>方法获得<code>CompressionInputStream</code>对象<br>压缩的示例代码<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.sweetop.styhadoop;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IOUtils;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.compress.CompressionCodec;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.compress.CompressionOutputStream;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.util.ReflectionUtils;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">StreamCompressor</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        String codecClassName = args[<span class="number">0</span>];</span><br><span class="line">        Class&lt;?&gt; codecClass = Class.forName(codecClassName);</span><br><span class="line">        Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">        CompressionCodec codec = (CompressionCodec) ReflectionUtils.newInstance(codecClass, conf);</span><br><span class="line"> </span><br><span class="line">        CompressionOutputStream out = codec.createOutputStream(System.out);</span><br><span class="line">        IOUtils.copyBytes(System.in, out, <span class="number">4096</span>, <span class="keyword">false</span>);</span><br><span class="line">        out.finish();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
从命令行接受一个CompressionCodec实现类的参数，然后通过ReflectionUtils把实例化这个类，调用CompressionCodec的接口方法对标准输出流进行封装，封装成一个压缩流，通过IOUtils类的copyBytes方法把标准输入流拷贝到压缩流中，最后调用CompressionCodec的finish方法，完成压缩。</li>
</ul>
<h4 id="CompressionCodecFactory"><a href="#CompressionCodecFactory" class="headerlink" title="CompressionCodecFactory"></a>CompressionCodecFactory</h4><p>如果你想读取一个被压缩的文件的话，首先你得先通过扩展名判断该用哪种codec。如前面的表可得，若文件名后缀为.gz，则需要用<code>GzipCodec</code>来读取。</p>
<p>也可以使用<code>CompressionCodecFactory</code>的<code>getCodec()</code>方法，通过传入一个Path,即可获得相应得codec。<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.sweetop.styhadoop;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FileSystem;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IOUtils;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.compress.CompressionCodec;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.compress.CompressionCodecFactory;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.io.InputStream;</span><br><span class="line"><span class="keyword">import</span> java.io.OutputStream;</span><br><span class="line"><span class="keyword">import</span> java.net.URI;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">FileDecompressor</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        String uri = args[<span class="number">0</span>];</span><br><span class="line">        Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">        FileSystem fs = FileSystem.get(URI.create(uri), conf);</span><br><span class="line"> </span><br><span class="line">        Path inputPath = <span class="keyword">new</span> Path(uri);</span><br><span class="line">        CompressionCodecFactory factory = <span class="keyword">new</span> CompressionCodecFactory(conf);</span><br><span class="line">        CompressionCodec codec = factory.getCodec(inputPath);</span><br><span class="line">        <span class="keyword">if</span> (codec == <span class="keyword">null</span>) &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;No codec found for &quot;</span> + uri);</span><br><span class="line">            System.exit(<span class="number">1</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        String outputUri = CompressionCodecFactory.removeSuffix(uri, codec.getDefaultExtension());</span><br><span class="line"> </span><br><span class="line">        InputStream in = <span class="keyword">null</span>;</span><br><span class="line">        OutputStream out = <span class="keyword">null</span>;</span><br><span class="line"> </span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            in = codec.createInputStream(fs.open(inputPath));</span><br><span class="line">            out = fs.create(<span class="keyword">new</span> Path(outputUri));</span><br><span class="line">            IOUtils.copyBytes(in,out,conf);</span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            IOUtils.closeStream(in);</span><br><span class="line">            IOUtils.closeStream(out);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>注意看下removeSuffix方法，这是一个静态方法，它可以将文件的后缀去掉，然后我们将这个路径做为解压的输出路径。</p>
<p>CompressionCodecFactory能找到的code默认只有三种 </p>
<ul>
<li>org.apache.hadoop.io.compress.GzipCodec</li>
<li>org.apache.hadoop.io.compress.BZip2Codec</li>
<li>org.apache.hadoop.io.compress.DefaultCodec</li>
</ul>
<p>如果想添加其他的codec你需要更改io.compression.codecs属性，并注册codec。</p>
<h4 id="Native-libraries-原生类库"><a href="#Native-libraries-原生类库" class="headerlink" title="Native libraries(原生类库)"></a>Native libraries(原生类库)</h4><p>通常情况下，使用Native libraries来实现解压缩会获得更高的性能。所有的解压缩格式都有原生类库，但并非都有java实现。如下表所示。<br><img src="/img/tuchuang/master/resource/2019-01/hadoop解压缩源生类库.png" alt="hadoop压缩原生类库"></p>
<p>默认情况下，Hadoop会根据自身运行的平台搜索原生代码库并自动加载，无需要做配置。当需要禁用原生代码库时，需要将<code>io.native.lib.available</code>设置为<code>false</code>。</p>
<h4 id="CodePool"><a href="#CodePool" class="headerlink" title="CodePool"></a>CodePool</h4><p>如果使用原生代码库执行大量解压缩，可以使用CodePool，支持反复使用，从而减少了创建对象的开销。<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">PooledStreamCompressor</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123; </span><br><span class="line">        String codecClassname = args[<span class="number">0</span>];</span><br><span class="line">        Class&lt;?&gt; codecClass = Class.forName(codecClassname); </span><br><span class="line">        Configuration conf = <span class="keyword">new</span> Configuration(); </span><br><span class="line">        CompressionCodec codec = (CompressionCodec) ReflectionUtils.newInstance(codecClass, conf); </span><br><span class="line">        Compressor compressor = <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            compressor = CodecPool.getCompressor(codec);</span><br><span class="line">            CompressionOutputStream out = codec.createOutputStream(System.out, compressor);</span><br><span class="line">            IOUtils.copyBytes(System.in, out, <span class="number">4096</span>, <span class="keyword">false</span>);</span><br><span class="line">            out.finish();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">finally</span> &#123;</span><br><span class="line">            CodecPool.returnCompressor(compressor);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure></p>
]]></content>
      <tags>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title>《Hadoop权威指南》ch5 Data Integrity</title>
    <url>/2019/01/25/%E3%80%8AHadoop%E6%9D%83%E5%A8%81%E6%8C%87%E5%8D%97%E3%80%8Bch5%20Data%20Integrity/</url>
    <content><![CDATA[<h2 id="Data-Integrity-数据完整性"><a href="#Data-Integrity-数据完整性" class="headerlink" title="Data Integrity(数据完整性)"></a>Data Integrity(数据完整性)</h2><p>尽管磁盘和网络的每个I/O操作，对数据造成损坏的可能性都很低，但是如果系统中需要处理的数据量大到Hadoop的处理极限时，数据被损坏的概率还是很高的。</p>
<span id="more"></span>
<h3 id="Checksum-校验和"><a href="#Checksum-校验和" class="headerlink" title="Checksum (校验和)"></a>Checksum (校验和)</h3><p>在数据第一次引入的时候计算checksum，当数据在进行传输后再计算一次checksum，若不同则代表数据已损坏。其中，校验和作为数据也是有可能损坏的，但是相比于普通数据要小的多，所以损坏的可能性也非常小。</p>
<p>常用的错误检测码为CRC-32（32-bit cyclic redundancy check 32位循环冗余校验），任何大小的数据输入均计算得出一个32位的整数校验和。</p>
<h3 id="Data-Integrity-in-HDFS"><a href="#Data-Integrity-in-HDFS" class="headerlink" title="Data Integrity in HDFS"></a>Data Integrity in HDFS</h3><ul>
<li><p><code>dfs.bytes-per-checksum</code>指定计算校验和字节的长度，默认为512个字节，CRC-32校验和是4个字节，因此存储数据的额外开销低于1%。</p>
</li>
<li><p><code>datanode</code>从客户端或者其它datanode收到数据后对数据进行验证。</p>
</li>
<li><p>每个datanode会保存<code>检验和日志(persistent log of checksum verification)</code>，用来保存每次验证的验证时间。</p>
</li>
<li><p>每个datanode也会在后台线程运行<code>DataBlockScanner</code>,定期验证该datanode上的数据块，该措施可用来解决数据的物理损坏。</p>
</li>
<li><p>每个HDFS存储着每个数据块的复本(replica),因此可以通过数据复本修复损坏的数据块。</p>
</li>
<li><p>在<code>open()</code>方法读取文件之前，可以将<code>FileSystem</code>实例的<code>setVerifyChecksum(false)</code>禁用校验和验证。该方法可以用来处理一些已损坏的数据，比如尝试是否能恢复部分数据。</p>
</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Tests read/seek/getPos/skipped opeation for input stream.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">testChecker</span><span class="params">(FileSystem fileSys, <span class="keyword">boolean</span> readCS)</span></span></span><br><span class="line"><span class="function"><span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">  Path file = <span class="keyword">new</span> Path(<span class="string">&quot;try.dat&quot;</span>);</span><br><span class="line">  writeFile(fileSys, file);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (!readCS) &#123;</span><br><span class="line">      fileSys.setVerifyChecksum(<span class="keyword">false</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    stm = fileSys.open(file);</span><br><span class="line">    checkReadAndGetPos();</span><br><span class="line">    checkSeek();</span><br><span class="line">    checkSkip();</span><br><span class="line">    <span class="comment">//checkMark</span></span><br><span class="line">    assertFalse(stm.markSupported());</span><br><span class="line">    stm.close();</span><br><span class="line">  &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (!readCS) &#123;</span><br><span class="line">      fileSys.setVerifyChecksum(<span class="keyword">true</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    cleanupFile(fileSys, file);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
]]></content>
      <tags>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title>python实用装饰器代码</title>
    <url>/2016/11/20/python%E5%AE%9E%E7%94%A8%E8%A3%85%E9%A5%B0%E5%99%A8%E4%BB%A3%E7%A0%81/</url>
    <content><![CDATA[<p>　　python装饰器是一种可以用来对函数进行装饰的面向对象的方法。<br>　　当想要对一个已有的模块做一些“修饰工作”，所谓修饰工作就是想给现有的模块加上一些小装饰（一些小功能，这些小功能可能好多模块都会用到），但又不让这个小装饰（小功能）侵入到原有的模块中的代码里去。我们便可以写成一个装饰器，哪些函数需要哪些修饰功能就可以直接在函数前套用装饰器。</p>
<span id="more"></span>
<h2 id="type-limit"><a href="#type-limit" class="headerlink" title="type_limit"></a>type_limit</h2><p><strong>用途</strong><br>　　限制函数的参数和返回值的类型<br><strong>装饰器代码</strong><br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LimitError</span>(<span class="params">Exception</span>):</span></span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line">    </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">type_limit</span>(<span class="params">*input_type, **return_type</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">test_value_type</span>(<span class="params">func</span>):</span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">wrapper</span>(<span class="params">*args, **kwargs</span>):</span></span><br><span class="line">            length = <span class="built_in">len</span>(input_type)</span><br><span class="line">            <span class="keyword">if</span> length != <span class="built_in">len</span>(args):</span><br><span class="line">                <span class="keyword">raise</span> LimitError(<span class="string">&quot;The list of typeLimit and param &quot;</span></span><br><span class="line">                                 <span class="string">&quot;must have the same length&quot;</span>)</span><br><span class="line">            <span class="keyword">for</span> index <span class="keyword">in</span> <span class="built_in">range</span>(length):</span><br><span class="line">                t = input_type[index]</span><br><span class="line">                p = args[index]</span><br><span class="line">                <span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">isinstance</span>(p, t):</span><br><span class="line">                    <span class="keyword">raise</span> LimitError(<span class="string">&quot;The param %s should be %s,&quot;</span></span><br><span class="line">                                     <span class="string">&quot;but it&#x27;s %s now!&quot;</span> % (<span class="built_in">str</span>(p), t, <span class="built_in">type</span>(p)))</span><br><span class="line">            res = func(*args, **kwargs)</span><br><span class="line">            <span class="keyword">if</span> <span class="string">&quot;return_type&quot;</span> <span class="keyword">in</span> return_type:</span><br><span class="line">                limit = return_type[<span class="string">&quot;return_type&quot;</span>]</span><br><span class="line">                <span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">isinstance</span>(res, limit):</span><br><span class="line">                    <span class="keyword">raise</span> LimitError(</span><br><span class="line">                        <span class="string">&quot;This function must return a value that is %s,&quot;</span></span><br><span class="line">                        <span class="string">&quot;but now it&#x27;s %s&quot;</span> % (limit, <span class="built_in">type</span>(res)))</span><br><span class="line">            <span class="keyword">return</span> res</span><br><span class="line">        <span class="keyword">return</span> wrapper</span><br><span class="line">    <span class="keyword">return</span> test_value_type</span><br></pre></td></tr></table></figure><br><strong>使用方法</strong><br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">@type_limit(<span class="params"><span class="built_in">int</span>, <span class="built_in">int</span>, return_type=<span class="built_in">int</span></span>)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">add</span>(<span class="params">a, b</span>):</span></span><br><span class="line">    <span class="keyword">return</span> a + b</span><br></pre></td></tr></table></figure></p>
<h2 id="exe-time"><a href="#exe-time" class="headerlink" title="exe_time"></a>exe_time</h2><p><strong>用途</strong><br>　　输出函数运行时间<br><strong>装饰器代码</strong><br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">exe_time</span>(<span class="params">func</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">wrapper</span>(<span class="params">*args, **kwargs</span>):</span></span><br><span class="line">        t0 = time.time()</span><br><span class="line">        sys.stdout.write(<span class="string">&#x27;\033[0;32;0m&#x27;</span>)</span><br><span class="line">        <span class="built_in">print</span> <span class="string">&quot;-----------------------------------&quot;</span></span><br><span class="line">        <span class="built_in">print</span> <span class="string">&quot;%s,function \033[4;32;0m%s()\033[0m\033[0;32;0m start&quot;</span> \</span><br><span class="line">              % (time.strftime(<span class="string">&quot;%X&quot;</span>, time.localtime()), func.__name__)</span><br><span class="line">        sys.stdout.write(<span class="string">&#x27;\033[0m&#x27;</span>)</span><br><span class="line">        res = func(*args, **kwargs)</span><br><span class="line">        sys.stdout.write(<span class="string">&#x27;\033[0;32;0m&#x27;</span>)</span><br><span class="line">        <span class="built_in">print</span> <span class="string">&quot;%s,function \033[4;32;0m%s()\033[0m\033[0;32;0m end&quot;</span> \</span><br><span class="line">              % (time.strftime(<span class="string">&quot;%X&quot;</span>, time.localtime()), func.__name__)</span><br><span class="line">        <span class="built_in">print</span> <span class="string">&quot;%.3fs taken for function \033[4;32;0m%s()\033[0m\033[0;32;0m&quot;</span> \</span><br><span class="line">              % (time.time() - t0, func.__name__)</span><br><span class="line">        <span class="built_in">print</span> <span class="string">&quot;-----------------------------------&quot;</span></span><br><span class="line">        sys.stdout.write(<span class="string">&#x27;\033[0m&#x27;</span>)</span><br><span class="line">        <span class="keyword">return</span> res</span><br><span class="line">    <span class="keyword">return</span> wrapper</span><br></pre></td></tr></table></figure><br><strong>使用方法</strong><br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">@exe_time</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">func</span>():</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100000</span>):</span><br><span class="line">        <span class="keyword">pass</span></span><br></pre></td></tr></table></figure></p>
]]></content>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>《Hadoop权威指南》ch6 MapReduce配置</title>
    <url>/2019/01/29/%E3%80%8AHadoop%E6%9D%83%E5%A8%81%E6%8C%87%E5%8D%97%E3%80%8Bch6%20MapReduce%E9%85%8D%E7%BD%AE/</url>
    <content><![CDATA[<h2 id="Hadoop-Configuration-API"><a href="#Hadoop-Configuration-API" class="headerlink" title="Hadoop Configuration API"></a>Hadoop Configuration API</h2><p>Hadoop中的组件Components是通过Hadoop自带的API进行配置的。一个Configuration类（<code>org.apache.hadoop.conf</code>）的实例代表配置属性及其取值的一个集合。每个属性有一个String进行命名并作为一个key，而值的类型包括Java的基本类型如（boolean、int、long、float等）。Configuration实例可以从XML文件中读取属性值。</p>
<span id="more"></span>
<h3 id="XML配置文件的创建及使用"><a href="#XML配置文件的创建及使用" class="headerlink" title="XML配置文件的创建及使用"></a>XML配置文件的创建及使用</h3><ul>
<li>一个简单的配置文件<code>configuration-1.xml</code><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>color<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>yellow<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>size<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>10<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>weight<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>heavy<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">final</span>&gt;</span>true<span class="tag">&lt;/<span class="name">final</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>size-weight<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>$&#123;size&#125;,$&#123;weight&#125;<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
配置文件需要放置在MapReduce项目的src目录下。<br><img src="/img/tuchuang/master/resource/2019-01/xml_configuration.png" alt="xml 配置文件路径"><br>实例化Configuration，并使用get()方法获取指定属性的值。另外，get()方法允许为XML文件中没有定义的属性指定默认值。</li>
<li>Java代码如下<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.*;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestConfiguration</span> </span>&#123;</span><br><span class="line">	</span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception</span>&#123;</span><br><span class="line">		Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">		conf.addResource(<span class="string">&quot;configuration-1.xml&quot;</span>);		</span><br><span class="line">		</span><br><span class="line">		System.out.println(conf.get(<span class="string">&quot;color&quot;</span>));  <span class="comment">// 输出为“yello”</span></span><br><span class="line">		System.out.println(conf.getInt(<span class="string">&quot;size&quot;</span>, <span class="number">0</span>));  <span class="comment">// 输出为10</span></span><br><span class="line">		System.out.println(conf.get(<span class="string">&quot;breadth&quot;</span>, <span class="string">&quot;wide&quot;</span>));   <span class="comment">//输出为“wide”</span></span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="资源合并（Combining-Resource）"><a href="#资源合并（Combining-Resource）" class="headerlink" title="资源合并（Combining Resource）"></a>资源合并（Combining Resource）</h3><p>Configuration类是添加多个配置文件的，后来添加到资源文件的属性会覆盖之前的定义属性。但若属性的final值为true的话，意味该属性值不能被后面的定义所覆盖。若尝试着覆盖，将会弹出警告消息帮助进行故障诊断。</p>
<ul>
<li>第二个配置文件<code>configuration-2.xml</code><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>size<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>12<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>weight<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>light<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<ul>
<li>Java代码如下<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.*;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestConfiguration</span> </span>&#123;</span><br><span class="line">	</span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception</span>&#123;</span><br><span class="line">		Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">		conf.addResource(<span class="string">&quot;configuration-1.xml&quot;</span>);</span><br><span class="line">		conf.addResource(<span class="string">&quot;configuration-2.xml&quot;</span>);</span><br><span class="line">		</span><br><span class="line"> 		System.out.println(conf.getInt(<span class="string">&quot;size&quot;</span>, <span class="number">0</span>));  <span class="comment">// 输出为12，size属性值被第二个配置文件覆盖</span></span><br><span class="line">		System.out.println(conf.get(<span class="string">&quot;weight&quot;</span>));  <span class="comment">// 输出为&quot;light&quot;，weight属性的final值为true，无法被覆盖输出不变</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
因尝试着override weight属性值，报以下警告<br><img src="/img/tuchuang/master/resource/2019-01/overrideXML_WARN.png" alt="override warn"></li>
</ul>
</li>
</ul>
<h3 id="变量扩展（Variable-Expansion）"><a href="#变量扩展（Variable-Expansion）" class="headerlink" title="变量扩展（Variable Expansion）"></a>变量扩展（Variable Expansion）</h3><p>配置文件可以定义配置属性，如第一个配置文件中，size-weight订了${size}和${weight}。<br>此外，在程序中可以另外定义系统属性，系统属性的优先级高于资源文件中定义的配置属性。<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.*;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestConfiguration</span> </span>&#123;</span><br><span class="line">	</span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception</span>&#123;</span><br><span class="line">		Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">		conf.addResource(<span class="string">&quot;configuration-1.xml&quot;</span>);</span><br><span class="line">		conf.addResource(<span class="string">&quot;configuration-2.xml&quot;</span>);</span><br><span class="line">		</span><br><span class="line">		System.setProperty(<span class="string">&quot;size&quot;</span>, <span class="string">&quot;14&quot;</span>);  <span class="comment">// 配置属性可以用系统属性进行定义</span></span><br><span class="line">		System.setProperty(<span class="string">&quot;weight&quot;</span>, <span class="string">&quot;super heavy&quot;</span>);</span><br><span class="line">		System.out.println(<span class="string">&quot;系统属性size为 &quot;</span> + System.getProperty(<span class="string">&quot;size&quot;</span>));  <span class="comment">// 输出为14</span></span><br><span class="line">		System.out.println(<span class="string">&quot;系统属性weight为 &quot;</span> + System.getProperty(<span class="string">&quot;weight&quot;</span>));  <span class="comment">// 输出为super heavy</span></span><br><span class="line">		System.out.println(<span class="string">&quot;配置属性size为 &quot;</span> + conf.get(<span class="string">&quot;size&quot;</span>));  <span class="comment">// 输出值仍为12</span></span><br><span class="line">		System.out.println(<span class="string">&quot;配置属性weight为 &quot;</span> + conf.get(<span class="string">&quot;weight&quot;</span>));  <span class="comment">// 输出值仍为light</span></span><br><span class="line">		</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure></p>
<h3 id="辅助类GenericOptionsParser-Tool和ToolRunner"><a href="#辅助类GenericOptionsParser-Tool和ToolRunner" class="headerlink" title="辅助类GenericOptionsParser, Tool和ToolRunner"></a>辅助类GenericOptionsParser, Tool和ToolRunner</h3><p>Hadoop提供了辅助类，GenericOptionsParser：用来解释常用的Hadoop命令选项，但是一般更常用的方式:实现Tool接口，通过ToolsRunner来运行程序，ToolRunner内部调用GenericOptionsParser<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> configuration;</span><br><span class="line"><span class="keyword">import</span> java.util.Map.Entry;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.*;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.util.*;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ConfigurationPrinter</span> <span class="keyword">extends</span> <span class="title">Configured</span> <span class="keyword">implements</span> <span class="title">Tool</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 将配置文件添加进资源，若配置无需修改（即src文件夹无配置文件），则无需执行 </span></span><br><span class="line"><span class="comment">//	static &#123;</span></span><br><span class="line"><span class="comment">//        Configuration.addDefaultResource(&quot;hdfs-default.xml&quot;);</span></span><br><span class="line"><span class="comment">//        Configuration.addDefaultResource(&quot;hdfs-site.xml&quot;);</span></span><br><span class="line"><span class="comment">//        Configuration.addDefaultResource(&quot;mapred-default.xml&quot;);</span></span><br><span class="line"><span class="comment">//        Configuration.addDefaultResource(&quot;mapred-site.xml&quot;);</span></span><br><span class="line"><span class="comment">//    &#125;</span></span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">run</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        Configuration conf = getConf();</span><br><span class="line">        <span class="keyword">for</span> (Entry&lt;String, String&gt; entry : conf) &#123;</span><br><span class="line">            System.out.printf(<span class="string">&quot;%s=%s\n&quot;</span>, entry.getKey(), entry.getValue());</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> exitCode = ToolRunner.run(<span class="keyword">new</span> ConfigurationPrinter(), args);</span><br><span class="line">        System.exit(exitCode);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><br>ConfigurationPrinter的main()没有直接调用自身的run()，而是调用了ToolRunner的静态run()方法，<strong>该方法在调用自身的run()之前，为Tool建立一个Configuration对象。</strong></p>
]]></content>
      <tags>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title>一趟聚类（One-pass Cluster）及python实现</title>
    <url>/2016/07/06/%E4%B8%80%E8%B6%9F%E8%81%9A%E7%B1%BB(One-Pass%20Cluster)%E5%8F%8Apython%E5%AE%9E%E7%8E%B0/</url>
    <content><![CDATA[<h2 id="一趟聚类简介"><a href="#一趟聚类简介" class="headerlink" title="一趟聚类简介"></a>一趟聚类简介</h2><p>一趟聚类算法是由蒋盛益教授提出的无监督聚类算法，该算法具有高效，简单的特点。数据集只需要遍历一遍即可完成聚类。算法对超球状分布的数据有良好的识别，对凸型数据分布识别较差。 一趟聚类可以在大规模数据，或者二次聚类中，或者聚类与其他算法结合的情况下，发挥其高效，简单的特点；<br><span id="more"></span></p>
<h2 id="算法流程"><a href="#算法流程" class="headerlink" title="算法流程"></a>算法流程</h2><ol>
<li>初始时从数据集读入一个新的对象</li>
<li>以这个对象构建一个新的簇</li>
<li>若达到数据集末尾,则转6,否则读入一个新的对象;计算它与每个已有簇之间的距离，并选择与它<strong>距离最小</strong>的簇</li>
<li>若最小距离超过给定的<strong>阈值r</strong>,转2</li>
<li>否则将对象并入该簇，并<strong>更新簇心</strong>，转3</li>
<li>结束</li>
</ol>
<h2 id="距离公式"><a href="#距离公式" class="headerlink" title="距离公式"></a>距离公式</h2><p>在本算法中，我采用的是欧氏距离公式计算节点与簇心之间的距离<br>欧氏距离公式<br><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/bfa1815838113388d78c9402bba7308d734a4af2" alt="欧氏距离公式"><br>在python代码中,使用numpy包可以轻易地实现<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">def euclidian_distance(vec_a, vec_b):</span><br><span class="line">    return np.sqrt(np.sum(np.square(np.array(vec_a) - vec_b)))</span><br></pre></td></tr></table></figure></p>
<h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><h3 id="核心代码"><a href="#核心代码" class="headerlink" title="核心代码"></a>核心代码</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">clustering</span>(<span class="params">self</span>):</span></span><br><span class="line">    self.cluster_list.append(ClusterUnit())  <span class="comment"># 初始新建一个簇</span></span><br><span class="line">    self.cluster_list[<span class="number">0</span>].add_node(<span class="number">0</span>, self.vectors[<span class="number">0</span>])  <span class="comment"># 将读入的第一个节点归于该簇</span></span><br><span class="line">    <span class="keyword">for</span> index <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(self.vectors))[<span class="number">1</span>:]:</span><br><span class="line">        min_distance = euclidian_distance(vec_a=self.vectors[<span class="number">0</span>],</span><br><span class="line">                                          vec_b=self.cluster_list[<span class="number">0</span>].centroid)  <span class="comment"># 与簇的质心的最小距离</span></span><br><span class="line">        min_cluster_index = <span class="number">0</span>  <span class="comment"># 最小距离的簇的索引</span></span><br><span class="line">        <span class="keyword">for</span> cluster_index, cluster <span class="keyword">in</span> <span class="built_in">enumerate</span>(self.cluster_list[<span class="number">1</span>:]):</span><br><span class="line">            <span class="comment"># 寻找距离最小的簇，记录下距离和对应的簇的索引</span></span><br><span class="line">            distance = euclidian_distance(vec_a=self.vectors[index],</span><br><span class="line">                                          vec_b=cluster.centroid)</span><br><span class="line">            <span class="keyword">if</span> distance &lt; min_distance:</span><br><span class="line">                min_distance = distance</span><br><span class="line">                min_cluster_index = cluster_index + <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> min_distance &lt; self.threshold:  <span class="comment"># 最小距离小于阀值,则归于该簇</span></span><br><span class="line">            self.cluster_list[min_cluster_index].add_node(index, self.vectors[index])</span><br><span class="line">        <span class="keyword">else</span>:  <span class="comment"># 否则新建一个簇</span></span><br><span class="line">            new_cluster = ClusterUnit()</span><br><span class="line">            new_cluster.add_node(index, self.vectors[index])</span><br><span class="line">            self.cluster_list.append(new_cluster)</span><br><span class="line">            <span class="keyword">del</span> new_cluster</span><br></pre></td></tr></table></figure>
<h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><h3 id="实验说明"><a href="#实验说明" class="headerlink" title="实验说明"></a>实验说明</h3><p>　　现有中国天气的<a href="/img/tuchuang/master/Other/c2.txt">数据集</a>,数据包括中国各个城市每年的最低和最高温以及该城市的x，y坐标。<br>　　现在分别使用nltk包中自带的k-mean聚类算法和上述的一趟聚类算法对中国城市的气温情况进行聚类。每个城市的属性只考虑2个属性分别为最高气温和最低气温。<br>　　最后使用matplotlib包对聚类结果进行构图。<br>　　其中k-means,初始设定的k的个数为5; 一趟聚类,阈值初始设置为9,最后聚类出10个簇。</p>
<h3 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h3><h4 id="运行时间"><a href="#运行时间" class="headerlink" title="运行时间"></a><strong>运行时间</strong></h4><p>针对该份数据集,通过多次运行计算运行时间求平均值<br>得出：<br><strong>k-means</strong>: 0.00024s<br><strong>one-pass cluster</strong>: 0.00008s<br>不难看出一趟聚类由于算法自身的简单,<strong>运行速度</strong>相比于k-means有显著的<strong>提升</strong>。</p>
<h4 id="聚类效果"><a href="#聚类效果" class="headerlink" title="聚类效果"></a><strong>聚类效果</strong></h4><p>不能只看运行时间，我们同样也要观察聚类的效果如何。现有2幅分别为k-means和一趟聚类的效果图。</p>
<p>k-means聚类效果图<br><img src="https://github.com/Hareric/ClusterTool/raw/master/Other/img/temp_KMeans.png" alt="k-means聚类效果图"></p>
<p>一趟聚类效果图<br><img src="https://github.com/Hareric/ClusterTool/raw/master/Other/img/temp_OnePassCluster.png" alt="一趟聚类效果图"></p>
<p>中国年平均气温图<br>　　　　　　　　<img src="/img/tuchuang/master/Other/img/%E4%B8%AD%E5%9B%BD%E6%B0%94%E6%B8%A9%E5%9B%BE.JPG" alt="中国年平均气温图"></p>
<p>　　通过简单的目测对比可得,一趟聚类和k-means聚类的效果都能够有效地反映出中国气温的分布。综上所述，一趟聚类是一种较为有效的聚类算法，考虑到它的算法简单，该算法在处理大数据上有着显著的优越性。<br>　　<br>　　<br><a href="https://github.com/Hareric/ClusterTool">完整代码</a></p>
]]></content>
      <tags>
        <tag>python</tag>
        <tag>聚类</tag>
      </tags>
  </entry>
  <entry>
    <title>使用MySQLdb对mysql数据库的进行读写</title>
    <url>/2016/04/23/%E4%BD%BF%E7%94%A8MySQLdb%E5%AF%B9mysql%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E8%BF%9B%E8%A1%8C%E8%AF%BB%E5%86%99/</url>
    <content><![CDATA[<p>MySQL是一个小型关系型数据库管理系统，开发者为瑞典MySQLAB公司。在2008年1月16号被Sun公司收购。目前MySQL被广泛地应用在Internet上的中小型网站中。由于其体积小、速度快、总体拥有成本低，尤其是开放源码这一特点，许多中小型网站为了降低网站总体拥有成本而选择了MySQL作为网站数据库。<br><span id="more"></span></p>
<h2 id="创建数据库表"><a href="#创建数据库表" class="headerlink" title="创建数据库表"></a>创建数据库表</h2><h3 id="如果数据库连接存在我们可以使用execute-方法来为数据库创建表，如下所示创建表EMPLOYEE："><a href="#如果数据库连接存在我们可以使用execute-方法来为数据库创建表，如下所示创建表EMPLOYEE：" class="headerlink" title="如果数据库连接存在我们可以使用execute()方法来为数据库创建表，如下所示创建表EMPLOYEE："></a>如果数据库连接存在我们可以使用execute()方法来为数据库创建表，如下所示创建表EMPLOYEE：</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> MySQLdb</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打开数据库连接</span></span><br><span class="line">db = MySQLdb.connect(<span class="string">&quot;localhost&quot;</span>,<span class="string">&quot;testuser&quot;</span>,<span class="string">&quot;test123&quot;</span>,<span class="string">&quot;TESTDB&quot;</span> )</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用cursor()方法获取操作游标 </span></span><br><span class="line">cursor = db.cursor()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果数据表已经存在使用 execute() 方法删除表。</span></span><br><span class="line">cursor.execute(<span class="string">&quot;DROP TABLE IF EXISTS EMPLOYEE&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建数据表SQL语句</span></span><br><span class="line">sql = <span class="string">&quot;&quot;&quot;CREATE TABLE EMPLOYEE (</span></span><br><span class="line"><span class="string">         FIRST_NAME  CHAR(20) NOT NULL,</span></span><br><span class="line"><span class="string">         LAST_NAME  CHAR(20),</span></span><br><span class="line"><span class="string">         AGE INT,  </span></span><br><span class="line"><span class="string">         SEX CHAR(1),</span></span><br><span class="line"><span class="string">         INCOME FLOAT )&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">cursor.execute(sql)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 关闭数据库连接</span></span><br><span class="line">db.close()</span><br></pre></td></tr></table></figure>
<h1 id=""><a href="#" class="headerlink" title=" "></a> </h1><h2 id="数据库插入操作"><a href="#数据库插入操作" class="headerlink" title="数据库插入操作"></a>数据库插入操作</h2><h3 id="以下实例使用执行-SQL-INSERT-语句向表-EMPLOYEE-插入记录："><a href="#以下实例使用执行-SQL-INSERT-语句向表-EMPLOYEE-插入记录：" class="headerlink" title="以下实例使用执行 SQL INSERT 语句向表 EMPLOYEE 插入记录："></a>以下实例使用执行 SQL INSERT 语句向表 EMPLOYEE 插入记录：</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> MySQLdb</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打开数据库连接</span></span><br><span class="line">db = MySQLdb.connect(<span class="string">&quot;localhost&quot;</span>,<span class="string">&quot;testuser&quot;</span>,<span class="string">&quot;test123&quot;</span>,<span class="string">&quot;TESTDB&quot;</span> )</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用cursor()方法获取操作游标 </span></span><br><span class="line">cursor = db.cursor()</span><br><span class="line"></span><br><span class="line"><span class="comment"># SQL 插入语句</span></span><br><span class="line">sql = <span class="string">&quot;&quot;&quot;INSERT INTO EMPLOYEE(FIRST_NAME,</span></span><br><span class="line"><span class="string">         LAST_NAME, AGE, SEX, INCOME)</span></span><br><span class="line"><span class="string">         VALUES (&#x27;Mac&#x27;, &#x27;Mohan&#x27;, 20, &#x27;M&#x27;, 2000)&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">   <span class="comment"># 执行sql语句</span></span><br><span class="line">   cursor.execute(sql)</span><br><span class="line">   <span class="comment"># 提交到数据库执行</span></span><br><span class="line">   db.commit()</span><br><span class="line"><span class="keyword">except</span>:</span><br><span class="line">   <span class="comment"># Rollback in case there is any error</span></span><br><span class="line">   db.rollback()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 关闭数据库连接</span></span><br><span class="line">db.close()</span><br></pre></td></tr></table></figure>
<h3 id="以上例子也可以写成如下形式："><a href="#以上例子也可以写成如下形式：" class="headerlink" title="以上例子也可以写成如下形式："></a>以上例子也可以写成如下形式：</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> MySQLdb</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打开数据库连接</span></span><br><span class="line">db = MySQLdb.connect(<span class="string">&quot;localhost&quot;</span>,<span class="string">&quot;testuser&quot;</span>,<span class="string">&quot;test123&quot;</span>,<span class="string">&quot;TESTDB&quot;</span> )</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用cursor()方法获取操作游标 </span></span><br><span class="line">cursor = db.cursor()</span><br><span class="line"></span><br><span class="line"><span class="comment"># SQL 插入语句</span></span><br><span class="line">sql = <span class="string">&quot;INSERT INTO EMPLOYEE(FIRST_NAME, \</span></span><br><span class="line"><span class="string">       LAST_NAME, AGE, SEX, INCOME) \</span></span><br><span class="line"><span class="string">       VALUES (&#x27;%s&#x27;, &#x27;%s&#x27;, &#x27;%d&#x27;, &#x27;%c&#x27;, &#x27;%d&#x27; )&quot;</span> % \</span><br><span class="line">       (<span class="string">&#x27;Mac&#x27;</span>, <span class="string">&#x27;Mohan&#x27;</span>, <span class="number">20</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">2000</span>)</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">   <span class="comment"># 执行sql语句</span></span><br><span class="line">   cursor.execute(sql)</span><br><span class="line">   <span class="comment"># 提交到数据库执行</span></span><br><span class="line">   db.commit()</span><br><span class="line"><span class="keyword">except</span>:</span><br><span class="line">   <span class="comment"># 发生错误时回滚</span></span><br><span class="line">   db.rollback()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 关闭数据库连接</span></span><br><span class="line">db.close()</span><br></pre></td></tr></table></figure>
]]></content>
      <tags>
        <tag>python</tag>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title>使用Pig对数据进行处理和分析</title>
    <url>/2019/02/25/%E4%BD%BF%E7%94%A8Pig%E5%AF%B9%E6%95%B0%E6%8D%AE%E8%BF%9B%E8%A1%8C%E5%A4%84%E7%90%86%E5%92%8C%E5%88%86%E6%9E%90/</url>
    <content><![CDATA[<p>本文将针对一份数据提出多个数据处理的相关问题，并介绍如何使用Apache Pig来解决相关的问题，建议读者根据具体问题具体实践后再查看我分享的解题Pig代码。<br><span id="more"></span></p>
<h2 id="数据"><a href="#数据" class="headerlink" title="数据"></a>数据</h2><h3 id="数据下载"><a href="#数据下载" class="headerlink" title="数据下载"></a>数据下载</h3><p>本文用到的数据是1999年至2004年的The Daily Show嘉宾的历史数据。<a href="/img/tuchuang/master/resource/2019-02/dialy_show_guests.txt">下载地址</a></p>
<h3 id="数据描述"><a href="#数据描述" class="headerlink" title="数据描述"></a>数据描述</h3><p><strong>YEAR</strong> – The year the episode aired.</p>
<p><strong>GoogleKnowlege_Occupation</strong> -Their occupation or office, according to Google’s Knowledge Graph. On the other hand, if they are not in there, how Stewart introduced them on the program.</p>
<p><strong>Show</strong> – Air date of the episode. Not unique, as some shows had more than one guest</p>
<p><strong>Group</strong> – A larger group designation for the occupation. For instance, U.S senators, U.S presidents, and former presidents are all under “politicians”</p>
<p><strong>Raw_Guest_List</strong> – The person or list of people who appeared on the show, according to Wikipedia. The GoogleKnowlege_Occupation only refers to one of them in a given row.</p>
<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><h3 id="问题1"><a href="#问题1" class="headerlink" title="问题1"></a>问题1</h3><p>在指定的时间范围内，根据<code>GoogleKnowlege_Occupation</code>的不同，找出最多的5种类型。</p>
<h4 id="pig代码"><a href="#pig代码" class="headerlink" title="pig代码"></a>pig代码</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">A = load <span class="string">&#x27;dialy_show_guests&#x27;</span> <span class="function">using <span class="title">PigStorage</span><span class="params">(<span class="string">&#x27;,&#x27;</span>)</span> </span></span><br><span class="line"><span class="function">	<span class="title">AS</span> <span class="params">(year:chararray,occupation:chararray,date:chararray,</span></span></span><br><span class="line"><span class="params"><span class="function">		groupName:chararray,gusetlist:chararray)</span></span>;</span><br><span class="line">C = foreach A generate occupation,ToDate(date,<span class="string">&#x27;MM/dd/yy&#x27;</span>) as date;</span><br><span class="line">D = <span class="function">filter C <span class="title">by</span> <span class="params">((date&gt; ToDate(<span class="string">&#x27;1/11/99&#x27;</span>,<span class="string">&#x27;MM/dd/yy&#x27;</span>)</span>) </span></span><br><span class="line"><span class="function">	<span class="title">AND</span> <span class="params">(date&lt;ToDate(<span class="string">&#x27;6/11/99&#x27;</span>,<span class="string">&#x27;MM/dd/yy&#x27;</span>)</span>))</span>;</span><br><span class="line">E = group D by occupation;</span><br><span class="line">F = foreach E generate group, COUNT(D) as cnt;</span><br><span class="line">describe F;</span><br><span class="line">G = order F by cnt desc;</span><br><span class="line">H = limit G <span class="number">5</span>;</span><br><span class="line">DUMP H;</span><br></pre></td></tr></table></figure>
<h4 id="输出结果"><a href="#输出结果" class="headerlink" title="输出结果"></a>输出结果</h4><blockquote>
<p>(actor,28)<br>(actress,20)<br>(comedian,4)<br>(television actress,3)<br>(singer,2)</p>
</blockquote>
<h3 id="问题2"><a href="#问题2" class="headerlink" title="问题2"></a>问题2</h3><p>根据<code>Group</code>,找出每年参加该show的politician的人数。</p>
<h4 id="pig-代码"><a href="#pig-代码" class="headerlink" title="pig 代码"></a>pig 代码</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">A = load <span class="string">&#x27;dialy_show_guests&#x27;</span> <span class="function">using <span class="title">PigStorage</span><span class="params">(<span class="string">&#x27;,&#x27;</span>)</span> </span></span><br><span class="line"><span class="function">	<span class="title">AS</span> <span class="params">(year:chararray,occupation:chararray,date:chararray,</span></span></span><br><span class="line"><span class="params"><span class="function">		groupName:chararray,gusetlist:chararray)</span></span>;</span><br><span class="line">B = FILTER A by groupName==<span class="string">&#x27;Politician&#x27;</span>;</span><br><span class="line">C = <span class="function">foreach B generate <span class="title">ToDate</span><span class="params">(date,<span class="string">&#x27;MM/dd/yy&#x27;</span>)</span> as date</span>;</span><br><span class="line">D = <span class="function">FOREACH C GENERATE  <span class="title">GetYear</span><span class="params">(date)</span> as y</span>;</span><br><span class="line">E = GROUP D by y;</span><br><span class="line">F = FOREACH E GENERATE group, COUNT(D) as cnt;</span><br><span class="line">DUMP F;</span><br></pre></td></tr></table></figure>
<p>在做这题的时候，没有发现数据已经提供了year数据域，于是我使用date数据域并提取了其中的年份，有些多此一举。</p>
<h4 id="输出结果-1"><a href="#输出结果-1" class="headerlink" title="输出结果"></a>输出结果</h4><blockquote>
<p>(1999,2)<br>(2000,13)<br>(2001,3)<br>(2002,8)<br>(2003,14)<br>(2004,32)<br>(2005,22)<br>(2006,25)<br>(2007,21)<br>(2008,27)<br>…</p>
</blockquote>
<h3 id="问题3"><a href="#问题3" class="headerlink" title="问题3"></a>问题3</h3><p>在数据描述中，Group数据类型与GoogleKnowledge occupation数据类型，是包含关系，本题是要统计每个group中有多少种不同的GoogleKnowledge occupation。</p>
<h4 id="pig-代码-1"><a href="#pig-代码-1" class="headerlink" title="pig 代码"></a>pig 代码</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">A = load <span class="string">&#x27;dialy_show_guests&#x27;</span> <span class="function">using <span class="title">PigStorage</span><span class="params">(<span class="string">&#x27;,&#x27;</span>)</span> </span></span><br><span class="line"><span class="function">	<span class="title">AS</span> <span class="params">(year:chararray,occupation:chararray,date:chararray,</span></span></span><br><span class="line"><span class="params"><span class="function">		groupName:chararray,gusetlist:chararray)</span></span>;</span><br><span class="line">B = FOREACH A GENERATE occupation, groupName;</span><br><span class="line">C = GROUP B by groupName;</span><br><span class="line">D = FOREACH C &#123;o = DISTINCT B.occupation; GENERATE group, COUNT(o) as cnt;&#125;;</span><br><span class="line">E = ORDER D BY cnt DESC ; </span><br><span class="line">DUMP E;</span><br></pre></td></tr></table></figure>
<h4 id="输出结果-2"><a href="#输出结果-2" class="headerlink" title="输出结果"></a>输出结果</h4><blockquote>
<p>(Politician,105)<br>(Media,80)<br>(Athletics,29)<br>(Government,27)<br>(Musician,25)<br>(Academic,24)<br>(Misc,16)<br>…</p>
</blockquote>
<h3 id="问题4"><a href="#问题4" class="headerlink" title="问题4"></a>问题4</h3><p>找出各个Group与GoogleKnowledge occupation组合类后的参加show的人数。</p>
<h4 id="pig-代码-2"><a href="#pig-代码-2" class="headerlink" title="pig 代码"></a>pig 代码</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">A = load <span class="string">&#x27;dialy_show_guests&#x27;</span> <span class="function">using <span class="title">PigStorage</span><span class="params">(<span class="string">&#x27;,&#x27;</span>)</span> </span></span><br><span class="line"><span class="function">	<span class="title">AS</span> <span class="params">(year:chararray,occupation:chararray,date:chararray,</span></span></span><br><span class="line"><span class="params"><span class="function">		groupName:chararray,gusetlist:chararray)</span></span>;</span><br><span class="line">B = <span class="function">GROUP A <span class="title">BY</span> <span class="params">(groupName, occupation)</span></span>;</span><br><span class="line">C = FOREACH B GENERATE group, COUNT(A) as cnt;</span><br><span class="line">D = ORDER C BY cnt desc;</span><br><span class="line">DUMP D; </span><br></pre></td></tr></table></figure>
<h4 id="输出结果-3"><a href="#输出结果-3" class="headerlink" title="输出结果"></a>输出结果</h4><blockquote>
<p>((Acting,actor),596)<br>((Acting,actress),271)<br>((Media,journalist),180)<br>((Media,author),102)<br>((Media,Journalist),72)<br>((Comedy,comedian),64)<br>((Politician,us senator),50)<br>((Media,Author),48)<br>((Media,television host),39)<br>((Comedy,Comedian),39)<br>((Media,writer),30)<br>…</p>
</blockquote>
]]></content>
      <tags>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title>哈希&amp;编码工具</title>
    <url>/2021/05/23/%E5%93%88%E5%B8%8C&amp;%E7%BC%96%E7%A0%81%E5%B7%A5%E5%85%B7/</url>
    <content><![CDATA[<iframe  
 height=900 
 width=95% 
 src="/dev_tools"  
 frameborder=0  
 allowfullscreen><br> </iframe>]]></content>
      <tags>
        <tag>开发工具</tag>
      </tags>
  </entry>
  <entry>
    <title>使用Eclipse+Java配置Pig开发环境</title>
    <url>/2019/02/22/%E4%BD%BF%E7%94%A8Eclipse-Java%E9%85%8D%E7%BD%AEPig%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83/</url>
    <content><![CDATA[<p>自从开始使用Eclipse+Maven来配置Java的开发环境并体验到了Maven的强大和方便以后。在之后学习Hadoop的过程中，我都尽量避免使用终端配置运行环境。</p>
<p>本文将介绍如何配置Eclipse在Pig中的开发环境。若还未使用过Maven配置Hadoop开发环境，可以参考我的另一篇<a href="http://hareric.com/2019/02/01/Eclipse+Maven%E6%9E%84%E5%BB%BAHadoop%E9%A1%B9%E7%9B%AE/">博客</a></p>
<span id="more"></span>
<h2 id="开发环境"><a href="#开发环境" class="headerlink" title="开发环境"></a>开发环境</h2><ul>
<li>系统：MacOS 10.14.1</li>
<li>Hadoop：2.7.0</li>
<li>Java：1.8.0</li>
<li>Eclipse：4.6.2</li>
<li>Maven: 3.3.9</li>
</ul>
<h2 id="Pig"><a href="#Pig" class="headerlink" title="Pig"></a>Pig</h2><h3 id="下载地址"><a href="#下载地址" class="headerlink" title="下载地址"></a>下载地址</h3><p>Apache Pig 的官方<a href="http://pig.apache.org/">下载地址</a></p>
<p>由于本文介绍的是用Eclipse开发，Maven配置，因此不需要从此网站下载。</p>
<h3 id="确定版本"><a href="#确定版本" class="headerlink" title="确定版本"></a>确定版本</h3><p>在下载前需要确定版本。</p>
<p>由于不同版本的Pig支持不同的版本的Hadoop，如下图所示。因此在开始配置前，需要确定自己的Hadoop版本并选择合适的Pig版本。</p>
<p>我使用的是Hadoop 2.7.0 只有Pig 0.17.0 可以支持。所以我选择0.17版本。</p>
<p><img src="/img/tuchuang/master/resource/2019-02/pig_release_for_hadoop.png" alt="Pig release for Hadoop"><br><a href="http://pig.apache.org/releases.html">其余版本介绍</a></p>
<h2 id="配置jar包"><a href="#配置jar包" class="headerlink" title="配置jar包"></a>配置jar包</h2><p>使用Java在Eclipse运行Pig代码，需要antlr，pig和pigunit包，因此需要在Maven Project的pom.xml添加以下依赖。</p>
<p>由于许多不可抗力，使用Apache原生的pig版本时一直无法配置成功，因此我选择Cloudera公司的发行版本，所以需要添加<a href="https://repository.cloudera.com/artifactory/cloudera-repos/">cloudera的资源库</a>。</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">repositories</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">repository</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">id</span>&gt;</span>cloudera<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">url</span>&gt;</span>https://repository.cloudera.com/artifactory/cloudera-repos/<span class="tag">&lt;/<span class="name">url</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">repository</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">repositories</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- https://mvnrepository.com/artifact/org.antlr/antlr4 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.antlr<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>antlr4<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>4.7.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.pig<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>pig<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>0.17.0-cdh6.0.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.pig<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>pigunit<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>0.17.0-cdh6.0.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h2 id="创建脚本"><a href="#创建脚本" class="headerlink" title="创建脚本"></a>创建脚本</h2><p>Apache Pig 提供了后缀名为脚本方式来处理数据。脚本是以后缀名为<code>.pig</code>的文本文件进行保存。</p>
<p>以下是一个pig脚本代码，统计单词的数量，将该脚本保存在src文件夹内<br><code>wordcount.pig</code>。<br><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">A = load <span class="string">&#x27;src/main/resources/pigData/sample.data&#x27;</span>;</span><br><span class="line">B = foreach A generate flatten(TOKENIZE((chararray)<span class="variable">$0</span>)) as word;</span><br><span class="line">C = group B by word;</span><br><span class="line">D = foreach C generate COUNT(B), group;</span><br><span class="line">dump D;</span><br></pre></td></tr></table></figure><br><code>sample.data</code>数据文件<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Johny, Johny!</span><br><span class="line">Yes, Papa</span><br><span class="line">Eating sugar?</span><br><span class="line">No, Papa</span><br><span class="line">Telling lies?</span><br><span class="line">No, Papa</span><br><span class="line">Open your mouth!</span><br><span class="line">Ha! Ha! Ha!</span><br></pre></td></tr></table></figure></p>
<h2 id="使用Java运行"><a href="#使用Java运行" class="headerlink" title="使用Java运行"></a>使用Java运行</h2><p>Pig 有两种运行模式： Local 模式和 MapReduce 模式。在Java中，可以通过<code>org.apache.pig.ExecType</code>进行设置</p>
<h3 id="PigServer"><a href="#PigServer" class="headerlink" title="PigServer"></a>PigServer</h3><p><code>PigRunner.java</code><br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.Properties;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.pig.ExecType;</span><br><span class="line"><span class="keyword">import</span> org.apache.pig.PigServer;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">PigRunner</span></span></span><br><span class="line"><span class="class"></span>&#123;</span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception</span></span><br><span class="line"><span class="function">	</span>&#123;</span><br><span class="line">		<span class="comment">// MapReduce 模式</span></span><br><span class="line">		Properties props = <span class="keyword">new</span> Properties();</span><br><span class="line">		props.setProperty(<span class="string">&quot;fs.default.name&quot;</span>, <span class="string">&quot;hdfs://localhost:9000&quot;</span>);</span><br><span class="line"><span class="comment">//		props.setProperty(&quot;mapred.job.tracker&quot;, &quot;http://localhost:50070&quot;);</span></span><br><span class="line">		PigServer pigServer = <span class="keyword">new</span> PigServer(ExecType.MAPREDUCE, props);</span><br><span class="line">		pigServer.registerScript(<span class="string">&quot;src/main/java/pig/wordcount.pig&quot;</span>);</span><br><span class="line"></span><br><span class="line">		<span class="comment">// local 模式</span></span><br><span class="line">		PigServer pigServer1 = <span class="keyword">new</span> PigServer(ExecType.LOCAL);</span><br><span class="line">		pigServer1.registerScript(<span class="string">&quot;src/main/java/pig/wordcount.pig&quot;</span>);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h3 id="PigTest"><a href="#PigTest" class="headerlink" title="PigTest"></a>PigTest</h3><p>PigTest提供了对Pig脚本所得的结果进行单元测试。<br><code>AppTest.java</code><br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.pig.pigunit.PigTest;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> junit.framework.*;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">AppTest</span> <span class="keyword">extends</span> <span class="title">TestCase</span></span></span><br><span class="line"><span class="class"></span>&#123;</span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testStudentsPigScript</span><span class="params">()</span> <span class="keyword">throws</span> Exception</span></span><br><span class="line"><span class="function">	</span>&#123;</span><br><span class="line">		PigTest pigTest = <span class="keyword">new</span> PigTest(<span class="string">&quot;src/main/java/pig/wordcount.pig&quot;</span>);</span><br><span class="line">		pigTest.assertOutput(<span class="string">&quot;D&quot;</span>, <span class="keyword">new</span> String[] &#123; <span class="string">&quot;(2,No)&quot;</span>, <span class="string">&quot;(3,Ha!)&quot;</span>, <span class="string">&quot;(1,Yes)&quot;</span>, <span class="string">&quot;(1,Open)&quot;</span>, <span class="string">&quot;(3,Papa)&quot;</span>, <span class="string">&quot;(1,your)&quot;</span>,</span><br><span class="line">				<span class="string">&quot;(1,Johny)&quot;</span>, <span class="string">&quot;(1,lies?)&quot;</span>, <span class="string">&quot;(1,Eating)&quot;</span>, <span class="string">&quot;(1,Johny!)&quot;</span>, <span class="string">&quot;(1,mouth!)&quot;</span>, <span class="string">&quot;(1,sugar?)&quot;</span>, <span class="string">&quot;(1,Telling)&quot;</span>&#125;);</span><br><span class="line">		</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>下图为上述文件在Java Project中的路径。可供读者进行参考<br><img src="/img/tuchuang/master/resource/2019-02/pig_src_path.png" alt="java project path"></p>
]]></content>
      <tags>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title>决策树之特征选择---信息增益</title>
    <url>/2016/05/19/%E5%86%B3%E7%AD%96%E6%A0%91%E4%B9%8B%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9---%E4%BF%A1%E6%81%AF%E5%A2%9E%E7%9B%8A/</url>
    <content><![CDATA[<p>　　基于信息增益的特征选取是一种广泛使用在决策树(decision tree)分类算法中用到的特征选取。该特征选择的方法是通过计算每个特征值划分数据集获得信息增益，通过比较信息增益的大小选取合适的特征值。<br><span id="more"></span></p>
<h3 id="一、定义"><a href="#一、定义" class="headerlink" title="一、定义"></a>一、定义</h3><h4 id="1-1-熵"><a href="#1-1-熵" class="headerlink" title="1.1 熵"></a>1.1 熵</h4><p>　　信息的期望值，可理解为数据集的无序度，熵的值越大，表示数据越无序，公式如下：<br>　　　　　　<img src="https://upload.wikimedia.org/math/d/b/7/db72f4463b48f5eb522c5bb92cae5028.png" alt="熵的计算公式"><br>　　其中<code>H</code>表示该数据集的熵值， <code>pi</code>表示类别<code>i</code>的概率， 若所有数据集只有一个类别，那么<code>pi=1</code>，<code>H=0</code>。因此<code>H=0</code>为熵的最小值，表示该数据集完全有序。</p>
<h4 id="1-2-信息增益"><a href="#1-2-信息增益" class="headerlink" title="1.2 信息增益"></a>1.2 信息增益</h4><p>　　熵的减少或者是数据无序度的减少。
　　</p>
<h3 id="二、流程"><a href="#二、流程" class="headerlink" title="二、流程"></a>二、流程</h3><p>1、计算原始数据的信息熵<code>H1</code><br>2、选取一个特征，根据特征值对数据进行分类，再对每个类别分别计算信息熵，按比例求和，得出这种划分方式的信息熵<code>H2</code><br>3、计算信息增益：<br>　　<code>infoGain = H1 - H2</code><br>4、根据2，3计算所有特征属性对应的信息增益，保留信息增益较大的特征属性。</p>
<h3 id="三、实例"><a href="#三、实例" class="headerlink" title="三、实例"></a>三、实例</h3><p>海洋生物数据</p>
<table>
<thead>
<tr>
<th style="text-align:center">被分类项\特征</th>
<th style="text-align:center">不浮出水面是否可以生存</th>
<th style="text-align:center">是否有脚蹼</th>
<th style="text-align:center">属于鱼类</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1</td>
<td style="text-align:center">是</td>
<td style="text-align:center">是</td>
<td style="text-align:center">是</td>
</tr>
<tr>
<td style="text-align:center">2</td>
<td style="text-align:center">是</td>
<td style="text-align:center">是</td>
<td style="text-align:center">是</td>
</tr>
<tr>
<td style="text-align:center">3</td>
<td style="text-align:center">是</td>
<td style="text-align:center">否</td>
<td style="text-align:center">否</td>
</tr>
<tr>
<td style="text-align:center">4</td>
<td style="text-align:center">否</td>
<td style="text-align:center">是</td>
<td style="text-align:center">否</td>
</tr>
<tr>
<td style="text-align:center">5</td>
<td style="text-align:center">否</td>
<td style="text-align:center">是</td>
<td style="text-align:center">否</td>
</tr>
</tbody>
</table>
<h4 id="3-1-原始数据信息熵"><a href="#3-1-原始数据信息熵" class="headerlink" title="3.1 原始数据信息熵"></a>3.1 原始数据信息熵</h4><p><code>p(是鱼类) = p1 =0.4</code><br><code>p(非鱼类) = p2 =0.6</code><br>通过信息熵公式可得原始数据信息熵 <code>H1 = 0.97095</code></p>
<h4 id="3-2-根据特征分类计算信息熵"><a href="#3-2-根据特征分类计算信息熵" class="headerlink" title="3.2 根据特征分类计算信息熵"></a>3.2 根据特征分类计算信息熵</h4><p>选择’不服出水面是否可以生存’作为分析的特征属性<br>可将数据集分为[1,2,3]与[4,5]，分别占0.6和0.4。<br>[1,2,3]可计算该类数据信息熵为 <code>h1=0.918295834054</code><br>[4,5] 可计算该类数据信息熵为 <code>h2=0</code><br>计算划分后的信息熵 <code>H2 = 0.6 * h1 + 0.4 * h2 = 0.550977500433</code></p>
<h4 id="3-3-计算信息增益"><a href="#3-3-计算信息增益" class="headerlink" title="3.3 计算信息增益"></a>3.3 计算信息增益</h4><p><code>infoGain_0 = H1-H2 = 0.419973094022</code></p>
<h4 id="3-4-特征选择"><a href="#3-4-特征选择" class="headerlink" title="3.4 特征选择"></a>3.4 特征选择</h4><p>同理可得对特征’是否有脚蹼’该特征计算信息增益 <code>infoGain_1 = 0.170950594455</code><br>比较可得，’不服出水面是否可以生存’所得的信息增益更大，因此在该实例中，该特征是最好用于划分数据集的特征</p>
<p>四、代码<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># coding=utf-8</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> math <span class="keyword">import</span> log</span><br><span class="line"></span><br><span class="line">data_feature_matrix = np.array([[<span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">                                [<span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">                                [<span class="number">1</span>, <span class="number">0</span>],</span><br><span class="line">                                [<span class="number">0</span>, <span class="number">1</span>],</span><br><span class="line">                                [<span class="number">0</span>, <span class="number">1</span>]])  <span class="comment"># 特征矩阵</span></span><br><span class="line">category = [<span class="string">&#x27;yes&#x27;</span>, <span class="string">&#x27;yes&#x27;</span>, <span class="string">&#x27;no&#x27;</span>, <span class="string">&#x27;no&#x27;</span>, <span class="string">&#x27;no&#x27;</span>]  <span class="comment"># 5个对象分别所属的类别</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">calc_shannon_ent</span>(<span class="params">category_list</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    :param category_list: 类别列表</span></span><br><span class="line"><span class="string">    :return: 该类别列表的熵值</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    label_count = &#123;&#125;  <span class="comment"># 统计数据集中每个类别的个数</span></span><br><span class="line">    num = <span class="built_in">len</span>(category_list)  <span class="comment"># 数据集个数</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num):</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            label_count[category_list[i]] += <span class="number">1</span></span><br><span class="line">        <span class="keyword">except</span> KeyError:</span><br><span class="line">            label_count[category_list[i]] = <span class="number">1</span></span><br><span class="line">    shannon_ent = <span class="number">0.</span></span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> label_count:</span><br><span class="line">        prob = <span class="built_in">float</span>(label_count[k]) / num</span><br><span class="line">        shannon_ent -= prob * log(prob, <span class="number">2</span>)  <span class="comment"># 计算信息熵</span></span><br><span class="line">    <span class="keyword">return</span> shannon_ent</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">split_data</span>(<span class="params">feature_matrix, category_list, feature_index, value</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    筛选出指定特征值所对应的类别列表</span></span><br><span class="line"><span class="string">    :param category_list: 类别列表</span></span><br><span class="line"><span class="string">    :param feature_matrix: 特征矩阵</span></span><br><span class="line"><span class="string">    :param feature_index: 指定特征索引</span></span><br><span class="line"><span class="string">    :param value: 指定特征属性的特征值</span></span><br><span class="line"><span class="string">    :return: 符合指定特征属性的特征值的类别列表</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># feature_matrix = np.array(feature_matrix)</span></span><br><span class="line">    ret_index = np.where(feature_matrix[:, feature_index] == value)[<span class="number">0</span>]  <span class="comment"># 获取符合指定特征值的索引</span></span><br><span class="line">    ret_category_list = [category_list[i] <span class="keyword">for</span> i <span class="keyword">in</span> ret_index]  <span class="comment"># 根据索引取得指定的所属类别，构建为列表</span></span><br><span class="line">    <span class="keyword">return</span> ret_category_list</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">choose_best_feature</span>(<span class="params">feature_matrix, category_list</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    根据信息增益获取最优特征</span></span><br><span class="line"><span class="string">    :param feature_matrix: 特征矩阵</span></span><br><span class="line"><span class="string">    :param category_list: 类别列表</span></span><br><span class="line"><span class="string">    :return: 最优特征对应的索引</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    feature_num = <span class="built_in">len</span>(feature_matrix[<span class="number">0</span>])  <span class="comment"># 特征个数</span></span><br><span class="line">    data_num = <span class="built_in">len</span>(category_list)  <span class="comment"># 数据集的个数</span></span><br><span class="line">    base_shannon_ent = calc_shannon_ent(category_list=category_list)  <span class="comment"># 原始数据的信息熵</span></span><br><span class="line">    best_info_gain = <span class="number">0</span>  <span class="comment"># 最优信息增益</span></span><br><span class="line">    best_feature_index = -<span class="number">1</span>  <span class="comment"># 最优特征对应的索引</span></span><br><span class="line">    <span class="keyword">for</span> f <span class="keyword">in</span> <span class="built_in">range</span>(feature_num):</span><br><span class="line">        uni_value_list = <span class="built_in">set</span>(feature_matrix[:, f])  <span class="comment"># 该特征属性所包含的特征值</span></span><br><span class="line">        new_shannon_ent = <span class="number">0.</span></span><br><span class="line">        <span class="keyword">for</span> value <span class="keyword">in</span> uni_value_list:</span><br><span class="line">            sub_cate_list = split_data(feature_matrix=feature_matrix, category_list=category_list, feature_index=f, value=value)</span><br><span class="line">            prob = <span class="built_in">float</span>(<span class="built_in">len</span>(sub_cate_list)) / data_num</span><br><span class="line">            new_shannon_ent += prob * calc_shannon_ent(sub_cate_list)</span><br><span class="line">        info_gain = base_shannon_ent - new_shannon_ent  <span class="comment"># 信息增益</span></span><br><span class="line">        <span class="built_in">print</span> <span class="string">&#x27;初始信息熵为：&#x27;</span>, base_shannon_ent, <span class="string">&#x27;按照特征%i分类后的信息熵为：&#x27;</span> % f, new_shannon_ent, <span class="string">&#x27;信息增益为：&#x27;</span>, info_gain</span><br><span class="line">        <span class="keyword">if</span> info_gain &gt; best_info_gain:</span><br><span class="line">            best_info_gain = info_gain</span><br><span class="line">            best_feature_index = f</span><br><span class="line">    <span class="keyword">return</span> best_feature_index</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    best_feature = choose_best_feature(data_feature_matrix, category)</span><br><span class="line">    <span class="built_in">print</span> <span class="string">&#x27;最好用于划分数据集的特征为：&#x27;</span>, best_feature</span><br></pre></td></tr></table></figure></p>
]]></content>
      <tags>
        <tag>python</tag>
        <tag>机器学习</tag>
        <tag>特征选择</tag>
      </tags>
  </entry>
  <entry>
    <title>基于SNN密度的聚类及python代码实现</title>
    <url>/2016/09/01/%E5%9F%BA%E4%BA%8ESNN%E5%AF%86%E5%BA%A6%E7%9A%84%E8%81%9A%E7%B1%BB%E5%8F%8Apython%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/</url>
    <content><![CDATA[<p>　　在某些情况下，依赖于相似度和密度的标准方法的聚类技术不能产生理想的聚类效果。<br><span id="more"></span></p>
<h2 id="存在的问题"><a href="#存在的问题" class="headerlink" title="存在的问题"></a>存在的问题</h2><h3 id="1-传统的相似度在高维数据上的问题"><a href="#1-传统的相似度在高维数据上的问题" class="headerlink" title="1.传统的相似度在高维数据上的问题"></a>1.传统的相似度在高维数据上的问题</h3><p>　　传统的欧几里得密度在高维空间变得没有意义。特别在文本处理之中，以分词作为特征，数据的维度将会非常得高，文本与文本之间的相似度低并不罕见。然而许多文档都有着不同类的最近邻，虽然近邻之间相似度虽然高，然而却不是同一类文档。由此可以看出，传统的相似度成为了不可靠的指导。</p>
<h3 id="2-密度不同的问题"><a href="#2-密度不同的问题" class="headerlink" title="2.密度不同的问题"></a>2.密度不同的问题</h3><p>　　传统的基于密度的聚类问题，虽然能够有效的发现不同形状的簇，然而由于在计算密度的时候是通过计算之间的欧式距离确定密度的，若存在密度差别较大的簇将无法很好地识别。<br>　　如下图，显示了一对具有不同密度点的二维簇。右边的簇尽管不太稠密，但形成了同样合法的簇。<br>　　<img src="/img/tuchuang/master/Other/img/different%20density%20clusters.png" alt="不同密度的二维簇图"><br>　　若使用传统的dbscan聚类算法(sklearn开源包)，将获得以下聚类效果，其中黑色点表示噪声。<br>　　<img src="/img/tuchuang/Other/dbscan.png" alt="dbscan"></p>
<h2 id="SNN相似度"><a href="#SNN相似度" class="headerlink" title="SNN相似度"></a>SNN相似度</h2><p>　　为了解决上诉问题，提出了<strong>共享最近邻</strong>(Shared Nearest Neighbor, SNN)相似度。如字面意思，通过计算2个点之间共享的近邻个数，确定两点之间的相似度。<br><strong><em>算法流程</em></strong><br><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">找出所有点的k-最近邻</span><br><span class="line"><span class="keyword">if</span> 两个点x和y不是在对方的k-最近邻中 <span class="function">then</span></span><br><span class="line"><span class="function">    <span class="title">similarity</span><span class="params">(x, y)</span> </span>= <span class="number">0</span></span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">    <span class="built_in">similarity</span>(x, y) = 共享的近邻个数</span><br></pre></td></tr></table></figure><br>　　SNN相似度只依赖于两个对象共享的最近邻的个数，而不是这些近邻之间相距多远。这样一来相似度关于点的密度自动进行缩放</p>
<h2 id="SNN密度"><a href="#SNN密度" class="headerlink" title="SNN密度"></a>SNN密度</h2><p>　　由于SNN相似性度量反映了数据空间中点的局部结构，因此它对密度的变化和空间的维度相对不太敏感，所以可以用来做新的密度度量。<br><strong><em>定义如下</em></strong><br><strong>核心点</strong>： 在给定邻域(Eps)内的点数超过某个阈值(MinPts)<br><strong>边界点</strong>： 不属于核心点，但在某个核心点的邻域内。<br><strong>噪声点</strong>： 既非核心点，也非边界点的噪声。<br>　　可以理解为，SNN密度度量一个点被类似的点包围的程度。</p>
<p>　　</p>
<h2 id="基于SNN密度的聚类"><a href="#基于SNN密度的聚类" class="headerlink" title="基于SNN密度的聚类"></a>基于SNN密度的聚类</h2><p>　　将上面定义的SNN密度与dbScan算法结合起来，就可以得出一种新的聚类算法<br><strong><em>算法流程</em></strong><br><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">计算SNN相似度图</span><br><span class="line">以用户指定的参数Eps和MinPts，使用dbScan算法</span><br></pre></td></tr></table></figure><br>　　以上面的数据集为例，使用该聚类算法得出以下结果。<br><img src="/img/tuchuang/master/Other/img/SNN.png" alt="SNN"></p>
<p>具体python代码实现，使用了开源包sklearn的kd-tree以及dbScan算法。<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> NearestNeighbors</span><br><span class="line"><span class="keyword">from</span> itertools <span class="keyword">import</span> combinations</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">snn_sim_matrix</span>(<span class="params">X, k=<span class="number">5</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    利用sklearn包中的KDTree,计算节点的共享最近邻相似度(SNN)矩阵</span></span><br><span class="line"><span class="string">    :param X: array-like, shape = [samples_size, features_size]</span></span><br><span class="line"><span class="string">    :param k: positive integer(default = 5), 计算snn相似度的阈值k</span></span><br><span class="line"><span class="string">    :return: snn距离矩阵</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        X = np.array(X)</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">raise</span> ValueError(<span class="string">&quot;输入的数据集必须为矩阵&quot;</span>)</span><br><span class="line">    samples_size, features_size = X.shape  <span class="comment"># 数据集样本的个数和特征的维数</span></span><br><span class="line">    nbrs = NearestNeighbors(n_neighbors=k, algorithm=<span class="string">&#x27;kd_tree&#x27;</span>).fit(X)</span><br><span class="line">    knn_matrix = nbrs.kneighbors(X, return_distance=<span class="literal">False</span>)  <span class="comment"># 记录每个样本的k个最近邻对应的索引</span></span><br><span class="line">    sim_matrix = <span class="number">0.5</span> + np.zeros((samples_size, samples_size))  <span class="comment"># snn相似度矩阵</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(samples_size):</span><br><span class="line">        t = np.where(knn_matrix == i)[<span class="number">0</span>]</span><br><span class="line">        c = <span class="built_in">list</span>(combinations(t, <span class="number">2</span>))</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> c:</span><br><span class="line">            <span class="keyword">if</span> j[<span class="number">0</span>] <span class="keyword">not</span> <span class="keyword">in</span> knn_matrix[j[<span class="number">1</span>]]:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            sim_matrix[j[<span class="number">0</span>]][j[<span class="number">1</span>]] += <span class="number">1</span></span><br><span class="line">    sim_matrix = <span class="number">1</span> / sim_matrix  <span class="comment"># 将相似度矩阵转化为距离矩阵</span></span><br><span class="line">    sim_matrix = np.triu(sim_matrix)</span><br><span class="line">    sim_matrix += sim_matrix.T - np.diag(sim_matrix.diagonal())</span><br><span class="line">    <span class="keyword">return</span> sim_matrix</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> DBSCAN</span><br><span class="line">    <span class="keyword">from</span> sklearn.datasets.samples_generator <span class="keyword">import</span> make_blobs</span><br><span class="line">    <span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 构建数据集</span></span><br><span class="line">    centers = [<span class="number">37</span>, <span class="number">4</span>]</span><br><span class="line">    centers_2 = [-<span class="number">37</span>, <span class="number">4</span>]</span><br><span class="line">    X, labels_true = make_blobs(n_samples=<span class="number">100</span>, centers=centers, cluster_std=<span class="number">20</span>)</span><br><span class="line">    X_2, l_2 = make_blobs(n_samples=<span class="number">50</span>, cluster_std=<span class="number">8</span>, centers=centers_2)</span><br><span class="line">    X = np.concatenate((X, X_2))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 基于snn相似度的聚类</span></span><br><span class="line">    t1 = time.time()</span><br><span class="line">    sim_matrix = snn_sim_matrix(X, k=<span class="number">8</span>)</span><br><span class="line">    t2 = time.time()</span><br><span class="line">    <span class="built_in">print</span> <span class="string">&quot;the time of creating sim matrix is %.5fs&quot;</span> % (t2 - t1)</span><br><span class="line">    t1 = time.time()</span><br><span class="line">    db = DBSCAN(eps=<span class="number">0.5</span>, min_samples=<span class="number">5</span>, metric=<span class="string">&#x27;precomputed&#x27;</span>).fit(sim_matrix)</span><br><span class="line">    t2 = time.time()</span><br><span class="line">    <span class="built_in">print</span> <span class="string">&quot;the time of clustering is %.5fs&quot;</span> % (t2 - t1)</span><br><span class="line">    <span class="comment"># 构图</span></span><br><span class="line">    core_samples_mask = np.zeros_like(db.labels_, dtype=<span class="built_in">bool</span>)</span><br><span class="line">    core_samples_mask[db.core_sample_indices_] = <span class="literal">True</span></span><br><span class="line">    labels = db.labels_</span><br><span class="line">    n_clusters_ = <span class="built_in">len</span>(<span class="built_in">set</span>(labels)) - (<span class="number">1</span> <span class="keyword">if</span> -<span class="number">1</span> <span class="keyword">in</span> labels <span class="keyword">else</span> <span class="number">0</span>)</span><br><span class="line">    unique_labels = <span class="built_in">set</span>(labels)</span><br><span class="line">    colors = plt.cm.Spectral(np.linspace(<span class="number">0</span>, <span class="number">1</span>, <span class="built_in">len</span>(unique_labels)))</span><br><span class="line">    <span class="keyword">for</span> k, col <span class="keyword">in</span> <span class="built_in">zip</span>(unique_labels, colors):</span><br><span class="line">        <span class="keyword">if</span> k == -<span class="number">1</span>:</span><br><span class="line">            <span class="comment"># Black used for noise.</span></span><br><span class="line">            col = <span class="string">&#x27;k&#x27;</span></span><br><span class="line">        class_member_mask = (labels == k)</span><br><span class="line">        xy = X[class_member_mask &amp; core_samples_mask]</span><br><span class="line">        plt.plot(xy[:, <span class="number">0</span>], xy[:, <span class="number">1</span>], <span class="string">&#x27;o&#x27;</span>, markerfacecolor=col,</span><br><span class="line">                 markeredgecolor=<span class="string">&#x27;k&#x27;</span>, markersize=<span class="number">10</span>)</span><br><span class="line">        xy = X[class_member_mask &amp; ~core_samples_mask]</span><br><span class="line">        plt.plot(xy[:, <span class="number">0</span>], xy[:, <span class="number">1</span>], <span class="string">&#x27;o&#x27;</span>, markerfacecolor=col,</span><br><span class="line">                 markeredgecolor=<span class="string">&#x27;k&#x27;</span>, markersize=<span class="number">6</span>)</span><br><span class="line">    plt.title(<span class="string">&#x27;SNN&#x27;</span>)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure></p>
]]></content>
      <tags>
        <tag>python</tag>
        <tag>聚类</tag>
      </tags>
  </entry>
  <entry>
    <title>基于规则的分词算法(MM RMM算法)及python代码实现</title>
    <url>/2016/10/08/%E5%9F%BA%E4%BA%8E%E8%A7%84%E5%88%99%E7%9A%84%E5%88%86%E8%AF%8D%E7%AE%97%E6%B3%95(MM%20RMM%E7%AE%97%E6%B3%95)%E5%8F%8Apython%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/</url>
    <content><![CDATA[<h2 id="一、理论描述"><a href="#一、理论描述" class="headerlink" title="一、理论描述"></a>一、理论描述</h2><p>　　中文分词指的是将一个汉字序列切分成一个一个单独的词。现有的分词算法可分为三大类：基于字符串匹配的分词方法、基于理解的分词方法和基于统计的分词方法。其中，基于字符串匹配的分词方法是按照一定的策略将待分析的汉字串与机器词典中的词条进行匹配，若在词典中找到某个字符串，则匹配成功（识别出一个词）。按照扫描方向的不同，基于字符串匹配的分词方法可以分为正向最大匹配算法（Maximum Matching，下面简称MM）和逆向最大匹配算法（Reverse Maximum Matching，下面简称RMM）。<br>　　本分词系统只是一个简单的演示程序，简单地根据语料库的信息，利用“正向最大匹配”、“逆向最大匹配算法”将一小段文字进行分词。<br><span id="more"></span></p>
<h2 id="二、算法描述"><a href="#二、算法描述" class="headerlink" title="二、算法描述"></a>二、算法描述</h2><p>➢　　正向最大匹配算法（MM）：按照人得而自然阅读顺序从左往右对一段话甚至文章进行词库匹配切分。<br>设MaxLen为最大词长,D为分词词典<br>（1）从待切分语料中按正向取长度为MaxLen的字符串str，令Len =MaxLen；<br>（2）将str与D中的词语互相匹配；<br>（3）if匹配成功，将指针向前移Len个汉字，并返回到（1）；<br>（4）if 不成功：<br>　　　　if（ Len&gt;1）：<br>　　　　　　Len = Len-1；<br>　　　　　　从待切分语料中取长度为Len的字符串str，并返回（2）；<br>　　　　else：<br>　　　　　　得到单个汉字，指针向前移一个汉字，并返回（1）</p>
<p>➢　　逆向最大匹配算法（RMM）：主要原理与正向最大匹配算法一致，只是切分方向相反，从文章的尾部开始匹配。</p>
<h2 id="三、python-代码实现"><a href="#三、python-代码实现" class="headerlink" title="三、python 代码实现"></a>三、python 代码实现</h2><p><strong>MM算法</strong><br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mm_cut</span>(<span class="params">self, sentence=<span class="string">&#x27;&#x27;</span>, max_len=<span class="number">6</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    使用正向最大匹配法划分词语</span></span><br><span class="line"><span class="string">    :param sentence: str 待划分句子</span></span><br><span class="line"><span class="string">    :param max_len: int 最大词长 默认为6</span></span><br><span class="line"><span class="string">    :return: str-list 已分词的字符串列表</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    sentence = sentence.decode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">    cur = <span class="number">0</span>  <span class="comment"># 表示分词的位置</span></span><br><span class="line">    sen_len = sentence.__len__()  <span class="comment"># 句子的长度</span></span><br><span class="line">    word_list = []  <span class="comment"># 划分的结果</span></span><br><span class="line">    <span class="keyword">while</span> cur &lt; sen_len:</span><br><span class="line">        l = <span class="literal">None</span></span><br><span class="line">        <span class="keyword">for</span> l <span class="keyword">in</span> <span class="built_in">range</span>(max_len, <span class="number">0</span>, -<span class="number">1</span>):</span><br><span class="line">            <span class="keyword">if</span> sentence[cur: cur+l] <span class="keyword">in</span> self.word_set:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">        word_list.append(sentence[cur: cur+l])</span><br><span class="line">        cur += l</span><br><span class="line">    <span class="keyword">return</span> word_list</span><br></pre></td></tr></table></figure></p>
<p><strong>RMM算法</strong><br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rmm_cut</span>(<span class="params">self, sentence=<span class="string">&#x27;&#x27;</span>, max_len=<span class="number">6</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    使用逆向最大匹配法划分词语</span></span><br><span class="line"><span class="string">    :param sentence: str 待划分句子</span></span><br><span class="line"><span class="string">    :param max_len: int 最大词长 默认为6</span></span><br><span class="line"><span class="string">    :return: str-list 已分词的字符串列表</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    sentence = sentence.decode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">    sen_len = sentence.__len__()  <span class="comment"># 句子的长度</span></span><br><span class="line">    cur = sen_len  <span class="comment"># 表示分词的位置</span></span><br><span class="line">    word_list = []  <span class="comment"># 划分的结果</span></span><br><span class="line">    <span class="keyword">while</span> cur &gt; <span class="number">0</span>:</span><br><span class="line">        l = <span class="literal">None</span></span><br><span class="line">        <span class="keyword">if</span> max_len &gt; cur:</span><br><span class="line">            max_len = cur</span><br><span class="line">        <span class="keyword">for</span> l <span class="keyword">in</span> <span class="built_in">range</span>(max_len, <span class="number">0</span>, -<span class="number">1</span>):</span><br><span class="line">            <span class="keyword">if</span> sentence[cur-l: cur] <span class="keyword">in</span> self.word_set:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">        word_list.insert(<span class="number">0</span>, sentence[cur-l: cur])</span><br><span class="line">        cur -= l</span><br><span class="line">    <span class="keyword">return</span> word_list</span><br></pre></td></tr></table></figure></p>
<h2 id="附"><a href="#附" class="headerlink" title="附"></a>附</h2><p>软件示意图<br><img src="/img/tuchuang/master/graph/Natural-Language-Processing4.png" alt="软件示意图"></p>
<p><a href="https://github.com/Hareric/Natural-Language-Processing/tree/master/%E5%88%86%E8%AF%8D">源码下载</a></p>
]]></content>
      <tags>
        <tag>NLP</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>基于图的关键词抽取(HITS算法和PageRank算法)</title>
    <url>/2017/01/23/%E5%9F%BA%E4%BA%8E%E5%9B%BE%E7%9A%84%E5%85%B3%E9%94%AE%E8%AF%8D%E6%8A%BD%E5%8F%96/</url>
    <content><![CDATA[<h2 id="项目研究背景："><a href="#项目研究背景：" class="headerlink" title="项目研究背景："></a>项目研究背景：</h2><p>　　在关键词抽取研究中，最常用的一种方法就是通过计算一篇文档中词语的TF-IDF值（term frequency-inverse document frequency）,并对它们进行排序选取TopK个作为关键词，这是一种无监督的方法。另外一种方法是通过有监督的方法，通过训练学习一个分类器，将关键词抽取问题转化为对每个词语的二分类问题，从而选择出合适的关键词。<br><span id="more"></span><br>　　无监督和有监督各有各的优势和缺点：无监督学习，不需要人工标注，训练集合的过程，因此更加方便和快捷；然而监督学习的方法，在进行了机器学习后，分类器更具有判断多种信息对关键词影响的能力，效果更优。但在信息爆炸的网络时代，人工标注训练集是非常耗时耗力的事情，更何况网络文档的主题常常随着时间变化剧烈，为了使分类器随时能够适应网络就必须随时进行训练和标注，显然这是不现实的。因此关键词抽取的研究主要还是集中在无监督的方法。<br>　　在信息检索领域，HITS算法和PageRank算法是搜索引擎中两个最基础和最重要的算法。其基本思想都是首先利用网页之间的链接关系构建网页的网络图，通过相邻节点之间的网页的重要性，计算出某个网页的重要性。<br>　　受PageRank的启发，提出了一种基于图的排序算法TextRank，通过将文档看作一个词的网络，该网络中的链接表示词与词之间的语义关系，然后利用PageRank计算网络图中词的重要性，选取重要性TopK个词作为关键词。同理也可将最初用于网页排序的HITS算法用来抽取关键词。</p>
<h2 id="项目具体思路："><a href="#项目具体思路：" class="headerlink" title="项目具体思路："></a>项目具体思路：</h2><p>input: 一篇文档    output: k个关键词<br>一．构建文档的词典<br>　　 1. 去除停用词。<br>　　 2. 消重。<br>　　 3. 获得词典 vocab。</p>
<p>二．构建词-词之间的关联矩阵<br>　　matrix[i][j]: 表示i词与j词之间的权值。初始值为0<br>　　1. 文章已分好段落。<br>　　2. 在一段新闻中，若w1和w2共现，则matrix[w1][w2]++，matrix[w2][w1]++</p>
<p>三．利用词-词之间的关联矩阵构建词语之间的无向拓扑图</p>
<p>四．评价节点重要性<br>　　计算拓扑图中每一个节点的PageRank值和Authority值用来评价节点的重要性，最后取TopK个节点作为本篇文章的关键词。</p>
<h2 id="PageRank-算法"><a href="#PageRank-算法" class="headerlink" title="PageRank 算法"></a>PageRank 算法</h2><h3 id="算法流程"><a href="#算法流程" class="headerlink" title="算法流程"></a>算法流程</h3><p>　　PageRank的思想在于将一个网页级别/重要性的排序问题转化成了一个公共参与、以群体民主投票的方式求解的问题，网页之间的链接即被认为是投票行为。同时，各个站点投票的权重不同，重要的网站投票具有较大的分量，而该网站是否重要的标准还需要依照其PageRank值。<br>　　现在假设有4个网站A、B、C、D，则它们的初始PageRank都是0.25。对于B而言的话，它把自己的总价值分散投给了A和C，各占一半的PageRank，即0.125，C和D的情况同理。即一个网站投票给其它网站PageRank的值，需要除以它所链接到的网站总数。此时PageRank的计算公式为：</p>
<pre><code>PR(A) = PR(B) / 2 + PR(C) / 1 + PR(D) / 3     
PR(B) = PR(D) / 3 
PR(C) = PR(B) / 2 + PR(D) / 3
PR(D) = 0 
</code></pre><p> <img src="http://img.my.csdn.net/uploads/201106/20/0_1308550749h06y.gif" alt="此处输入图片的描述"> </p>
<table>
<thead>
<tr>
<th>PageRank</th>
<th>PR(A)</th>
<th>PR(B)</th>
<th>PR(C)</th>
<th>PD(D)</th>
</tr>
</thead>
<tbody>
<tr>
<td>初始值</td>
<td>0.25</td>
<td>0.25</td>
<td>0.25</td>
<td>0.25</td>
</tr>
<tr>
<td>第一次迭代后</td>
<td>0.4583</td>
<td>0.0833</td>
<td>0.2083</td>
<td>0</td>
</tr>
<tr>
<td>第二次迭代后</td>
<td>0.25</td>
<td>0</td>
<td>0.0417</td>
<td>0</td>
</tr>
<tr>
<td>第三次迭代后</td>
<td>0.0417</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>第四次迭代后</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
</tbody>
</table>
<p>PageRank值计算过程的一般步骤可以概括如下：<br>（1）为每个网站设置一个初始的PageRank值。<br>（2）第一次迭代：每个网站得到一个新的PageRank。<br>（3）第二次迭代：用这组新的PageRank再按上述公式形成另一组新的PageRank。<br>（4）重复迭代直至PageRank值收敛</p>
<h2 id=""><a href="#" class="headerlink" title=" "></a> </h2><h3 id="黑洞效应"><a href="#黑洞效应" class="headerlink" title="黑洞效应"></a>黑洞效应</h3><p>　　上图中，顶点Ａ由于无出度像黑洞一样吸收所有PR值，最后导致所有PR值为0。为了防止这种情况的发生，有人给出了一种解决办法：即如果一个网站没有外链，那么就假定该连通图内其余所有的网点都是它的外链，这样我们就避免了整体PageRank值被吸收的现象。</p>
<h2 id="-1"><a href="#-1" class="headerlink" title=" "></a> </h2><h3 id="马尔可夫链-马氏链，-Markov-Chain"><a href="#马尔可夫链-马氏链，-Markov-Chain" class="headerlink" title="马尔可夫链(马氏链， Markov Chain)"></a>马尔可夫链(马氏链， Markov Chain)</h3><p><img src="http://hi.csdn.net/attachment/201106/20/0_1308550801pWe7.gif" alt="此处输入图片的描述"><br>针对以上该图，建立概率转移矩阵P，P[i][j]表示从顶点i到达顶点j的概率，那么矩阵表示就是：</p>
<pre><code>0   0.5  0   0.5
0   0    1   0
0   0    0   1
0   1    0   0
</code></pre><p>我们所给定的初始向量是：(0.25   0.25       0.25       0.25)，做第一次迭代，就相当于用初始向量乘以上面的矩阵。第二次迭代就相当于第一次迭代的结果再乘以上面的矩阵……设转移概率矩阵为P，若存在正整数N，使得P^N&gt;0（每个元素大于0），这种链被称作正则链，它存在唯一的极限状态概率，并且与初始状态无关。</p>
<h2 id="-2"><a href="#-2" class="headerlink" title=" "></a> </h2><h3 id="PageRank算法的马尔科夫过程分析"><a href="#PageRank算法的马尔科夫过程分析" class="headerlink" title="PageRank算法的马尔科夫过程分析"></a>PageRank算法的马尔科夫过程分析</h3><p>假设{A, B, C}为马氏链，其转移概率矩阵如下所示：</p>
<pre><code>0.7         0.1         0.2
0.1         0.8         0.1
0.05        0.05        0.9
</code></pre><p>因为该马氏链是不可约的非周期的有限状态，平稳分布存在，则我们要求其平衡分布为：</p>
<pre><code>X = 0.7X + 0.1Y + 0.05Z
Y = 0.1X + 0.8Y + 0.05Z
Z = 0.2X + 0.1Y + 0.9Z
X + Y + Z = 1
</code></pre><p>解得上述方程组的平稳分布为：X = 0.1765，Y = 0.2353，Z = 0.5882。<br>把PageRank收敛性问题转化为了求马尔可夫链的平稳分布的问题，那么我们就可以从马氏链的角度来分析问题。因此，对于PageRank的收敛性问题的证明也就迎刃而解了，只需要证明马氏链在什么情况下才会出现平稳分布即可。</p>
<h1 id="-3"><a href="#-3" class="headerlink" title=" "></a> </h1><h2 id="HITS算法"><a href="#HITS算法" class="headerlink" title="HITS算法"></a>HITS算法</h2><h3 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h3><p>　　所谓“Authority”页面，是指与某个领域或者某个话题相关的高质量网页，比如搜索引擎领域，Google和百度首页即该领域的高质量网页，比如视频领域，优酷和土豆首页即该领域的高质量网页。<br>　　所谓“Hub”页面，指的是包含了很多指向高质量“Authority”页面链接的网页，比如hao123首页可以认为是一个典型的高质量“Hub”网页。</p>
<h3 id="基本假设"><a href="#基本假设" class="headerlink" title="基本假设"></a>基本假设</h3><p>　　假设1：一个好的“Authority”页面会被很多好的“Hub”页面指向；<br>　　假设2：一个好的“Hub”页面会指向很多好的“Authority”页面；<br>　　<img src="http://hi.csdn.net/attachment/201202/6/0_1328534718Ug2w.gif" alt="此处输入图片的描述"></p>
<h2 id="-4"><a href="#-4" class="headerlink" title=" "></a> </h2><h3 id="算法流程-1"><a href="#算法流程-1" class="headerlink" title="算法流程"></a>算法流程</h3><p>　　具体算法：可利用上面提到的两个基本假设，以及相互增强关系等原则进行多轮迭代计算，每轮迭代计算更新每个页面的两个权值，直到权值稳定不再发生明显的变化为止。<br>　　在网页排名中，HITS算法是与用户输入的查询请求密切相关的，即HITS算法在使用之前必须构建一个根集合，由于本次项目集中研究HITS算法在文档网络的运用价值，所以在此不详细说明。<br>具体流程<br>　　一、a(i), h(i)分别表示结点i的Authority Score 和 Hub值（中心度）<br>　　二、在初始情况下，在没有更多可利用信息前，每个页面的这两个权值都是相同的，可以都设置为1，即：a(i)=1, h(i)=1<br>　　三、每次迭代计算Hub权值和Authority权值：<br>　　　　网页 a (i)在此轮迭代中的Authority权值即为所有指向网页 a (i)页面的Hub权值之和：<br>　　　　 a (i) = Σ h (i) ;<br>　　　　 网页 a (i)的Hub分值即为所指向的页面的Authority权值之和：<br>　　　　 h (i) = Σ a (i) 。<br>　　　　对a (i)、h (i)进行规范化处理:<br>　　　　将所有网页的中心度都除以最高中心度以将其标准化：<br>　　　　a (i) = a (i)/|a(i)| ；<br>　　　　将所有网页的权威度都除以最高权威度以将其标准化：<br>　　　　 h (i) = h (i)/ |h(i)| ：<br>　　四、收敛<br>　　上一轮迭代计算中的权值和本轮迭代之后权值的差异，如果发现总体来说权值没有明显变化，说明系统已进入稳定状态，则可以结束计算，即a ( u),h(v)收敛 。</p>
<h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><h4 id="实验一："><a href="#实验一：" class="headerlink" title="实验一："></a>实验一：</h4><p>新闻报道：</p>
<blockquote>
<p>　　原标题：陈君文一行到长沙县调研两型住宅产业化工作</p> <p>　　红网长沙县站3月17日讯(星沙时报记者<br>廖真怡)昨日，湖南省人大常委会副主任陈君文率队来到长沙县，就两型住宅产业化工作开展实地调研。长沙县人大常委会主任李建章，副主任彭军其，副县长李开兴陪同调研。</p><br><p>　　在福临镇泉源村集中安置房项目现场，调研组一行参观了该示范点去年底新建完成的轻钢结构房屋。据介绍，轻钢结构房屋是以冷弯薄壁型钢为结构体系的绿色建筑，具备抗震防火、保温隔热、节能环保等诸多特点。一栋250平方米的轻钢结构房屋建成耗时不到两个月，村民只需花费约六十万元即可入住。</p><br><p>　　近年来，长沙县加快推进两型住宅产业化工作，逐步将保障性住房、棚户区改造、学校、医院等政府投资类建设项目纳入两型住宅产业化实施。目前，已启动福临镇泉源村、影珠山村住宅产业化的试点工作，建成4栋冷弯薄壁轻钢房屋，均选择了农民集中居住点进行统一规划设计，集中运用住宅产业化技术建设。</p><br><p>　　陈君文强调，轻钢结构房屋集环保、节能、高效等优点于一体，符合绿色发展理念，在农村住房改造中值得大力推广。政府要出台相关政策加以扶持，示范点则要积极发挥带头引领作用，通过政府、市场两手抓，推动项目又好又快发展。</p>
</blockquote>
<p>利用textRank抽取关键词<br>　轻钢 0.01902440798<br>　房屋 0.01902440798<br>　长沙县 0.0139585118277<br>　两型 0.0139585118277<br>　住宅 0.0139585118277<br>　产业化 0.0139585118277<br>　工作 0.0139585118277<br>　福临 0.0136226056716<br>　泉源 0.0136226056716<br>　薄壁 0.0136226056716<br>耗时：0.0591039657593ｓ</p>
<p>利用jieba包中内置基于tf-idf提取关键词<br>　轻钢 0.386129934778<br>　长沙县 0.309113581381<br>　产业化 0.267338155519<br>　两型 0.265661500064<br>　住宅 0.234284985021<br>　陈君文 0.199246125048<br>　房屋 0.183773798317<br>　泉源 0.136569330439<br>　结构 0.13419387805<br>　示范点 0.124362527232<br>耗时：0.00664782524109ｓ</p>
<h4 id="实验二："><a href="#实验二：" class="headerlink" title="实验二："></a>实验二：</h4><p>新闻报道：</p>
<blockquote>
<p>　　原标题：美国宣布对朝鲜新的制裁措施</p> <p>　　据新华社电 美国政府16日宣布对朝鲜实施新的制裁措施。</p><br><p>　　美国白宫的一份新闻公告说，总统奥巴马当天发布行政令，旨在冻结朝鲜政府和朝鲜劳动党资产，禁止与朝鲜的特定交易。</p><br><p>　　美国财政部随后发布新闻公告，对朝鲜17个政府官员和机构以及20艘船只实施制裁。</p><br><p>　　新制裁针对朝鲜的能源、矿业、金融服务和交通业，禁止对朝鲜的商品、服务、技术出口以及在朝鲜进行新的投资。</p><br><p>　　白宫的新闻公告说，美国将继续对朝鲜施压，令其付出“代价”，直至朝鲜最终履行国际责任和义务。</p><br><p>　　联合国安理会3月2日一致通过第2270号决议，针对朝鲜核、导计划规定一系列制裁措施，重申支持重启六方会谈及通过和平方式实现半岛无核化。</p>
</blockquote>
<p>利用textRank抽取关键词<br>　朝鲜 0.0324132510978<br>　制裁 0.0239090726699<br>　公告 0.0206482233926<br>　新闻 0.0165485844427<br>　禁止 0.0164814054247<br>　措施 0.0158486641078<br>　实施 0.0138236030274<br>　美国 0.0133183833419<br>　朝鲜劳动党 0.012182643101<br>　资产 0.012182643101<br>耗时: 0.0261380672455ｓ</p>
<p>利用jieba包中内置基于tf-idf提取关键词<br>　朝鲜 0.645829143617<br>　制裁 0.427122149321<br>　公告 0.161725613834<br>　措施 0.161613619075<br>　禁止 0.133688805542<br>　针对 0.118448597479<br>　20 0.11720360297<br>　17 0.11720360297<br>　16 0.11720360297<br>　2270 0.11720360297<br>耗时: 0.00232791900635ｓ</p>
<h4 id="实验总结"><a href="#实验总结" class="headerlink" title="实验总结"></a>实验总结</h4><p>　　本次实验主要针对新浪网中近100条新闻作为实验的测试集，通过人工统计，对比评价基于图的关键词提取法（textRank）以及基于tf-idf的关键词的抽取法。其中选取了最具代表性2篇新闻作为本次的实验的实验样本。<br>　　实验一的关键词提取效果中，textRank和tf-idf均能较好提取出关键词，二个算法之间的关键词提取效果也并没有太大的差异。然而二者之间的耗时却有着明显的差异。由于textRank算法中涉及到网络图的构建以及多轮迭代，所以性能上普遍比tf-idf要低上一截。（jieba包中已包含了常见词语的idf词语，因此不需要大量文档进行学习）<br>　　实验二的关键词的提取效果中就有着明显差异，由于jieba包内置的tf-idf关键词提取算法，并不存在实时标注和学习的过程，在面对不同的主题的新闻时，关键词的提取效果就有些差异。如实验二中，textRank所抓取的10个关键词都较符合新闻的主题，而tf-idf所提取的就有少些无实际意义的词作为关键词。<br>　　总结，基于图的关键词的提取中算法，较于传统的tf-idf关键词提取效果有一定的提高。然而在本次实验室中的100多个测试集中，粗略统计，大多数新闻的关键词的提取中，tf-idf的关键词提取效果与textRank相比，并无多大差异。因此我觉得在实际应用中，还需要综合各种情况选取合适的算法。</p>
]]></content>
      <tags>
        <tag>python</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title>招聘网数据库系统说明书</title>
    <url>/2016/06/03/%E6%8B%9B%E8%81%98%E7%BD%91%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F%E8%AF%B4%E6%98%8E%E4%B9%A6/</url>
    <content><![CDATA[<h2 id="一、需求分析"><a href="#一、需求分析" class="headerlink" title="一、需求分析"></a>一、需求分析</h2><h3 id="1-1-背景"><a href="#1-1-背景" class="headerlink" title="1.1 背景"></a>1.1 背景</h3><p>　　随着互联网的快速发展，网民数量的不断增加，人们上网的途径也越来越方便，网络在现代人生活中的应用也越来越广泛。与互联网相结合的网络招聘在解决了部分大学生工作的同时，也大大减少了人力、物力的消耗以及大学毕业生奔波路途的时间和精力，其效果也将远远超过传统招聘所获得的效果。目前，网络招聘已发展成为深受招聘求职者喜欢的一种求职招聘环境。互联网给求职招聘者提供了丰富的资源，未他们创造出一种良好的求职招聘平台，具备现实中人才中介机构的功能。招聘求职网站为应聘者提供了方便、快捷的应聘途径，不仅信息更新快、信息数量多、而且选择余地大。对招聘单位来说，招聘网站不仅为他们开辟了招聘人才的新方式，而且使其工作流程更加方便、快捷、高效。使得招聘工作中的人员初选工作变得轻松简单。双方通过交互式的网上登陆和查询完成信息的交流。这种现代化招聘方式与传统招聘方式有很大的不同，它不需要时间和空间上保持绝对的一致，方便了双方时间的选择。<br>　　网络招聘在节约招聘单位和求职者双方的费用上有很大的优势。求职者可以通过互联网对工作类型、地点、工作待遇等条件进行筛选之后快速得到自己想要的招聘信息并投递简历，大大减少了打印简历和证书、交通等当面的费用；对于招聘单位而言，在网上发布招聘信息不仅仅能够帮助扩大招聘信息的覆盖面及宣传度，还能帮助企业节约不少传统招聘所需的人力、财力资源，而且对信息的发布和修改也十分方便。招聘网就是这样一个跨时间和空间的信息互动过程。招聘单位与求职者的双方的积极互动将促进网络招聘的功能更加完善，而网络招聘也将减少企业招聘和求职者应聘过程中的盲目行为，大大提高招聘求职规模和招聘求职成功率。<br><span id="more"></span></p>
<h3 id="1-2功能需求"><a href="#1-2功能需求" class="headerlink" title="1.2功能需求"></a>1.2功能需求</h3><p>网站主要用户角色分为应聘用户、企业用户<br>个人用户：　用户注册<br>　　　　　　用户信息管理<br>　　　　　　创建简历<br>　　　　　　简历信息管理<br>　　　　　　投放简历<br>企业用户：　用户注册<br>　　　　　　用户信息管理<br>　　　　　　发布招聘信息<br>　　　　　　招聘信息管理<br>　　　　　　获得相关简历的投放信息<br>　　　　　　管理简历的评判成绩</p>
<h3 id="1-3数据需求"><a href="#1-3数据需求" class="headerlink" title="1.3数据需求"></a>1.3数据需求</h3><h4 id="1-3-1流程图"><a href="#1-3-1流程图" class="headerlink" title="1.3.1流程图"></a>1.3.1流程图</h4><p><img src="/img/tuchuang/db/image001.png" alt="招聘网---数据流程图"></p>
<h4 id="1-3-2数据需求表"><a href="#1-3-2数据需求表" class="headerlink" title="1.3.2数据需求表"></a>1.3.2数据需求表</h4><p>数据组名：用户信息<br>与其他数据的约束关系：与简历存在一对多关系</p>
<table>
<thead>
<tr>
<th>数据项名</th>
<th>数据类型</th>
<th>数据长度</th>
<th>小数位数</th>
<th>约束</th>
<th>允许空值</th>
<th>备注</th>
</tr>
</thead>
<tbody>
<tr>
<td>用户名</td>
<td>Varchar</td>
<td>20</td>
<td>-</td>
<td>-</td>
<td>否</td>
<td></td>
</tr>
<tr>
<td>口令</td>
<td>Varchar</td>
<td>20</td>
<td>长度为6-16个字符</td>
<td>不允许空格</td>
<td>否</td>
<td>可用MD5算法加密</td>
</tr>
<tr>
<td>性别</td>
<td>Varchar</td>
<td>2</td>
<td>-</td>
<td>-</td>
<td>否    </td>
</tr>
<tr>
<td>邮件地址</td>
<td>Varchar</td>
<td>32</td>
<td>-</td>
<td>unique</td>
<td>否    </td>
</tr>
<tr>
<td>联系电话</td>
<td>Varchar</td>
<td>11</td>
<td>-</td>
<td>unique</td>
<td>否    </td>
</tr>
</tbody>
</table>
<p>数据组名：企业信息<br>与其他数据的约束关系：与招聘信息存在一对多关系</p>
<table>
<thead>
<tr>
<th>数据项名</th>
<th>数据类型</th>
<th>数据长度</th>
<th>小数位数</th>
<th>约束</th>
<th>允许空值</th>
<th>备注</th>
</tr>
</thead>
<tbody>
<tr>
<td>企业名称</td>
<td>Varchar</td>
<td>20</td>
<td>-</td>
<td>foreign key</td>
<td>否</td>
</tr>
<tr>
<td>公司地址</td>
<td>Varchar</td>
<td>128</td>
<td>-</td>
<td></td>
<td>否</td>
</tr>
<tr>
<td>公司成立时间</td>
<td>Varchar</td>
<td>20</td>
<td>-</td>
<td></td>
<td>否</td>
</tr>
<tr>
<td>邮件地址</td>
<td>Varchar</td>
<td>40</td>
<td>-</td>
<td>unique</td>
<td>否</td>
</tr>
<tr>
<td>公司性质</td>
<td>Varchar</td>
<td>40</td>
<td>-</td>
<td></td>
<td>否</td>
</tr>
<tr>
<td>联系电话</td>
<td>Varchar</td>
<td>11</td>
<td>-</td>
<td>unique</td>
<td>否</td>
</tr>
<tr>
<td>公司规模</td>
<td>Varchar</td>
<td>20</td>
<td>-</td>
<td></td>
<td>否</td>
</tr>
<tr>
<td>公司简介</td>
<td>Varchar</td>
<td>255</td>
<td>-</td>
<td></td>
<td>否</td>
</tr>
</tbody>
</table>
<p>数据组名：简历信息<br>与其他数据的约束关系：与用户存在一对一关系</p>
<table>
<thead>
<tr>
<th>数据项名</th>
<th>数据类型</th>
<th>数据长度</th>
<th>小数位数</th>
<th>约束</th>
<th>允许空值</th>
<th>备注</th>
</tr>
</thead>
<tbody>
<tr>
<td>求职类别</td>
<td>Varchar</td>
<td>40</td>
<td>-</td>
<td></td>
<td>否</td>
</tr>
<tr>
<td>求职者姓名</td>
<td>Varchar</td>
<td>20</td>
<td>-</td>
<td></td>
<td>否</td>
</tr>
<tr>
<td>出生日期</td>
<td>Varchar</td>
<td>20</td>
<td>-</td>
<td></td>
<td>否</td>
</tr>
<tr>
<td>现居住地</td>
<td>Varchar</td>
<td>20</td>
<td>-</td>
<td></td>
<td>否</td>
</tr>
<tr>
<td>学历</td>
<td>Varchar</td>
<td>40</td>
<td>-</td>
<td></td>
<td>否</td>
</tr>
<tr>
<td>工作经验</td>
<td>Varchar</td>
<td>128</td>
<td>-</td>
<td></td>
<td>否</td>
</tr>
<tr>
<td>毕业院校</td>
<td>Varchar</td>
<td>40</td>
<td>-</td>
<td></td>
<td>是</td>
</tr>
<tr>
<td>主修专业</td>
<td>Varchar</td>
<td>20</td>
<td>-</td>
<td></td>
<td>是</td>
</tr>
<tr>
<td>邮件</td>
<td>Varchar</td>
<td>20</td>
<td>-</td>
<td>unique</td>
<td>否</td>
</tr>
<tr>
<td>联系电话</td>
<td>Int</td>
<td>20</td>
<td>-</td>
<td>unique</td>
<td>否</td>
</tr>
<tr>
<td>个人介绍</td>
<td>Varchar</td>
<td>128</td>
<td>-</td>
<td></td>
<td>否</td>
</tr>
<tr>
<td>期望工作</td>
<td>Varchar</td>
<td>40</td>
<td>-</td>
<td></td>
<td>否</td>
</tr>
</tbody>
</table>
<p>数据组名：招聘信息<br>与其他数据的约束关系：与企业存在多对一关系</p>
<table>
<thead>
<tr>
<th>数据项名</th>
<th>数据类型</th>
<th>数据长度</th>
<th>小数位数</th>
<th>约束</th>
<th>允许空值</th>
<th>备注</th>
</tr>
</thead>
<tbody>
<tr>
<td>所发布岗位类别</td>
<td>Varchar</td>
<td>40</td>
<td>-</td>
<td></td>
<td>否</td>
</tr>
<tr>
<td>岗位名称</td>
<td>Varchar</td>
<td>2</td>
<td>-</td>
<td></td>
<td>否</td>
</tr>
<tr>
<td>岗位地址</td>
<td>Varchar</td>
<td>40</td>
<td>-</td>
<td></td>
<td>否</td>
</tr>
<tr>
<td>学历要求</td>
<td>Varchar</td>
<td>20</td>
<td>-</td>
<td></td>
<td>否</td>
</tr>
<tr>
<td>性别要求</td>
<td>Varchar</td>
<td>10</td>
<td>-</td>
<td></td>
<td>是</td>
</tr>
<tr>
<td>工作经验要求</td>
<td>Varchar</td>
<td>20</td>
<td>-</td>
<td></td>
<td>否</td>
</tr>
<tr>
<td>年龄要求</td>
<td>Int</td>
<td>20</td>
<td>-</td>
<td></td>
<td>否</td>
</tr>
<tr>
<td>岗位地址</td>
<td>Varchar</td>
<td>40</td>
<td>-</td>
<td></td>
<td>否</td>
</tr>
<tr>
<td>工资</td>
<td>Varchar</td>
<td>20</td>
<td>-</td>
<td></td>
<td>否</td>
</tr>
<tr>
<td>招聘人数</td>
<td>Int</td>
<td>10</td>
<td>-</td>
<td></td>
<td>否</td>
</tr>
<tr>
<td>联系电话</td>
<td>Varchar</td>
<td>11</td>
<td>-</td>
<td>unique</td>
<td>否</td>
</tr>
<tr>
<td>邮箱</td>
<td>Varchar</td>
<td>20</td>
<td>-</td>
<td>unique</td>
<td>否</td>
</tr>
<tr>
<td>岗位简介</td>
<td>Varchar</td>
<td>128</td>
<td>-</td>
<td></td>
<td>是</td>
</tr>
<tr>
<td>发布时间</td>
<td>Varchar</td>
<td>20</td>
<td>-</td>
<td></td>
<td>否</td>
</tr>
</tbody>
</table>
<h2 id="二、概念模型"><a href="#二、概念模型" class="headerlink" title="二、概念模型"></a>二、概念模型</h2><p> <img src="/img/tuchuang/db/image003.png" alt="招聘网 E-R图"></p>
<h2 id="三、逻辑模型"><a href="#三、逻辑模型" class="headerlink" title="三、逻辑模型"></a>三、逻辑模型</h2><p> <img src="/img/tuchuang/db/image005.png" alt="招聘网---关系模式图"></p>
<p><strong>1. 用户信息（user）</strong></p>
<table>
<thead>
<tr>
<th>属性名</th>
<th>说明</th>
<th>类型</th>
<th>长度</th>
<th>默认值</th>
<th>允许空值</th>
<th>约束</th>
</tr>
</thead>
<tbody>
<tr>
<td>id</td>
<td>用户id,主码</td>
<td>Varchar</td>
<td>15</td>
<td>-</td>
<td>否</td>
<td>-</td>
</tr>
<tr>
<td>mid</td>
<td>用户对应的网站管理信息</td>
<td>Varchar</td>
<td>20</td>
<td>-</td>
<td>否</td>
<td>外码，参照manage中的id</td>
</tr>
<tr>
<td>name</td>
<td>姓名/联系人</td>
<td>Varchar</td>
<td>20</td>
<td>-</td>
<td>否</td>
<td>-</td>
</tr>
<tr>
<td>sex</td>
<td>性别</td>
<td>Varchar</td>
<td>2</td>
<td>-</td>
<td>否</td>
<td>-</td>
</tr>
<tr>
<td>email</td>
<td>邮件地址</td>
<td>Varchar</td>
<td>20</td>
<td>-</td>
<td>否</td>
<td>-</td>
</tr>
<tr>
<td>tel</td>
<td>联系电话</td>
<td>Varchar</td>
<td>20</td>
<td>-</td>
<td>否</td>
<td>-</td>
</tr>
</tbody>
</table>
<p><strong>2. 公司信息（company）</strong></p>
<table>
<thead>
<tr>
<th>属性名</th>
<th>说明</th>
<th>类型</th>
<th>长度</th>
<th>默认值</th>
<th>允许空值</th>
<th>约束</th>
</tr>
</thead>
<tbody>
<tr>
<td>id</td>
<td>公司id，主码</td>
<td>Varchar</td>
<td>15</td>
<td>-</td>
<td>否</td>
<td>-</td>
</tr>
<tr>
<td>mid</td>
<td>公司对应的网站管理信息</td>
<td>Varchar</td>
<td>20</td>
<td>-</td>
<td>否</td>
<td>外码，参照manage中的id</td>
</tr>
<tr>
<td>name</td>
<td>公司名称</td>
<td>Varchar</td>
<td>20</td>
<td>-</td>
<td>否</td>
<td>-</td>
</tr>
<tr>
<td>address</td>
<td>公司地址</td>
<td>Varchar</td>
<td>20</td>
<td>-</td>
<td>否</td>
<td>-</td>
</tr>
<tr>
<td>establish</td>
<td>公司成立时间</td>
<td>Varchar</td>
<td>10</td>
<td>-</td>
<td>否</td>
<td>-</td>
</tr>
<tr>
<td>email</td>
<td>邮件地址</td>
<td>Varchar</td>
<td>20</td>
<td>-</td>
<td>是</td>
<td>-</td>
</tr>
<tr>
<td>property</td>
<td>公司性质</td>
<td>Varchar</td>
<td>20</td>
<td>-</td>
<td>否</td>
<td>-</td>
</tr>
<tr>
<td>tel</td>
<td>联系电话</td>
<td>Varchar</td>
<td>20</td>
<td>-</td>
<td>否</td>
<td>-</td>
</tr>
<tr>
<td>scale</td>
<td>公司规模</td>
<td>Varchar</td>
<td>10</td>
<td>-</td>
<td>否</td>
<td>-</td>
</tr>
<tr>
<td>intro</td>
<td>公司简介</td>
<td>Varchar</td>
<td>300</td>
<td>-</td>
<td>否</td>
<td>-</td>
</tr>
</tbody>
</table>
<p><strong>3. 管理信息（manage）</strong></p>
<table>
<thead>
<tr>
<th>属性名</th>
<th>说明</th>
<th>类型</th>
<th>长度</th>
<th>默认值</th>
<th>允许空值</th>
<th>约束</th>
</tr>
</thead>
<tbody>
<tr>
<td>id</td>
<td>注册id，主码</td>
<td>Varchar</td>
<td>15</td>
<td>-</td>
<td>否</td>
<td>-</td>
</tr>
<tr>
<td>password</td>
<td>密码</td>
<td>Varchar</td>
<td>20</td>
<td>-</td>
<td>否</td>
<td>-</td>
</tr>
<tr>
<td>role</td>
<td>用户角色</td>
<td>Varchar</td>
<td>2</td>
<td>-</td>
<td>否</td>
<td>-</td>
</tr>
</tbody>
</table>
<p><strong>4. 简历（CV）</strong></p>
<table>
<thead>
<tr>
<th>属性名</th>
<th>说明</th>
<th>类型</th>
<th>长度</th>
<th>默认值</th>
<th>允许空值</th>
<th>约束</th>
</tr>
</thead>
<tbody>
<tr>
<td>id</td>
<td>简历id，主码</td>
<td>Varchar</td>
<td>15</td>
<td>-</td>
<td>否</td>
<td>-</td>
</tr>
<tr>
<td>category</td>
<td>求职类型</td>
<td>Varchar</td>
<td>15</td>
<td>-</td>
<td>否</td>
<td>外码，参照job_category中的cate_name</td>
</tr>
<tr>
<td>name</td>
<td>名字</td>
<td>Varchar</td>
<td>20</td>
<td>-</td>
<td>否</td>
<td>-</td>
</tr>
<tr>
<td>sex</td>
<td>性别</td>
<td>Varchar</td>
<td>2</td>
<td>-</td>
<td>否</td>
<td>-</td>
</tr>
<tr>
<td>birth</td>
<td>出生日期</td>
<td>Varchar</td>
<td>20</td>
<td>-</td>
<td>否</td>
<td>-</td>
</tr>
<tr>
<td>address</td>
<td>居住地址</td>
<td>Varchar</td>
<td>20</td>
<td>-</td>
<td>否</td>
<td>-</td>
</tr>
<tr>
<td>education</td>
<td>学历</td>
<td>Varchar</td>
<td>10</td>
<td>-</td>
<td>否</td>
<td>-</td>
</tr>
<tr>
<td>work_exp</td>
<td>工作经验</td>
<td>Varchar</td>
<td>10</td>
<td>-</td>
<td>否</td>
<td>-</td>
</tr>
<tr>
<td>school</td>
<td>毕业院校</td>
<td>Varchar</td>
<td>20</td>
<td>-</td>
<td>是</td>
<td>-</td>
</tr>
<tr>
<td>major</td>
<td>主修专业</td>
<td>Varchar</td>
<td>20</td>
<td>-</td>
<td>是</td>
<td>-</td>
</tr>
<tr>
<td>email</td>
<td>邮箱</td>
<td>Varchar</td>
<td>20</td>
<td>-</td>
<td>否</td>
<td>-</td>
</tr>
<tr>
<td>tel</td>
<td>联系电话</td>
<td>Varchar</td>
<td>20</td>
<td>-</td>
<td>否</td>
<td>-</td>
</tr>
<tr>
<td>intro</td>
<td>个人介绍</td>
<td>Varchar</td>
<td>300</td>
<td>-</td>
<td>否</td>
<td>-</td>
</tr>
<tr>
<td>expected_job</td>
<td>期望工作</td>
<td>Varchar</td>
<td>20</td>
<td>-</td>
<td>否</td>
<td>-</td>
</tr>
</tbody>
</table>
<p><strong>5. 岗位（job_deliver）</strong></p>
<table>
<thead>
<tr>
<th>属性名</th>
<th>说明</th>
<th>类型</th>
<th>长度</th>
<th>默认值</th>
<th>允许空值</th>
<th>约束</th>
</tr>
</thead>
<tbody>
<tr>
<td>id</td>
<td>岗位id，主码</td>
<td>Varchar</td>
<td>15</td>
<td>-</td>
<td>否</td>
<td>-</td>
</tr>
<tr>
<td>category</td>
<td>岗位类别</td>
<td>Varchar</td>
<td>20</td>
<td>-</td>
<td>否</td>
<td>外码，参照manage中的id</td>
</tr>
<tr>
<td>job_name</td>
<td>岗位名称</td>
<td>Varchar</td>
<td>10</td>
<td>-</td>
<td>否</td>
<td>-</td>
</tr>
<tr>
<td>sex</td>
<td>性别要求</td>
<td>Varchar</td>
<td>5</td>
<td>-</td>
<td>否</td>
<td>-</td>
</tr>
<tr>
<td>education</td>
<td>学历要求</td>
<td>Varchar</td>
<td>10</td>
<td>-</td>
<td>否</td>
<td>-</td>
</tr>
<tr>
<td>work_year</td>
<td>工作经验要求</td>
<td>Varchar</td>
<td>10</td>
<td>-</td>
<td>否</td>
<td>-</td>
</tr>
<tr>
<td>age</td>
<td>年龄要求</td>
<td>Varchar</td>
<td>10</td>
<td>-</td>
<td>否</td>
<td>-</td>
</tr>
<tr>
<td>position</td>
<td>岗位地址</td>
<td>Varchar</td>
<td>20</td>
<td>-</td>
<td>否</td>
<td>-</td>
</tr>
<tr>
<td>salary</td>
<td>工资</td>
<td>Varchar</td>
<td>10</td>
<td>-</td>
<td>否</td>
<td>-</td>
</tr>
<tr>
<td>num</td>
<td>招聘人数</td>
<td>Int</td>
<td>4</td>
<td>-</td>
<td>否</td>
<td>-</td>
</tr>
<tr>
<td>contact</td>
<td>联系方式</td>
<td>Varchar</td>
<td>20</td>
<td>-</td>
<td>否</td>
<td>-</td>
</tr>
<tr>
<td>description</td>
<td>岗位介绍</td>
<td>Varchar</td>
<td>300</td>
<td>-</td>
<td>是</td>
<td>-</td>
</tr>
<tr>
<td>created_time</td>
<td>发布时间</td>
<td>Varchar</td>
<td>20</td>
<td>-</td>
<td>否</td>
<td>-</td>
</tr>
</tbody>
</table>
<p><strong>6. 岗位类别（job_category）</strong></p>
<table>
<thead>
<tr>
<th>属性名</th>
<th>说明</th>
<th>类型</th>
<th>长度</th>
<th>默认值</th>
<th>允许空值</th>
<th>约束</th>
</tr>
</thead>
<tbody>
<tr>
<td>cate_name</td>
<td>岗位类别</td>
<td>Varchar</td>
<td>10</td>
<td>-</td>
<td>否</td>
<td></td>
<td>-</td>
</tr>
<tr>
<td>pre_cate</td>
<td>岗位的父类类别，若无父类，则为空</td>
<td>Varchar</td>
<td>20</td>
<td>-    否</td>
<td>-</td>
</tr>
</tbody>
</table>
<p><strong>7. 用户-简历（user-CV）</strong></p>
<table>
<thead>
<tr>
<th>属性名</th>
<th>说明</th>
<th>类型</th>
<th>长度</th>
<th>默认值</th>
<th>允许空值</th>
<th>约束</th>
</tr>
</thead>
<tbody>
<tr>
<td>id</td>
<td>用户-简历id，主码</td>
<td>Varchar</td>
<td>15</td>
<td>-</td>
<td>否</td>
<td>-</td>
</tr>
<tr>
<td>user_id</td>
<td>对应的用户id</td>
<td>Varchar</td>
<td>20</td>
<td>-</td>
<td>否</td>
<td>外码，参照user中的id</td>
</tr>
<tr>
<td>cv_id</td>
<td>对应的简历id</td>
<td>Varchar</td>
<td>20</td>
<td>-</td>
<td>否</td>
<td>外码，参照CV中的id</td>
</tr>
</tbody>
</table>
<p><strong>8. 公司-岗位（company-job）</strong></p>
<table>
<thead>
<tr>
<th>属性名</th>
<th>说明</th>
<th>类型</th>
<th>长度</th>
<th>默认值</th>
<th>允许空值</th>
<th>约束</th>
</tr>
</thead>
<tbody>
<tr>
<td>id</td>
<td>公司-岗位id，主码</td>
<td>Varchar</td>
<td>15</td>
<td>-</td>
<td>否</td>
<td>-</td>
</tr>
<tr>
<td>company_id</td>
<td>对应的公司id</td>
<td>Varchar</td>
<td>20</td>
<td>-</td>
<td>否</td>
<td>外码，参照company中的id</td>
</tr>
<tr>
<td>job_deliver_id</td>
<td>对应的岗位id</td>
<td>Varchar</td>
<td>20</td>
<td>-</td>
<td>否</td>
<td>外码，参照job_deliver中的id</td>
</tr>
</tbody>
</table>
<p><strong>9. 简历投递（job-wanted）</strong></p>
<table>
<thead>
<tr>
<th>属性名</th>
<th>说明</th>
<th>类型</th>
<th>长度</th>
<th>默认值</th>
<th>允许空值</th>
<th>约束</th>
</tr>
</thead>
<tbody>
<tr>
<td>id</td>
<td>用户-简历id，主码</td>
<td>Varchar</td>
<td>15</td>
<td>-</td>
<td>否</td>
<td>-</td>
</tr>
<tr>
<td>job_deliver_id</td>
<td>对应的招聘岗位id</td>
<td>Varchar</td>
<td>20</td>
<td>-</td>
<td>否</td>
<td>外码，参照job_deliver中的id</td>
</tr>
<tr>
<td>cv_id</td>
<td>对应的简历id</td>
<td>Varchar</td>
<td>20</td>
<td>-</td>
<td>否</td>
<td>外码，参照CV中的id</td>
</tr>
<tr>
<td>result</td>
<td>投递状态</td>
<td>Varchar</td>
<td>10</td>
<td>-</td>
<td>否</td>
<td>-</td>
</tr>
</tbody>
</table>
<h2 id="四、建表代码"><a href="#四、建表代码" class="headerlink" title="四、建表代码"></a>四、建表代码</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1.建立数据库：</span><br><span class="line">CREATE DATABASE jobnetwork;</span><br><span class="line">USE jobnetwork;</span><br><span class="line"></span><br><span class="line">2.建立管理信息表：</span><br><span class="line">CREATE TABLE manage (</span><br><span class="line">  ID varchar(12) NOT NULL,            /* 注册者管理信息的id */</span><br><span class="line">  role varchar(20) NOT NULL,          /* 0代表应聘者，1代表公司 */</span><br><span class="line">  password varchar(20) NOT NULL,      /* 注册者的登录密码 */</span><br><span class="line">  PRIMARY KEY (ID)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">3.建立应聘者信息表：</span><br><span class="line">CREATE TABLE applicant (</span><br><span class="line">  ID varchar(11) NOT NULL,            /* 应聘者的id */</span><br><span class="line">  name varchar(20) NOT NULL,          /* 应聘者名字 */</span><br><span class="line">  sex varchar(10) NOT NULL,           /* 应聘者性别 */</span><br><span class="line">  email varchar(20) NOT NULL,         /* 应聘者邮箱 */</span><br><span class="line">  telephone varchar(20) NOT NULL,     /* 应聘者手机号码 */</span><br><span class="line">  mid_id varchar(12) NOT NULL,        /* 应聘者对应的注册管理信息的id */</span><br><span class="line">  PRIMARY KEY (ID),</span><br><span class="line">  FOREIGN KEY (mid_id) REFERENCES manage (ID)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">4.建立公司信息表：</span><br><span class="line">CREATE TABLE company (</span><br><span class="line">  ID varchar(11) NOT NULL,            /* 公司的id */</span><br><span class="line">  name varchar(20) NOT NULL,          /* 公司名字 */</span><br><span class="line">  address varchar(30) NOT NULL,       /* 公司地址 */</span><br><span class="line">  establish varchar(20) NOT NULL,     /* 公司建立时间 */</span><br><span class="line">  email varchar(20) NOT NULL,         /* 公司联系邮箱 */</span><br><span class="line">  property varchar(20) NOT NULL,      /* 公司性质 */</span><br><span class="line">  telephone varchar(20) NOT NULL,     /* 公司联系电话 */</span><br><span class="line">  scale varchar(20) NOT NULL,         /* 公司规模 */</span><br><span class="line">  intro varchar(300) NOT NULL,        /* 公司简介 */</span><br><span class="line">  mid_id varchar(12) NOT NULL,        /* 公司对应的注册管理信息的id */</span><br><span class="line">  PRIMARY KEY (ID),</span><br><span class="line">  FOREIGN KEY (mid_id) REFERENCES manage (ID)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">5.建立岗位类别表：</span><br><span class="line">CREATE TABLE jobcategory (</span><br><span class="line">  cate_name varchar(20) NOT NULL,     /* 岗位类别 */</span><br><span class="line">  pre_cate varchar(20) NOT NULL,      /* 岗位对应的父类别，若无则为空 */</span><br><span class="line">  PRIMARY KEY (cate_name)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">6.建立简历表：</span><br><span class="line">CREATE TABLE cv (</span><br><span class="line">  ID varchar(11) NOT NULL,            /* 简历的id */</span><br><span class="line">  name varchar(20) NOT NULL,          /* 应聘者名字 */</span><br><span class="line">  sex varchar(10) NOT NULL,           /* 应聘者性别 */</span><br><span class="line">  birth varchar(20) NOT NULL,         /* 应聘者出生日期 */</span><br><span class="line">  create_time varchar(20) NOT NULL,   /* 简历创建日期 */</span><br><span class="line">  location varchar(50) NOT NULL,      /* 应聘者先居住地 */</span><br><span class="line">  education varchar(20) NOT NULL,     /* 应聘者学历 */</span><br><span class="line">  work_exp varchar(100) NOT NULL,     /* 应聘者工作经历 */</span><br><span class="line">  school varchar(20) NOT NULL,        /* 应聘者毕业院校 */</span><br><span class="line">  major varchar(20) NOT NULL,         /* 应聘者专业 */</span><br><span class="line">  email varchar(20) NOT NULL,         /* 应聘者邮箱 */</span><br><span class="line">  telephone varchar(20) NOT NULL,     /* 应聘者手机号码 */</span><br><span class="line">  intro varchar(300) NOT NULL,        /* 应聘者简介 */</span><br><span class="line">  expected_job varchar(20) NOT NULL,  /* 应聘者期望应聘岗位 */</span><br><span class="line">  category_id varchar(20) NOT NULL,   /* 应聘者应聘岗位类别 */</span><br><span class="line">  PRIMARY KEY (ID),</span><br><span class="line">  FOREIGN KEY (category_id) REFERENCES jobcategory (cate_name)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">7.建立发布岗位表：</span><br><span class="line">CREATE TABLE jobdeliver (</span><br><span class="line">  ID varchar(11) NOT NULL,            /* 发布的岗位id */</span><br><span class="line">  job_name varchar(20) NOT NULL,      /* 岗位名字 */</span><br><span class="line">  position varchar(40) NOT NULL,      /* 岗位工作地点 */</span><br><span class="line">  numb int NOT NULL,                  /* 岗位招聘人数 */</span><br><span class="line">  sex varchar(10) NOT NULL,           /* 性别要求 */</span><br><span class="line">  work_year varchar(5) NOT NULL,      /* 工作经历要求 */</span><br><span class="line">  age varchar(10) NOT NULL,           /* 年龄要求 */</span><br><span class="line">  education varchar(20) NOT NULL,     /* 学历要求 */</span><br><span class="line">  salary varchar(20) NOT NULL,        /* 工资 */</span><br><span class="line">  intro varchar(300) NOT NULL,        /* 岗位介绍 */</span><br><span class="line">  contact varchar(20) NOT NULL,       /* 联系方式 */</span><br><span class="line">  created_time varchar(20) NOT NULL,  /* 创建时间 */</span><br><span class="line">  category_id varchar(20) NOT NULL,   /* 岗位所属类别 */</span><br><span class="line">  PRIMARY KEY (ID),</span><br><span class="line">  FOREIGN KEY (category_id) REFERENCES jobcategory (cate_name)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">8.建立公司-岗位表：</span><br><span class="line">CREATE TABLE companyjob (</span><br><span class="line">  ID varchar(11) NOT NULL,            /* 公司-岗位的id */</span><br><span class="line">  company_id varchar(11) NOT NULL,    /* 公司的id */</span><br><span class="line">  job_deliver_id varchar(11) NOT NULL,/* 已发布岗位的id */</span><br><span class="line">  PRIMARY KEY (ID),</span><br><span class="line">  FOREIGN KEY (job_deliver_id) REFERENCES jobdeliver (ID),</span><br><span class="line">  FOREIGN KEY (company_id) REFERENCES company (ID)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">9.建立应聘者-简历表：</span><br><span class="line">CREATE TABLE usercv (</span><br><span class="line">  ID varchar(11) NOT NULL,            /* 用户-简历的id */</span><br><span class="line">  cv_id varchar(11) NOT NULL,         /* 简历的id */</span><br><span class="line">  applicant_id varchar(11) NOT NULL,  /* 应聘者的id */</span><br><span class="line">  PRIMARY KEY (ID),</span><br><span class="line">  FOREIGN KEY (applicant_id) REFERENCES applicant (ID),</span><br><span class="line">  FOREIGN KEY (cv_id) REFERENCES cv (ID)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">10.建立岗位-建立投递表：</span><br><span class="line">CREATE TABLE jobwanted (</span><br><span class="line">  ID varchar(11) NOT NULL,            /* 简历-岗位 投递的id */</span><br><span class="line">  result varchar(10) NOT NULL,        /* 投递结果 */</span><br><span class="line">  cv_id varchar(11) NOT NULL,         /* 简历的id */</span><br><span class="line">  job_deliver_id varchar(11) NOT NULL,/* 发布岗位的id */</span><br><span class="line">  PRIMARY KEY (ID),</span><br><span class="line">  FOREIGN KEY (job_deliver_id) REFERENCES jobdeliver (ID),</span><br><span class="line">  FOREIGN KEY (cv_id) REFERENCES cv (ID)</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h2 id="五、招聘网数据库查询系统说明"><a href="#五、招聘网数据库查询系统说明" class="headerlink" title="五、招聘网数据库查询系统说明"></a>五、招聘网数据库查询系统说明</h2><h3 id="5-1系统介绍"><a href="#5-1系统介绍" class="headerlink" title="5.1系统介绍"></a>5.1系统介绍</h3><p>1)操作系统 系统搭建在Ubuntu系统上。Ubuntu是一免费开源操作系统，是基于Linux的发行版本，具有开放性和高性价比等显著特点。同时Ubuntu具有庞大的社区力量支持，可以方便地从社区获得帮助。系统选用的是Ubuntu14.04版本，该版本代号为“Trusty Tahr”（值得信赖的塔尔羊），是一个长期支持版本，有很好的性能和交互性。</p>
<p>2）开发语言 系统主要使用python，python是一种完全面向对象、解释型计算机程序设计语言，语法简洁清晰，拥有丰富和强大的库，易读且易维护，提供API，能方便进行维护和管理。</p>
<p>3）数据库管理系统<br>系统选用SQLite数据库，SQLite是遵守ACID的关系数据库管理系统，它包含在一个相对小的C程式库中。与许多其它数据库管理系统不同，SQLite不是一个客户端/服务器结构的数据库引擎，而是被集成在用户程序中。</p>
<p>4）开发框架 系统选用Django框架，Django是一个开放源代码的Web应用框架，由Python写成。采用了MVC的软件设计模式。它强调代码复用,多个组件可以很方便的以“插件”形式服务于整个框架，有许多功能强大的第三方插件，具有很强的可扩展性。</p>
<h3 id="5-2界面展示"><a href="#5-2界面展示" class="headerlink" title="5.2界面展示"></a>5.2界面展示</h3><h4 id="5-2-1登陆界面"><a href="#5-2-1登陆界面" class="headerlink" title="5.2.1登陆界面"></a>5.2.1登陆界面</h4><p> <img src="/img/tuchuang/db/image007.png" alt="登陆界面"><br>输入账号和密码，查询数据库并与密码匹配成功后可登陆<br><img src="/img/tuchuang/db/image009.png" alt="登录失败1"> <img src="/img/tuchuang/db/image011.png" alt="登录失败2"><br>若查询失败则无法登陆</p>
<h4 id="5-2-2普通用户登录"><a href="#5-2-2普通用户登录" class="headerlink" title="5.2.2普通用户登录"></a>5.2.2普通用户登录</h4><p> <img src="/img/tuchuang/db/image013.png" alt="普通用户登录"><br>获得用户详细信息，和对应的简历列表<br><img src="/img/tuchuang/db/image015.png" alt="简历的详细信息"><br>每份简历的详细信息</p>
<h4 id="5-2-3企业用户登录"><a href="#5-2-3企业用户登录" class="headerlink" title="5.2.3企业用户登录"></a>5.2.3企业用户登录</h4><p> <img src="/img/tuchuang/db/image017.png" alt="企业用户详细信息"><br>获得企业用户详细信息，和对应的发布的招聘信息列表<br><img src="/img/tuchuang/db/image019.png" alt="详细招聘信息"><br>每条招聘的详细招聘信息<br><img src="/img/tuchuang/db/image021.png" alt="对应该招聘投放的简历"><br>以及对应该招聘投放的简历</p>
<h4 id="5-2-4数据库后台管理"><a href="#5-2-4数据库后台管理" class="headerlink" title="5.2.4数据库后台管理"></a>5.2.4数据库后台管理</h4><p><img src="/img/tuchuang/db/image023.png" alt="此处输入图片的描述"><br>用来管理数据库的后台，实现增删查改。</p>
<h3 id="5-3-系统使用说明"><a href="#5-3-系统使用说明" class="headerlink" title="5.3 系统使用说明"></a>5.3 系统使用说明</h3><p>系统运行需求：<br>系统环境：ubuntu14.04/OS X<br>程序语言：python 2.7.+<br>框架: django 1.8.0+</p>
<p>系统下载:<br>使用github下载：<br>git clone <a href="https://github.com/Hareric/dbBigHW.git">https://github.com/Hareric/dbBigHW.git</a><br>直接下载：<br><a href="https://github.com/Hareric/dbBigHW/archive/master.zip">https://github.com/Hareric/dbBigHW/archive/master.zip</a></p>
<p>系统运行：<br>进入该系统根目录，终端下执行python manage.py runserver开启本地服务器<br>浏览器访问: 127.0.0.1:8000/home 进入查询页面<br>浏览器访问: 127.0.0.1:8000/admin 进入数据库后台管理页面<br>管理员帐号: admin 密码: admin</p>
]]></content>
      <tags>
        <tag>数据库</tag>
        <tag>Django</tag>
        <tag>文档</tag>
      </tags>
  </entry>
  <entry>
    <title>简易方法解决ubuntu下解压文件乱码</title>
    <url>/2016/07/26/%E7%AE%80%E6%98%93%E6%96%B9%E6%B3%95%E8%A7%A3%E5%86%B3ubuntu%E4%B8%8B%E8%A7%A3%E5%8E%8B%E6%96%87%E4%BB%B6%E4%B9%B1%E7%A0%81/</url>
    <content><![CDATA[<p>在windows上压缩的文件，是以系统默认编码中文来压缩文件。由于zip文件中没有声明其编码，所以linux上的unzip一般以默认编码解压，中文文件名会出现乱码。<br>可以使用终端zip文件进行解压并指定解压的编码<br><code>unzip -O GBK xxx.zip</code><br>解压后的文件的路径为当前终端所在的路径</p>
]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>朴素贝叶斯分类器（Naive Bayes classifier)</title>
    <url>/2016/04/23/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8/</url>
    <content><![CDATA[<p>　　朴素贝叶斯是一种构建分类器的简单方法。该分类器模型会给问题实例分配用特征值表示的类标签，类标签取自有限集合。它不是训练这种分类器的单一算法，而是一系列基于相同原理的算法：所有朴素贝叶斯分类器都假定样本每个特征与其他特征都不相关。举个例子，如果一种水果其具有红，圆，直径大概3英寸等特征，该水果可以被判定为是苹果。尽管这些特征相互依赖或者有些特征由其他特征决定，然而<strong>朴素</strong>贝叶斯分类器认为这些属性在判定该水果是否为苹果的概率分布上<strong>独立</strong>的。<br><span id="more"></span></p>
<h3 id="一、朴素贝叶斯分类的基本原理"><a href="#一、朴素贝叶斯分类的基本原理" class="headerlink" title="一、朴素贝叶斯分类的基本原理"></a>一、朴素贝叶斯分类的基本原理</h3><p>　　给定的待分类项的特征属性，计算该项在各个类别出现的概率，取最大的概率类别作为预测项。</p>
<h3 id="二、贝叶斯定理"><a href="#二、贝叶斯定理" class="headerlink" title="二、贝叶斯定理"></a>二、贝叶斯定理</h3><p>　　根据条件概率的定义。在事件B发生的条件下事件A发生的概率是:</p>
<p>　　　 <img src="https://upload.wikimedia.org/math/8/6/9/8694e4193ba45b55403595096b7d23c5.png" alt="P(A|B)=\frac{P(A \cap B)}{P(B)}。"><br>　　同样地，在事件A发生的条件下事件B发生的概率:</p>
<p>　　　<img src="https://upload.wikimedia.org/math/8/b/6/8b6c81124815aad54c91c42b3261165d.png" alt="P(B|A) = \frac{P(A \cap B)}{P(A)}. \!"><br>　　整理与合并这两个方程式，我们可以得到:</p>
<p>　　　<img src="https://upload.wikimedia.org/math/e/f/a/efaf8fda8a92eeb2d8cf70468c20ed5a.png" alt="P(A|B)\, P(B) = P(A \cap B) = P(B|A)\, P(A). \!"><br>　　这个引理有时称作概率乘法规则。上式两边同除以P(A)，若P(A)是非零的，我们可以得到贝叶斯定理:</p>
<p>　　　<img src="https://upload.wikimedia.org/math/f/1/3/f13abde4811844c29b556a35ca4f55a5.png" alt="P(B|A) = \frac{P(A|B)\,P(B)}{P(A)}. \!"> </p>
<h3 id="三、贝叶斯定理的变式应用"><a href="#三、贝叶斯定理的变式应用" class="headerlink" title="三、贝叶斯定理的变式应用"></a>三、贝叶斯定理的变式应用</h3><p>　　现有一个待分类项x，拥有n个特征，归于类别c的概率可表示为：<br>　　　<img src="http://img.blog.csdn.net/20150919230336645" alt="1111"><br>　　使用贝叶斯定理可变式为:<br>　　　<img src="http://img.blog.csdn.net/20150919230412981" alt="这里写图片描述"><br>　　由于在计算其他类别的概率时，均会除以<img src="http://img.blog.csdn.net/20150919230523709" alt="http://img.blog.csdn.net/20150919230438224)">，并不影响最后结果的判断预测，因此可省略，即:<br>　　　<img src="http://img.blog.csdn.net/20150919230629093" alt="这里写图片描述"><br>　　变式后:<br>　　　<img src="http://img.blog.csdn.net/20150919231524861" alt="这里写图片描述"><br>　　<strong>例：</strong><br>　　　现给出10个被分类项的特征和已确定的类别，用来训练该分类器。</p>
<table>
<thead>
<tr>
<th style="text-align:center">被分类项\特征</th>
<th style="text-align:center">F1</th>
<th style="text-align:center">F2</th>
<th style="text-align:center">F3</th>
<th style="text-align:center">F4</th>
<th style="text-align:center">F5</th>
<th style="text-align:center">F6</th>
<th style="text-align:center">类别</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">U1</td>
<td style="text-align:center">1</td>
<td style="text-align:center">0</td>
<td style="text-align:center">1</td>
<td style="text-align:center">0</td>
<td style="text-align:center">1</td>
<td style="text-align:center">0</td>
<td style="text-align:center">a</td>
</tr>
<tr>
<td style="text-align:center">U2</td>
<td style="text-align:center">1</td>
<td style="text-align:center">1</td>
<td style="text-align:center">0</td>
<td style="text-align:center">1</td>
<td style="text-align:center">0</td>
<td style="text-align:center">0</td>
<td style="text-align:center">a</td>
</tr>
<tr>
<td style="text-align:center">U3</td>
<td style="text-align:center">1</td>
<td style="text-align:center">0</td>
<td style="text-align:center">0</td>
<td style="text-align:center">1</td>
<td style="text-align:center">1</td>
<td style="text-align:center">1</td>
<td style="text-align:center">b</td>
</tr>
<tr>
<td style="text-align:center">U4</td>
<td style="text-align:center">0</td>
<td style="text-align:center">0</td>
<td style="text-align:center">1</td>
<td style="text-align:center">0</td>
<td style="text-align:center">1</td>
<td style="text-align:center">1</td>
<td style="text-align:center">a</td>
</tr>
<tr>
<td style="text-align:center">U5</td>
<td style="text-align:center">1</td>
<td style="text-align:center">0</td>
<td style="text-align:center">0</td>
<td style="text-align:center">1</td>
<td style="text-align:center">1</td>
<td style="text-align:center">0</td>
<td style="text-align:center">c</td>
</tr>
<tr>
<td style="text-align:center">U6</td>
<td style="text-align:center">1</td>
<td style="text-align:center">1</td>
<td style="text-align:center">1</td>
<td style="text-align:center">1</td>
<td style="text-align:center">1</td>
<td style="text-align:center">0</td>
<td style="text-align:center">b</td>
</tr>
<tr>
<td style="text-align:center">U7</td>
<td style="text-align:center">1</td>
<td style="text-align:center">1</td>
<td style="text-align:center">1</td>
<td style="text-align:center">0</td>
<td style="text-align:center">1</td>
<td style="text-align:center">1</td>
<td style="text-align:center">a</td>
</tr>
<tr>
<td style="text-align:center">U8</td>
<td style="text-align:center">1</td>
<td style="text-align:center">0</td>
<td style="text-align:center">1</td>
<td style="text-align:center">0</td>
<td style="text-align:center">1</td>
<td style="text-align:center">0</td>
<td style="text-align:center">c</td>
</tr>
<tr>
<td style="text-align:center">U9</td>
<td style="text-align:center">0</td>
<td style="text-align:center">1</td>
<td style="text-align:center">0</td>
<td style="text-align:center">0</td>
<td style="text-align:center">1</td>
<td style="text-align:center">0</td>
<td style="text-align:center">c</td>
</tr>
<tr>
<td style="text-align:center">U10</td>
<td style="text-align:center">0</td>
<td style="text-align:center">1</td>
<td style="text-align:center">1</td>
<td style="text-align:center">0</td>
<td style="text-align:center">1</td>
<td style="text-align:center">0</td>
<td style="text-align:center">a</td>
</tr>
</tbody>
</table>
<p>由上示表格可计算出  P(F1|c)=0.66  ;  P(F5|a)=0.8 ; P(F3|b)=0.5 ; P(c)=0.3…<br>现给出 U11 项的特征，进行预测推断该项应属于a,b,c中的哪一类</p>
<table>
<thead>
<tr>
<th style="text-align:center">被分类项\特征</th>
<th style="text-align:center">F1</th>
<th style="text-align:center">F2</th>
<th style="text-align:center">F3</th>
<th style="text-align:center">F4</th>
<th style="text-align:center">F5</th>
<th style="text-align:center">F6</th>
<th style="text-align:center">类别</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">U11</td>
<td style="text-align:center">0</td>
<td style="text-align:center">0</td>
<td style="text-align:center">1</td>
<td style="text-align:center">0</td>
<td style="text-align:center">1</td>
<td style="text-align:center">0</td>
<td style="text-align:center">未知</td>
</tr>
</tbody>
</table>
<p>由表格可得知：被分类项 U11 拥有特征F3和F5</p>
<ul>
<li>预测分到类别a的概率: <img src="http://img.blog.csdn.net/20150920000652999" alt="这里写图片描述"></li>
<li>预测分到类别b的概率: <img src="http://img.blog.csdn.net/20150920001125208" alt="这里写图片描述"></li>
<li>预测分到类别c的概率: <img src="http://img.blog.csdn.net/20150920001136676" alt="这里写图片描述"><br>因此可预测该项应分至类别a</li>
</ul>
<h3 id="四、贝叶斯分类运用于文本分类中"><a href="#四、贝叶斯分类运用于文本分类中" class="headerlink" title="四、贝叶斯分类运用于文本分类中"></a>四、贝叶斯分类运用于文本分类中</h3><p>实例:对邮件进行垃圾邮件和正常邮件的分类<br><strong>基本思路：</strong><br>1.将邮件中的文本的每一个词都作为特征，是否存在这个词可视为该邮件是否存在这个特征。<br>2.首先给出了已人工划分好的邮件作为训练集，创建关于邮件的完整词库。<br>3.对每条邮件都创建关于词库的向量，邮件若存在某词语则为1，不存在则为0.<br>4.创建如下图的向量表。</p>
<table>
<thead>
<tr>
<th style="text-align:center">　</th>
<th style="text-align:center">ability</th>
<th style="text-align:center">ad</th>
<th style="text-align:center">after</th>
<th style="text-align:center">basket</th>
<th style="text-align:center">battle</th>
<th style="text-align:center">behind</th>
<th style="text-align:center">…</th>
<th style="text-align:center">zero</th>
<th style="text-align:center">zebu</th>
<th style="text-align:center">zest</th>
<th style="text-align:center">zoom</th>
<th>是否为垃圾邮件</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">Email01</td>
<td style="text-align:center">1</td>
<td style="text-align:center">0</td>
<td style="text-align:center">1</td>
<td style="text-align:center">0</td>
<td style="text-align:center">1</td>
<td style="text-align:center">1</td>
<td style="text-align:center"></td>
<td style="text-align:center">0</td>
<td style="text-align:center">1</td>
<td style="text-align:center">1</td>
<td style="text-align:center">1</td>
<td>1</td>
</tr>
<tr>
<td style="text-align:center">Email02</td>
<td style="text-align:center">0</td>
<td style="text-align:center">0</td>
<td style="text-align:center">0</td>
<td style="text-align:center">0</td>
<td style="text-align:center">1</td>
<td style="text-align:center">0</td>
<td style="text-align:center"></td>
<td style="text-align:center">1</td>
<td style="text-align:center">0</td>
<td style="text-align:center">1</td>
<td style="text-align:center">1</td>
<td>0</td>
</tr>
<tr>
<td style="text-align:center">Email03</td>
<td style="text-align:center">1</td>
<td style="text-align:center">1</td>
<td style="text-align:center">1</td>
<td style="text-align:center">1</td>
<td style="text-align:center">0</td>
<td style="text-align:center">1</td>
<td style="text-align:center"></td>
<td style="text-align:center">1</td>
<td style="text-align:center">1</td>
<td style="text-align:center">0</td>
<td style="text-align:center">1</td>
<td>0</td>
</tr>
<tr>
<td style="text-align:center">Email04</td>
<td style="text-align:center">0</td>
<td style="text-align:center">0</td>
<td style="text-align:center">0</td>
<td style="text-align:center">0</td>
<td style="text-align:center">1</td>
<td style="text-align:center">0</td>
<td style="text-align:center"></td>
<td style="text-align:center">0</td>
<td style="text-align:center">0</td>
<td style="text-align:center">0</td>
<td style="text-align:center">0</td>
<td>1</td>
</tr>
<tr>
<td style="text-align:center">Email05</td>
<td style="text-align:center">1</td>
<td style="text-align:center">1</td>
<td style="text-align:center">0</td>
<td style="text-align:center">1</td>
<td style="text-align:center">1</td>
<td style="text-align:center">1</td>
<td style="text-align:center"></td>
<td style="text-align:center">1</td>
<td style="text-align:center">0</td>
<td style="text-align:center">0</td>
<td style="text-align:center">1</td>
<td>1</td>
</tr>
<tr>
<td style="text-align:center">Email06</td>
<td style="text-align:center">0</td>
<td style="text-align:center">0</td>
<td style="text-align:center">1</td>
<td style="text-align:center">0</td>
<td style="text-align:center">0</td>
<td style="text-align:center">0</td>
<td style="text-align:center"></td>
<td style="text-align:center">0</td>
<td style="text-align:center">0</td>
<td style="text-align:center">1</td>
<td style="text-align:center">0</td>
<td>0</td>
</tr>
<tr>
<td style="text-align:center">Email07</td>
<td style="text-align:center">0</td>
<td style="text-align:center">1</td>
<td style="text-align:center">0</td>
<td style="text-align:center">1</td>
<td style="text-align:center">1</td>
<td style="text-align:center">1</td>
<td style="text-align:center"></td>
<td style="text-align:center">1</td>
<td style="text-align:center">0</td>
<td style="text-align:center">0</td>
<td style="text-align:center">0</td>
<td>1</td>
</tr>
<tr>
<td style="text-align:center">Email08</td>
<td style="text-align:center">0</td>
<td style="text-align:center">1</td>
<td style="text-align:center">1</td>
<td style="text-align:center">1</td>
<td style="text-align:center">0</td>
<td style="text-align:center">0</td>
<td style="text-align:center"></td>
<td style="text-align:center">0</td>
<td style="text-align:center">1</td>
<td style="text-align:center">1</td>
<td style="text-align:center">1</td>
<td>1</td>
</tr>
<tr>
<td style="text-align:center">Email09</td>
<td style="text-align:center">1</td>
<td style="text-align:center">1</td>
<td style="text-align:center">1</td>
<td style="text-align:center">1</td>
<td style="text-align:center">1</td>
<td style="text-align:center">1</td>
<td style="text-align:center"></td>
<td style="text-align:center">1</td>
<td style="text-align:center">0</td>
<td style="text-align:center">0</td>
<td style="text-align:center">1</td>
<td>0</td>
</tr>
<tr>
<td style="text-align:center">Email10</td>
<td style="text-align:center">0</td>
<td style="text-align:center">0</td>
<td style="text-align:center">0</td>
<td style="text-align:center">0</td>
<td style="text-align:center">0</td>
<td style="text-align:center">0</td>
<td style="text-align:center"></td>
<td style="text-align:center">0</td>
<td style="text-align:center">1</td>
<td style="text-align:center">0</td>
<td style="text-align:center">0</td>
<td>1</td>
</tr>
<tr>
<td style="text-align:center">…</td>
</tr>
<tr>
<td style="text-align:center">Email n</td>
<td style="text-align:center">0</td>
<td style="text-align:center">0</td>
<td style="text-align:center">1</td>
<td style="text-align:center">0</td>
<td style="text-align:center">1</td>
<td style="text-align:center">0</td>
<td style="text-align:center"></td>
<td style="text-align:center">0</td>
<td style="text-align:center">1</td>
<td style="text-align:center">0</td>
<td style="text-align:center">0</td>
<td>1</td>
</tr>
</tbody>
</table>
<p>5、待分类的邮件则可以利用上图表使用贝叶斯定理，计算出归于垃圾邮件和正常邮件的概率，并进行预测。</p>
<p><strong>代码实例</strong><br>１．首先读入数据集 spam 文件夹中的垃圾邮件和 ham 文件夹中的正常邮件，并对它进行解码、分词处理和小写处理，最后合并成一个列表。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadDataSet</span>():</span> <span class="comment">#导入垃圾邮件和正常邮件作为训练集</span></span><br><span class="line">    test_list = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">21</span>)[<span class="number">1</span>:]:</span><br><span class="line">        file1 = <span class="built_in">open</span>(<span class="string">r&#x27;spam/%s.txt&#x27;</span>%i)</span><br><span class="line">        text = file1.read()</span><br><span class="line">        code = chardet.detect(text)[<span class="string">&#x27;encoding&#x27;</span>]</span><br><span class="line">        text = text.decode(code).lower()</span><br><span class="line">        words = nltk.word_tokenize(text)</span><br><span class="line">        test_list.append(words)</span><br><span class="line">        file1.close()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">21</span>)[<span class="number">1</span>:]:</span><br><span class="line">        file1 = <span class="built_in">open</span>(<span class="string">r&#x27;ham/%s.txt&#x27;</span>%i)</span><br><span class="line">        text = file1.read()</span><br><span class="line">        code = chardet.detect(text)[<span class="string">&#x27;encoding&#x27;</span>]</span><br><span class="line">        text = text.decode(code).lower()</span><br><span class="line">        words = nltk.word_tokenize(text)</span><br><span class="line">        test_list.append(words)</span><br><span class="line">        file1.close()</span><br><span class="line">    classVec = [<span class="number">1</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">20</span>)]</span><br><span class="line">    classVec.extend([<span class="number">0</span> <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">20</span>)])<span class="comment">#1 代表垃圾邮件 0代表普通邮件</span></span><br><span class="line">    <span class="keyword">return</span> test_list,classVec</span><br></pre></td></tr></table></figure>
<p>2、利用set类型操作，对列表进行处理，删除重复单词，最后合并成一个词库<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">createVocabList</span>(<span class="params">dataSet</span>):</span><span class="comment">#创建词库</span></span><br><span class="line">    vocabSet = <span class="built_in">set</span>([])</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> dataSet:</span><br><span class="line">        vocabSet = vocabSet | <span class="built_in">set</span>(i) <span class="comment">#取并集，消除重复集</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">list</span>(vocabSet)</span><br></pre></td></tr></table></figure></p>
<p>3、对单条邮件创建向量</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">createVector</span>(<span class="params">unit,vocabList</span>):</span></span><br><span class="line">    vector = [<span class="number">0</span>]*<span class="built_in">len</span>(vocabList)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> unit:</span><br><span class="line">        <span class="keyword">if</span> i <span class="keyword">in</span> vocabList:</span><br><span class="line">            vector[vocabList.index(i)] = <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="built_in">print</span> <span class="string">&quot;the word %s is not in my vocabList&quot;</span>%i</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">    <span class="keyword">return</span> vector</span><br></pre></td></tr></table></figure>
<p>4、利用已分好类型的邮件数对贝叶斯分类器进行训练。训练结束后能够得到：正常邮件中和垃圾邮件词库中每个词出现的概率列表（p1Vect,p0Vect），以及垃圾邮件和正常邮件的概率（p1,p0）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">trainNBO</span>(<span class="params">train_matrix,train_bool</span>):</span></span><br><span class="line">    train_num = <span class="built_in">len</span>(train_matrix)</span><br><span class="line">    words_num = <span class="built_in">len</span>(train_matrix[<span class="number">0</span>])</span><br><span class="line">    sum_1 = [<span class="number">0</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(words_num)]</span><br><span class="line">    sum_0 = [<span class="number">0</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(words_num)]</span><br><span class="line">    _1_num = <span class="number">0</span>  <span class="comment">#是垃圾邮件的邮件数</span></span><br><span class="line">    _0_num = <span class="number">0</span>  <span class="comment">#非垃圾邮件的邮件数</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(train_num):  <span class="comment">#将训练矩阵向量进行相加</span></span><br><span class="line">        <span class="keyword">if</span> train_bool[i]==<span class="number">1</span>:</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(words_num):</span><br><span class="line">                sum_1[j] += train_matrix[i][j]</span><br><span class="line">            _1_num = _1_num + <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> train_bool[i]==<span class="number">0</span>:</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(words_num):</span><br><span class="line">                sum_0[j] += train_matrix[i][j]</span><br><span class="line">            _0_num = _0_num + <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span> <span class="string">&quot;正常邮件数：&quot;</span>,_0_num,<span class="string">&quot; 垃圾邮件数：&quot;</span>,_1_num</span><br><span class="line">    p1Vect = [(<span class="built_in">float</span>(sum_1[j])/_1_num) <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(words_num)]</span><br><span class="line">    p0Vect = [(<span class="built_in">float</span>(sum_0[j])/_0_num) <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(words_num)]</span><br><span class="line">    p1 = <span class="built_in">float</span>(_1_num)/train_num</span><br><span class="line">    p0 = <span class="built_in">float</span>(_0_num)/train_num</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> p1Vect,p0Vect,p1,p0</span><br></pre></td></tr></table></figure>
<p>5、将已转化成向量的邮件，进行类别推测。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">classing</span>(<span class="params">p1Vect,p0Vect,P1,P0,unitVector</span>):</span></span><br><span class="line">    p1 = <span class="number">1.</span></span><br><span class="line">    p0 = <span class="number">1.</span></span><br><span class="line">    words_num = <span class="built_in">len</span>(unitVector)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(words_num):</span><br><span class="line">        <span class="keyword">if</span> unitVector[i]==<span class="number">1</span>:</span><br><span class="line">            p1 *= p1_vect[i]</span><br><span class="line">            p0 *= p0_vect[i]</span><br><span class="line">    p1 *= P1</span><br><span class="line">    p0 *= P0</span><br><span class="line">    <span class="keyword">if</span> p1&gt;p0:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>:<span class="keyword">return</span> <span class="number">0</span></span><br></pre></td></tr></table></figure>
<p><a href="https://github.com/Hareric/DM/tree/36be6b6e8fddb13ad6541009b65684ac903b98f5/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8">数据集和源代码下载</a></p>
<p>资料参考：<br>1、 维基百科<br>2、《机器学习实战》</p>
]]></content>
      <tags>
        <tag>python</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>花20分钟写的-大白话讲解如何给github上项目贡献代码</title>
    <url>/2016/06/05/%E8%8A%B120%E5%88%86%E9%92%9F%E5%86%99%E7%9A%84-%E5%A4%A7%E7%99%BD%E8%AF%9D%E8%AE%B2%E8%A7%A3%E5%A6%82%E4%BD%95%E7%BB%99github%E4%B8%8A%E9%A1%B9%E7%9B%AE%E8%B4%A1%E7%8C%AE%E4%BB%A3%E7%A0%81/</url>
    <content><![CDATA[<p>转自 <a href="https://site.douban.com/196781/widget/notes/12161495/note/269163206/">https://site.douban.com/196781/widget/notes/12161495/note/269163206/</a></p>
<p>本文献给对git很迷茫的新手，注意是新手，但至少会点基本操作，有点基本概念的新手，我不会从怎么用github和git是什么开始讲的。如果作为新手你看书又看不进去，原理又太复杂，有没有直接了当告诉我们怎么给项目贡献代码，并和项目同步代码的大体流程。于是我快速写了这么个东西。一来整理下自己混乱的思路，二来想号召大家一起用git开发点东西，可是好几个同鞋只会寂寞的给自己push。<br><span id="more"></span><br>我先说下 我之前对github操作的一些迷茫历程，然后之后是怎么解惑的。</p>
<ol>
<li><p>最最开始，我以为git clone ［项目地址］，也就是把代码clone下来 然后修改，然后push到项目里就可以了。<br>后来发现，这种情况只适合该项目属于你自己的情况，如果你git clone别人的项目代码，你想push都push不上去，因为 git push 不是需要你输入github帐号密码么。</p>
</li>
<li><p>然后 我就知道了 github上 不是有个fork么， 好，那么给别人的项目提交代码的方式就有了，先fork下别人的代码，于是你的github上就出现了同名的项目，这个项目就属于你自己了，你把这个自己的项目git clone到本地，修修改改，然后push到你自己的项目里，那么你如何把你对自己项目的改动，给发到之前fork的那个原项目呢，看见了没，在github上你的项目页面有个按钮，叫Pull request，对 你点它就会把你的修改发到对方的项目里，人还会收到邮件呢，由原项目主人决定是否接受你的修改。<br>但是，这样问题就出来了，在你fork他的项目之后，如果他又更新了代码，你自己fork的项目怎么做到和原项目同步呢？<br>我就想啊，是不是 我还得重新git clone原项目的代码，然后手动合并到我fork的项目里呢。。。<br>梁老师说，你丫这太蛋疼了，肯定不是这么麻烦，我细想，也是啊，这不2么。。。</p>
</li>
<li><p>然后，从《Pro git》上看到一个知识点，我擦，github居然可以给项目添加合作者，也就是说，假如你，对，说你呢，戴眼镜那个，你想参与我的项目，你跟我说一声，我就把你添加到我的项目里作为合作者，这个选项在项目的设置里面有，只要我添加你了，你就可以git clone我的代码然后修修改改，然后直接push上来就行了，就不用fork那么麻烦了，如果你要更新服务器代码，只要git pull就行了，看 合作者这东西多方便，就像我们在公司用svn似的。</p>
</li>
<li><p>然后我就想啊，有了合作者还需要你丫fork这个功能干啥？仔细一想，你写个好项目，不能随便加合作者啊，加了个熊孩子把你代码改废了可咋整，这年头熊孩子很多，我自己不就是一个么。所以fork肯定还是需要，fork就是专门预防熊孩子的，这就是真相！那么前面说道到fork之后如何与原项目同步的问题还在啊，没有得到解决。</p>
</li>
<li><p>于是《Pro git》再次给了我一个解答，具体流程是你啊想给我的项目做贡献，你先git clone我的代码到本地，然后修修改改，然后你不是不能push到我的项目里么，你可以先在github页面上fork我的项目，有了你自己的项目地址（url）之后呢，你在本地操作git remote add [sort name] [your url]，意思就是添加第二个远程仓库地址，这个仓库的“昵称”就是你刚指定的[sort name]，然后，你之后push文件呢 就通过指定这个［sort name］来push到这个你自己的仓库里。等你觉得想要把你改的发给原项目同步，就在你的项目上点Pull request按钮.说下另一种情况，如果是，原项目发生了改动，你要想同步到本地，就直接从git fetch origin 从原项目的地址同步代码，然后再merge就好了。当然，如《Pro git》上所写，你可以通过新建分支的方式往自己的项目上push，这样同步的时候直接fetch就行了。这块如果我没写明白或者你想知道怎么新建分支的方式push到自己的项目里，可以直接参考《Pro git》的“公开的小型项目”一节，那我的贡献就是指点你如何从这本书里快速的找到你想要的。= =。</p>
</li>
</ol>
]]></content>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
</search>
